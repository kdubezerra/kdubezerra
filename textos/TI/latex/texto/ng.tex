\chapter{Uma arquitetura multi-servidor para walkthrough virtual distribuído}

Neste trabalho, Beatrice Ng et al. apresentam a arquitetura do CyberWalk \cite{ng2002msa}, um sistema de walkthrough virtual distribuído desenvolvida pelos autores. Ele permite que usuários em diferentes locais no globo compartilhem informação e interajam dentro de um ambiente virtual comum através de uma rede local ou da Internet. Para permitir boa performance do sistema, são utilizados múltiplos servidores e é empregada uma técnica de particonamento adaptativo dos dados que particiona dinamicamente o ambiente virtual inteiro em regiões. Todos os objetos dentro de cada região serão gerenciados por um servidor. Sob circunstâncias normais, quando um usuário está explorando uma região, o servidor daquela região será responsável por responder a todos os pedidos do usuário. Quando um usuário está cruzando a fronteira entre duas ou mais regiões, os servidores das regiões envolvidas estarão respondendo às requisições do usuário, já que ele pode visualizar objetos dentro de todas as regiões. Informações a respeito de objetos virtuais, incluindo suas localizações e formas, são mantidas em um servidor de banco de dados central.

%1
\section{Visão geral do CyberWalk}

O sistema é implementado com baso no conceito de transmissão sob demanda, que possui algumas vantagens em relação a outros sistemas existentes: redução do custo de transmissão através de envio progressivo de modelos e a introdução dos escopos do observador e do objeto; redução do custo de renderização através da modelagem de objetos com múltiplas resoluções e aumento da interatividade e disponibilidade do sistema através de caching e prefetching.

\begin{figure}
 \centering
 \includegraphics[width=0.8\textwidth]{imagens/NG_Z.JPG}
 \caption{Escopo de objeto (object) e escopo de observador (viewer)}
 \label{fig:Z}
\end{figure}

\begin{itemize}
	
	\item Escopo de observador e escopo de objeto: para reduzir a quantidade de dados necessários para enviar, é generalizado o conceito de área de interesse para ambos observador e objeto, chamados de escopo de observador e escopo de objeto. Um escopo de observador indica quão longe o observador pode ver. Um escopo de objeto indica quão longe um objeto pode ser visto. Seu tamanho é proporcional ao tambanho do objeto. Em geral, um observador pode também ser considerado um objeto e ter um escopo de objeto a ele atribuído, além do próprio escopo de observador. Um objeto pode apenas ser visto por um observador quando os dois escopos se sobrepõem. Além disso, objetos cujos escopos não se sobrepõem com o escopo do observador não precisam ser transferidos para o cliente, de modo a economizar largura de banda de transmissão, processamento e memória necessária. Os autores definem um escopo como uma região circular caracterizada por um raio, como mostrado na Figura \ref{fig:Z}.
	
	\item Modelagem com múltiplas resoluções para envio e renderização progressivos: enviar os modelos completos apenas daqueles objetos visíveis à máquina do cliente sob demanda pode ainda causar uma possível longa pausa no walkthrough. Ao invés disso, o sistema proposto codifica cada modelo de objeto como uma malha progressiva. Durante a execução, a distância entre os centros do escopo do observador e o escopo do objeto determina a resolução da malha progressiva necessária à máquina do cliente. Como a visibilidade de um objeto geralmente muda apenas um pouco entre um quadro e outro, apenas um pequeno número de registros progressivos precisam ser transmitidos ao cliente entre quadros consecutivos.
	
	\item Caching com múltiplas resoluções: foi desenvolvida uma técnica de caching para permitir uma granularidade fina de caching e substituição de objetos. Um mecanismo de caching permite que um cliente utilize sua memória e armazenamento local para guardar objetos que estão visíveis e que provavelmente continuarão visíveis num futuro próximo. Um cache local também suporta um certo grau de operação desconectada quando a Internet estiver temporariamente indisponível.
	
	\item Prefetching: um mecanismo de prefetching permite que um cliente prediga objetos que provavelmente estarão visíveis no futuro e os obtenha antecipadamente para melhorar o tempo de resposta. Considerando o fato de que a maior parte dos usuários estaria utilizando um PC equipado com um mouse 2D para navegação 3D, foi desenvolvido um método de previsão de movimento para predizer o futuro movimento do observador, baseado no padrão de movimento do mouse 2D.
	
\end{itemize}

%2
\section{Arquitetura paralela do CyberWalk}

\begin{figure}
 \centering
 \includegraphics[width=0.8\textwidth]{imagens/NG_architecture.JPG}
 \caption{Arquitetura paralela do CyberWalk}
 \label{fig:C}
\end{figure}

Para tratar o problema da sobrecarga do servidor com um grande número de clientes, o CyberWalk emprega uma arquitetura paralela de múltiplos servidores. Uma arquitetura paralela é fundamentalmente uma arquitetura share-nothing (não compartilha nada). Como ilustrado na Figura \ref{fig:C}, cada servidor gerencia sua própria memória e repositório local de objetos virtuais. Em arquiteturas share-nothing tradicionais, um dos servidores está frequentemente dedicado a ser um coordenador, que tem conhecimento completo dos dados gerenciados em cada um dos outros servidores. O coordenador recebe uma requisição de um cliente e a encaminha ao servidor que gerencia os dados que foram requisitados. No entanto, o coordenador poderia rapidamente tornar-se um gargalo quando a freqüência de submissão das requisições se tornar alta. Há outro problema com tal arquitetura: quaisquer mudanças feitas por um cliente podem ter que executar vários passos na comunicação da rede, até que o cliente receba uma resposta. Esse atraso extra pode afetar seriamente a interatividade do sistema, especialmente se os servidores não estiverem localizados na mesma rede local.

No CyberWalk, o ambiente virtual inteiro é particionado em regiões, formando uma matriz bidimensional. Objetos virtuais dentro de uma região serão gerenciados apenas por um servidor. Cada servidor estará respondendo pedidos apenas dos clientes que estiverem explorando objetos dentro da região por ele gerenciada. Sob circunstâncias normais, quando um observador V está explorando a região R1, o servidor de R1, S1, será responsável por responder a todos os pedidos de V. Quando V estiver cruzando a fronteira entre R1 e R2, ou seja, quando o escopo de observador de V tocar a fronteira de R2, os servidores de todas as regiões envolvidas estarão respondendo pedidos do observador pois ester poderia visualizar objetos dentro de todas essas regiões. Em outras palavras, tanto S1 como S2 estarão servindo pedidos de V. Para conseguir isto, quando o escopo de observador de V tocar a fronteira de R2, S1 enviará uma mensagem a S2 no formato <idv, locv, vv>, onde idv é o ID de V, que é inerentemente o endereço IP do cliente, locv é a localização de V, e vv é a direção de visualização de V. Uma vez que S2 recebeu tal mensagem de S1, ele pode determinar quais objetos em R2 estão visíveis a V e transmitir os correspondentes registros progressivos e/ou malhas base diretamente a ele. Este, então, irá manter canais de comunicação direta tanto com S1 quanto com S2, enquanto seu escopo de observador se sobrepuser a ambas regiões. Quando eventualmente mover-se para a região R2, V irá parar de se comunicar com S1 e irá comunicar-se apenas com S2.

Quando o número de clientes em uma determinada região tiver aumentado substancialmente, a um ponto em que a diminuição da performance é perceptível pelo observador, aquela região deve ser particionada e a nova partição deve ser alocada a um servidor vizinho menos ocupado.

Como mostrado na Figura \ref{fig:C}, um processo, chamado de LoC (coletor de carregamento), é dedicado a coletar a informação de carregamento de cada servidor. Cada um deles irá periodicamente informar ao processo LoC a respeito de seu então nível de carga, e há a flexibilidade de determinar quão frequente será o envio desta informação ao coletor. Quanto mais rapidamente a carga de um servidor variar, maior será a freqüência de envio de informações ao LoC. Este, assim sendo, possui o mais atualizado conjunto de informações a respeito do carregamento de cada servidor. Quando um servidor está sobrecarregado, ele requisita informações de carregamento de seus vizinhos ao LoC. A partir daí, ele seleciona um de seus vizinhos e - o menos sobrecarregado - para absorver uma porção de sua região.

Para que esta abordagem realmente seja vantajosa, é necessário que:

\begin{enumerate}

	\item Haja um mecanismo de medição do carregamento em cada servidor e um critério que divida a carga de maneira justa e eficiente, de forma que o servidor que a recebeu uma porção do trabalho do servidor sobrecarregado não seja penalizado com carga acima do que pode suportar.
	
	\item Deve ser feito um particionamento do ambiente virtual, levando em conta que algumas áreas do mundo virtual atrairão mais usuários que outras. É necessário, pois, que o particionamento resulte em regiões que possuam cargas semelhantes. Isto seria o particionamento adaptativo de regiões.

\end {enumerate}

%3
\section{Balanceamento de carga adaptativo}

No sistema proposto, o ambiente virtual inteiro é regularmente subdividido em um grande número de células retangulares. Cada célula, Cij, contém um conjunto de objetos, ou seja, $Cij = \{Ocij1, Ocij2, ..., Ocij|Cij|\}$. O ambiente  também é particionado em um conjunto de Nr regiões, ou seja, $ambiente = \{R1, R2, ..., RNr\}$, enquanto cada região contém um número inteiro de células, ou seja, $Ri = \{Ci1, Ci2, ..., Ci|Ri|\}$. A Figura \ref{fig:D} ilustra uma partição de 9 regiões, cada uma contendo 9 células e gerenciada por um servidor.

\begin{figure}
 \centering
 \includegraphics[width=0.8\textwidth]{imagens/NG_partitions.JPG}
 \caption{Particionamento em regiões}
 \label{fig:D}
\end{figure}

Há diversas maneiras de particionar o ambiente virtual em regiões. A mais simples é dividí-lo em regiões iguais. Cada região irá cobrir o mesmo tamanho geográfico do mundo virtual e conter o mesmo número de células, ou seja, $\forall$ Ri, Rj $\in$ ambiente, |Ri| = |Rj|. No entanto, como os objetos virtuais podem não ser distribuídos uniformemente dentro do ambiente, algumas regiões podem conter mais objetos do que outras. Isso poderia ser tratado particionando o ambiente com base na "densidade de objetos", que é o número de objetos por célula no mundo virtual. Neste esquema, cada região irá conter aproximadamente o mesmo número de objetos, ou seja, $\sum_{k=1}^{|R_i|}|c_{i,k}| \approx \sum_{l=1}^{|R_j|}|c_{j,l}| \forall R_i, R_j \in \mathsf{VE}$. No entanto, cada região pode cobrir um tamanho geográfico diferente e, portanto, conter um número diferente de células. Esta abordagem busca uma carga uniforme entre todos os servidores, garantindo que irão tratar o mesmo número de objetos. Isto é baseado no pressuposto de que todos os objetos tem graus de interesse semelhante entre os observadores e, portanto, uma probabilidade próxima de serem acessados. Na prática, no entanto, algumas áreas e objetos atraem mais observadores que outras. Assim, não necessariamente o esquema baseado em densidade de objetos irá garantir uma distribuição uniforme de carga entre os servidores. Por este motivo, os autores propuseram um particionamente em regiões adaptativo, de acordo com a carga entre os diferentes servidores.

%3.1
\subsection{O esquema de particionamento adaptativo em regiões}

No início do sistema, o ambiente virtual é divido sem levar em conta a carga dos servidores, pois não havia clientes conectados até então. Por isso, o particionamento inicial do ambiente é ou em regiões de tamanho igual, ou de número de densidade de objetos igual. Cada uma é atribuída a um servidor Si, que possui um indicador de carga wi. Quando wi indica que Si está sobrecarregado, a região Ri - gerenciada por Si - deve ser particionada. Um vizinho de Si com a menor carga será selecionado e a nova partição será entregue a ele.

Para determinar se uma região precisa ser particionada, cada servidor Si irá continuamente monitorar seu indicador wi, mantendo duas janelas de monitoração, chamadas janela de curta duração Ws(Si) e janela de longa duração Wl(Si). A primeira tem o objetivo de detectar repentinas chegadas de carga a Si, seja por congestionamento da rede, aumento repentino do interesse em Ri ou algum outro motivo. A janela de longa duração tem o objetivo de detectar sobrecarga contínua de Si.

Cada uma das janelas de monitoração avalia a carga do servidor baseado em dois fatores: comunicação e processamento. Se algum destes chegar a um nível acima de determinado limite, seja na janela de curta ou de longa duração, é disparado um particionamento da região gerenciada por aquele servidor. Tais limites podem ser pré fixados ou calculados dinamicamente, o que requeriria um algoritmo para cálculo dos mesmos.

Os autores sugerem um algoritmo para executar o particionamento de uma região Ri, de forma a reduzir a carga sobre o servidor Si dela encarregado:

\begin{enumerate}

	\item Quando Si estiver sobrecarregado, ele entra em contato com o LoC, de modo a obter informações referentes à atual carga de seus vizinhos - um servidor vizinho de Si é aquele que gerencia uma área adjacente a Ri.
	
	\item Após receber as informações a respeito de seus vizinhos, Si seleciona dentre les aquele que tiver a menor carga, que será chamado de St. Este receberá parte da carga de Si. Isto é feito particionando Ri e alocando a nova partição para St.
	
	\item Si irá determinar a carga alvo, que é a quantidade de carga que deverá ser transferida para St.
	
	\item O particionamento ocorre no nível das células. Cada servidor manterá um indicador de carga para cada célula. O particionamento de uma região Ri é conseguido desalocando uma ou mais das células Cij da fronteira desta região, e agregando-as à região Rt, gerenciada por St: $Ri \leftarrow Ri - \{Cij\}$ e $Rt \leftarrow Rt \cup \{Cij\}$. Uma célula da fronteira de uma região Ri é aquela adjacente a uma célula pertencente a outra região, Rj. Por exemplo, na Figura \ref{fig:D}, C4,3 é uma célula de fronteira de R4 e será agregada a R5.
	
	\item Como muito provavelmente haverá mais de uma célula de fronteira, aquela com o indicador de carga mais próximo da carga alvo será alocada para St primeiro.

\end{enumerate}

A razão para que a transferência de carga de um servidor seja apenas para seus vizinhos, ao invés de servidores arbitrários, é que quando o escopo de observador cruzar a fronteira entre dois servidores, ambos serão responsáveis por transferir modelos de objetos para o observador. Se um servidor descarregar a nova partição que criou em qualquer outro servidor, o observador poderá ter que se comunicar com um grande número de servidores, aumentando significativamente o sobrecusto de comunicação. Na figura D, se o servidor S4 descarregar as células C4,3, C4,6 e C4,9 em três servidores aleatórios, eles poderão ser diferentes. Quando um observador cujo escopo atravessar a fronteira entre as regiões R4,1 e R4,2, terá que se comunicar com vários servidores para que possa receber modelos de objetos dentro das três células. Por outro lado, se a transferência de carga é feita apenas para servidores vizinhos, todas essas três células serão descarregadas para o servidor S5. O observador terá apenas que se comunicar com dois servidores quando seu escopo atravessar a fronteira.

%3.2
\subsection{Alocação de sub-região}

Quando um servidor está sobrecarregado, suas células de fronteira são transferidas para o mesmo servidor de destino até que a carga de trabalho do primeiro esteja abaixo de um determinado valor. Na figura D, se a transferência da célula C4,9 para R5 não pode reduzir a carga de trabalho da região R4,1 de forma que esteja abaixo do valor pré-determinado, outras células de fronteira, como C4,3 e C4,6, poderão também ser transferidas. Um problema em potencial, chamado de balanceamento de carga em cascata, pode ocorrer. Uma vez que um servidor vizinho é identificado como servidor alvo, ele recebe as células do servidor sobrecarregando, podendo ele mesmo ficar sobrecarregado, o que dispararia um novo processo de balanceamento.

Quando o efeito em cascata acontece enquanto o servidor Si descarrega uma nova sub-região a um servidor St, é possível que St identifique Si como servidor alvo e isso gere um efeito de troca contínua de carga. Desta forma, é necessário garantir que St não irá selecionar Si como servidor alvo imediatamente após Si ter lhe entregue uma partição.

%4
\section{Avaliação do trabalho}

Uma forte limitação da proposta de \cite{ng2002msa} é que se considera o cenário de rede local para a rede de servidores. Tal premissa implica que haja pouca latência entre os servidores e a largura de banda disponível para intercomunicação dos mesmos seja a menor possível. Tais pressupostos não funcionam se é considerado um sistema distribuído geograficamente, em que os links entre as máquinas servidoras pode ser mais limitado.

No entanto, os autores propõem algumas soluções interessantes: uma delas é a utilização de diferentes resoluções para os dados a serem transmitidos, divididas em níveis de resolução. Isso é bastante útil para prover qualidade de serviço adaptativa aos recursos disponíveis na rede: se há largura de banda disponível, envie o máximo de níveis de resolução possível. Caso contrário, envie apenas aqueles que for possível.

Outra idéia interessante é a do pre-fetch. Apesar de ser um conceito antigo e simples, a aplicação em jogos MMG pode ser bastante útil: clientes começam a comunicar-se, se provavelmente irão se ver num futuro próximo (o "provavelmente"{} pode ser calculado através de alguma heurística).

Por último, é deixado em aberto qual será o limite de subdivisão das regiões. A proposta de um novo método para calcular tal limite pode ser um trabalho interessante a desenvolver.