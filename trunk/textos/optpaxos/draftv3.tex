\documentclass[times, 10pt]{article} 
%\documentclass[times, 10pt,twocolumn]{article} 
%\usepackage[noend]{distribalgo}
\usepackage{algorithm}
%\usepackage{times}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{color}
\usepackage{amssymb}
\usepackage[noend]{distribalgo}
\usepackage[draft]{fixme}
\usepackage[hmargin=2.5cm,vmargin=2.2cm]{geometry}


\begin{document}

\newcommand{\mv}[1]{\ensuremath{\operatorname{\mathit{#1}}}}
\definecolor{dark}{gray}{.6}
\newcommand{\bc}[1]{\textcolor{dark}{#1}}
\newtheorem{lems}{Lemma}
\newtheorem{props}{Proposition}
\newtheorem{thms}{Theorem}
\newtheorem{defs}{Definition}
\newtheorem{obs}{Observation}

\newcommand{\code}[1]{\texttt{\small{\textbf{#1}}}}

\newcommand{\blankline}{\vspace{4 mm}}
\newcommand{\cms}{\mbox{multicast}}
\newcommand{\cmd}{\mbox{deliver}}
\newcommand{\cmdel}[1]{\mbox{\cmd({#1})}}
\newcommand{\cmsend}[1]{\mbox{\cms({#1})}}
\newcommand{\tconsm}{T_{cons}}
\newcommand{\tcons}{\mbox{$\tconsm$}}
\newcommand{\opt}{\mbox{opt-deliver}}
\newcommand{\cons}{\mbox{deliver}}
\newcommand{\rmc}{\mbox{fifor-mcast}}
\newcommand{\rmd}{\mbox{fifor-deliver}}
\newcommand{\optdel}[1]{\mbox{\opt({#1})}}
\newcommand{\consdel}[1]{\mbox{\cons({#1})}}
\newcommand{\rmcast}[2]{\mbox{\rmc({#1},{#2})}}
\newcommand{\rmdel}[1]{\mbox{\rmd({#1})}}
 

\title{A Quasi-Genuine FIFO Total Order Multicast Primitive}

%\author{
%xxx\\
%University \\ Country\\
%\and
%xxx\\
%University \\ Country\\
%\and
% ...
%}

\maketitle

\begin{abstract}


\end{abstract}

\section{Introduction}
\label{sec:intro}

Some multicast primitives have been devised in such a way that multicast groups needed to communicate only when they had messages to exchange. These multicast primitives are called \emph{genuine}. We argue that it is possible, however, to devise a multicast primitive that, although not genuine, can make use of some knowledge given by the application to figure out which groups \emph{can} communicate with each other. With such knowledge, although message exchanges take place even when there is no application message being transmitted between some two groups, such exchanges happen only when they are able to send to -- or receive from -- one another. The primitive that makes use of such property we call \emph{quasi-genuine}. 

\section{System model and definitions}
\label{sec:model}

We assume a system composed of processes, regardless of how they are distributed -- they may consist from local processes in the same device to nodes distributed over a large geographical area. Processes may fail by crashing and stoping, but they do not experience arbitrary behavior (i.e., no Byzantine failures). A correct process is operational ``forever" and can reliably exchange messages with other correct processes. This assumption is only needed to prove liveness properties about the system. In practice, ``forever" means long enough for one instance of \emph{consensus} (defined below) to terminate. Every process $p$ in the system belongs to one group, denoted by $group(p)$, which is a non-empty set of processes. We assume that consensus is solvable within each group.

Communication is done by message passing. %, through the primitives \emph{send}$(p,m)$ and \emph{receive}$(m)$, where $p$ is the addressee of message $m$.
Messages can be lost but not corrupted. If a message is repeatedly resubmitted to a correct process, it is eventually received. In particular, being $m$ a message and $gs$ a set of groups, we also use a \textit{\rmc{}$(m,gs)$} primitive, which is a FIFO reliable multicast primitive that sends message $m$ to every process of each group in $gs$. If no failures occur, the delivery -- \textit{\rmd} -- of the messages sent with this primitive is done in FIFO order and in one communication step. By \emph{communication step}, we mean the time needed for a message, after being sent by a process, to be delivered at another process. However, there are no bounds on this time, for actions to be executed or for the drift between the clocks of the different processes, which implies that the considered system is asynchronous.

\subsection{Consensus}

An important part of this work relies on the use of consensus to ensure that processes will agree upon which messages are delivered, and upon the order in which such messages are delivered. In the consensus problem, processes propose values and must reach agreement on the value decided. Uniform consensus is defined by the primitives \textit{Propose($v$)} and \textit{Decide($v$)} and satisfies the following properties \cite{hadzilacos1993ftb}, which we adapted to consider that each consensus is achieved within some group:

\textit{Uniform integrity}: if process $p$ decides $v$, then $v$ was previously proposed by some process of $group(p)$.

\textit{Uniform agreement}: if process $p$ decides $v$, then all correct processes from $group(p)$ eventually decide $v$.

\textit{Termination}: every correct process of $group(p)$ eventually decides exactly one value.

Many different consensus instances may be executed in the same group, leading to several different values being agreed upon. To distinguish the different instances of consensus run within the same group, we assign to each one of them an unique identifier. Therefore, to propose a value $v$ in a consensus instance of id $k$, a process  $p$ executes \textit{Propose($k$,$v$)}. When such consensus is decided, \textit{Decide($k$,$v'$)} is called back at $p$, letting $p$ know that the value decided at the instance $k$ was $v'$, which may be equal to $v$ or to something else proposed by some other process of $group(p)$ for instance $k$.

Although we are considering an asynchronous system, where it is impossible to guarantee the termination of consensus \cite{fischer1985idc}, some assumptions can be made regarding the maximum message transmission delay and the existence of a leader in the group. As assuming that the processes know the maximum transmission delay, the considered system model is no longer syncronous, but `partially synchronous'. In the section \ref{sec:paxos}, such assumptions are better detailed.

\subsection{Quasi-genuine multicast}

%Our protocols ensure safety under both asynchronous and synchronous execution periods. The FLP impossibility result~\cite{fischer1985idc} states that under asynchronous assumptions consensus cannot be both safe and live. We thus assume that the system is initially asynchronous and eventually becomes synchronous. The time when the system becomes synchronous is called the \emph{Global Stabilization Time (GST)}~\cite{dwork1988cpp}, and it is unknown to the nodes.



%A game is composed of a set of objects. The game state is defined by the individual states of each one of its objects. We assume that the game objects are partitioned among different servers. Since objects have a location in the game, one way to perform this partitioning is by zoning the virtual world of the game. Each partition consists of a set of objects of the game and the server responsible for them is their \emph{coordinator}. As partitions represent physical regions in the game world, we define \emph{neighbor} regions as those which share a border with each other. We consider that each server is replicated, thus forming several groups which consist of the coordinator and its replicas. Therefore, for each region of the game world, there is a group assigned to it. This way, a group is said to coordinate an object when the group's coordinator is the coordinator for that object. Finally, groups are called neighbors when they are assigned to neighbor regions. From now on, the word `server' will be used for any kind of server, be it a coordinator or a replica.

%Each player may send his command to one of the servers -- which might not be the group's coordinator, if that provides a lower delay between the issuing of a command and its delivery. In the case of avatar based virtual environments, and as an avatar is usually also an object, the server to which a player is connected belongs to the group of his avatar's coordinator. A command $C = \{ c_1, c_2, ... \}$ is composed of one or more subcommands, one subcommand per object it affects. We refer to the set of objects affected by command $C$ as $obj(C)$. Also, we refer to the objects coordinated by a server $S$ as $obj(S)$. Finally, we define $obj(C,S)$ = \{$o$ : $o \in obj(C)$ and $o \in obj(S)$\}.

%Each object has its own command stream. When a command affects more than one object, it must be inserted in the command stream of all the objects it affects.

%Our consistency criterion is ``eventual linearizability". (I'm not sure this is indeed what we want and how to define it, but we do need some consistency criterion...)


%In order to guarantee that commands are executed properly by servers, theywe define the following order requirement.
% 
%Let $G =(V,E)$ be a graph where the set $V$ of vertices contains all game commands and $E$ contains edge $C_i \rightarrow C_j$ if subcommand $c_x \in C_i$ is executed before subcommand $c_y \in C_j$. The order requirement states that $G$ is acyclic. In other words, if two commands affect common objects, their subcommands must be executed in the same order.
%
%Our goal is to design ordering protocols with low latency. Two aspects affect latency: (a)~the number of communication steps needed to ensure that subcommands can be properly executed in the absence of contention and (b)~possible slowdowns due to contention. We illustrate these aspects in the following section.
%
%To each partition, a group of servers is assigned, and they are responsible for storing and managing the state of those objects. One of them is a coordinator (or region manager, if one considers partitions as regions) and the rest of the group is formed by replicas, whose purpose is to provide fault tolerance.



%\section{Protocol}

%To ensure reliability despite server crashes, each server is replicated using state-machine replication, implemented with consensus (e.g. Paxos \cite{lamport1998ptp}). Each player sends his commands to the server to which he is connected, which then proposes that command in a consensus instance. Each command is assigned a timestamp and executed against objects in timestamp order. We implement this by using a logical clock in each server group. Guaranteeing that the same set of commands is executed by the respective affected objects in the same order provides the level of consistency we are seeking. Therefore, the challenge is how to assign timestamps to commands such that consistency is not violated and commands are not discarded due to stale timestamp values.

%However, providing such level of consistency may prove to be costly in an MMOG context, since there may be several communication steps between the sending of a command and its atomic delivery. For this reason, we use a primitive we call quasi-genuine global fifo total order multicast, which is described in section \ref{sec:quasi}.

%\section{Quasi-Genuine FIFO Total Order Multicast}
%\label{sec:quasi}

%To reduce the time needed to deliver a message, we use a multicast primitive which delivers messages optmistically, based on the time when they are created in a sender. This \emph{optimistic} delivery, although not guaranteeing that all replicas will receive all messages, is designed to have a fairly low latency, counting from when each message is sent until it is delivered.

%The final -- conservative, fault tolerant, but costly in terms of communication steps for each message -- delivery order should be as close as possible to the optimistic one, so that no rollbacks would be deemed necessary. To explain how this works, we first should understand the idea behind the optimistic delivery. Also, we must define what ``quasi-genuine'' and ``global FIFO'' means.

\textbf{Genuine} multicast protocols are those where two multicast groups only communicate with each other when one has some message to send to the other. A \textbf{quasi-genuine} multicast protocol assumes that: 

\begin{center}
\emph{A1: every group knows from which other groups a multicast message can possibly arrive, and to which other groups it can send a multicast message.}
\end{center}

In a quasi-genuine multicast protocol, different groups communicate with each other even if there is no message to be sent from one to the other, but, from \emph{A1}, there is no need for a group $g_i$ to communicate with some other group $g_j$ which cannot send messages to $g_i$, or receive messages from $g_i$\footnote{This relation may even be asymmetric: it could be possible to send a message from group $g_i$ to $g_j$, but not in the opposite direction. In this case, in a protocol where a group is blocked waiting for possible messages from other groups, $g_j$ may block its delivery of messages waiting for some kind of ``clearance'' from $g_i$, but $g_i$ will never block waiting for messages from $g_j$.}. This information may be given by the application which is making use of such protocol, so, although not genuine, a quasi-genuine protocol does not imply that each group has to keep sending messages to every other group.

We define $sendersTo(G)$ as the set of other groups which are able to send a message to $G$. Also, we define $receiversFrom(G)$ as the set of other groups who are able to receive a message from $G$.

%\subsubsection{Optimistic delivery}

%Even when ordering commands relevant to only one group, a significant number of communication steps is required: player to replica; replica to coordinator; consensus (two communication steps in the case of Paxos, when having the coordinator as the leader, using ballot reservation, each acceptor sending phase 2b messages to all other acceptors and assuming a tolerable number of failures) and, once consensus is achieved, each replica can put the command in the delivery queue and send it to each player. That sums up to five communication steps. On a geographically distributed scenario, this number of communication steps may be prohibitive for the ``playability'' of a vast number of online games.

%In order to mitigate this problem, we propose a protocol for \emph{optimistic ordering and delivery} of the commands, which is supposed to run in parallel with the protocol described in the previous section, which from now on will be called \emph{conservative ordering and delivery}. The optimistic order and delivery are correct if they include all the messages delivered with the conservative one and if they are delivered in the same order. Also, each object has an optimistic state and a conservative state. When a command is conservatively delivered to an object, its conservative state is updated, and this state is certainly consistent -- given the assumptions we have made about the system. Likewise, when a command is optimistically delivered, its optimistic state is updated.

%The optimistic ordering and delivery is supposed to be much faster than the conservative one. Assuming that it will be, and if the optimistic delivery order is always correct -- which means that it correctly predicted the conservative delivery order --, then the objects will always have a valid state within much fewer communication steps, counting from when each command $C$ was issued to when it is delivered and applied to $obj(C)$.

%The basic idea of the optimistic ordering is the following: assuming that the processes have a synchronized clock\footnote{We don't require here perfectly synchronized clocks, as the optimistic protocol tolerates mistakes by its very definition. We only need clocks which are synchronized enough, so that our delivery order prediction succeeds and matches the conservative delivery order.}, whenever a process $p$ receives a message $m$ from a client, it immediately applies a timestamp $ts$ to it, which consists simply of the current value of $p$'s wallclock, $now$. Therefore, $m.ts=now$. A wait window of length $w(p)$ is considered, where $w(p)$ is defined as the highest value of the estimated communication delay plus the wallclock deviation between the process $p$ and any of the other processes in its group $G$ or in any of the groups in $sendersTo(G)$.

%More formally, let $\delta(p',p)$ be the maximum time for a message from $p'$ to arrive at $p$. Also, let $\epsilon(p',p)$ be the deviation between the wallclocks of $p$ and $p'$. The value of $w(p)$ is estimated as the maximum value of \mbox{$(\delta(p',p) + \epsilon(p',p))$} for every $p'$ in $G = group(p)$ or in some group of $sendersTo(G)$.

%After applying the timestamp to $m$, the process $p$ immediately forwards it to all the other processes involved, including those in other groups. A process is involved with a message $m$ when it is one of its destinations, which can be inferred from $m.dst$. Then, $p$ puts $m$ in an \mbox{\textit{optPending}} list, where it stays until $now>m.ts+w(p)$, which means that $m$ has been in that list for a time longer than the defined wait window. In the meantime, other messages, sent from other processes, may have been received and also inserted in that list, always sorting by their timestamps.

%If $w(p)$ has been correctly estimated, and no message was lost, than all the messages that were supposed to be delivered before $m$ have necessarily been received already. If the same has occurred for all the processes, then all of them have received all the messages, and can deliver them in the same order of $ts$.

%To avoid out-of-order deliveries, if when $m$ arrives at $p$, \mbox{$m.ts < now - w(p)$}, wich means that $m$ arrived too late, the message $m$ is simply discarded by $p$, since another message $m' : m'.ts > m.ts$ may have already been delivered\footnote{We could make this in a way such that $m$ is only discarded by $p$ if, in fact, there was a delivered message $m' : m'.ts > m.ts$. If there was no such message, $m$ could still be delivered without violating the order we defined.}.

%However, even if the optimistic order is the same for all the processes, it won't be valid if the conservative order is different from it. For that reason, we devised a way to make the conservative delivery order as close as possible to the optimistic one.

\section{Quasi-genuine FIFO multicast}

In this section, we present a quasi-genuine multicast protocol which is able to deliver messages in three communication steps when some assumptions hold. Also, an optimistic delivery done within one single communication step is performed; if the optimistic assumption (defined later in this text) holds, such delivery will match the final conservative delivery. If there are mismatches, the application will be responsible for taking action to correct it -- i.e. rolling back its state, if it has been changed based on the optimistic delivery.

We want the messages to be delivered according to their sending time from their sources, which is the FIFO order. As every two messages which are delivered in different groups should be delivered in the same order in these groups, we need total order. For the formal definition of the properties of the algorithm, assuming a crash-stop model, we have:

\textbf{Uniform Validity}: if a process \cms{}s $m$, then one of the correct processes that is a destination of $m$ eventually \cons{}s $m$.

\textbf{Uniform Integrity}: for any message $m$, every correct process $p$ \cons{}s $m$ at most once, and only if some process executed \cmsend{$m$} and $p$ is one of $m$'s destinations.

\textbf{Uniform Agreement}: if a process \cons{}s $m$, then every correct process that is a destination of $m$ also \cons{}s $m$.

\textbf{Uniform Total Order}: if processes $p$ and $p'$ both \cons\ $m$ and $m'$, then $p$ \cons{}s $m$ before $m'$ if and only if $p'$ \cons{}s $m$ before $m'$.

\textbf{FIFO Order}: if a correct process \cms{}s $m$ before it \cms{}s $m'$, then no correct process that is a destination of both $m$ and $m'$ \cons{}s $m'$, unless it has previously \cons{}ed  $m$.
 
%Instead of having the conservative delivery done completely independently from the optimistic one, we can actually use the latter as a hint for the final delivery order. Since the optimistic delivery should be fast when compared to the conservative one, waiting for it should not decrease the system performance significantly. Also, if we wait a short period longer, we can avoid a rollback later caused by mismatches between the two delivery orders, which is not desirable. The basic idea is, then, to pick the optimistic delivery order seen at the processes of each group.

%The complicating factor is the possibility of a command affecting the state of objects in more than one group. So, all involved groups must somehow agree regarding the delivery order of these commands. However, as in most MMOGs objects interact only with other objects which are nearby, we can exploit the fact that the groups addressed by a single command are usually neighbors. We do this by defining \emph{barriers} for multicast, such that $barrier(G_{send},G_{recv})$ = $t$ means that the group $G_{send}$ promised that no commands with timestamp lower than $t$ would be sent to group $G_{recv}$ anymore. When a server $S$ has received all the barrier values from its neighbours, and they are all greater than a value $t$, then $S$ knows that no more commands are coming from other groups and that, once the local ordering is done, all the commands with timestamp up to $t$ can be conservatively delivered. Besides, a barrier is sent along with the bundle of all messages with timestamp greater than the last previous barrier sent from $G_{send}$ to $G_{recv}$, so that when a server has received a barrier from a group, it means that it knows all the messages sent by that group until the time value stored in that barrier.

In section \ref{sec:baseline}, we present a minimalistic version of the algorithm, which describes its basic operation, without any optimistic assumptions. The assumptions and optimizations that lead to a conservative delivery within three communication steps, with an optimistic delivery within one single communication step, are presented in sections \ref{sec:liveness} to \ref{sec:paxos}. In section \ref{sec:discard}, we discuss the possibility of reducing the number of rollbacks by means of discarding messages -- and thus not always ensuring liveness.

\subsection{Baseline algorithm}
\label{sec:baseline}

Each message $m$ has a source group $m.src$, a set of destination groups $m.dst$ and a timestamp $m.ts$. Note that, by abuse of notation, we have `process \mbox{$p \in m.dst$'} instead of `\mbox{$\exists$ group $G \in m.dst : \text{process }p \in G$'}. The total order delivery of messages in a group can be solved by using consensus. Each consensus instance agrees upon some message set as the next ones to be delivered -- messages within the same set are told apart by the timestamp $m.ts$ applied by the process which created them; to solve timestamp collisions, the unique id of the sender process can be used. If processes send messages to each other using FIFO reliable channels, and after receival, messages are proposed via consensus in the order in which they are received, the FIFO delivery order is ensured.

The complicating factor is the possibility of a message having at least one destination group different from its source group. So, all involved groups must somehow agree regarding the delivery order of these messages. However, from assumption \emph{A1}, each group knows which other groups it could send messages to -- or receive messages from. We can use this by defining \emph{barriers} for multicast, such that \mbox{$barrier(G_{send},G_{recv}) = t$} means that the group $G_{send}$ promised that it would send no more messages with a timestamp lower than or equal to $t$ to group $G_{recv}$. We have defined that $sendersTo(G) =$ \mbox{$\{G' \neq G : G'\text{ is able to send a message to }G\}$}. When a process $p$, from group $G$, has received all the barrier values from all the groups in $sendersTo(G)$, and they are all greater than a value $t$, then $p$ knows that no more messages with timestamp lower than $t$ are coming from other groups and that, once the local ordering (the ordering of messages originated in $G$) is done, all the pending messages with timestamp up to $t$ can be delivered. Besides, a barrier is sent along with the bundle of all messages with timestamp greater than the last previous barrier sent from $G_{send}$ to $G_{recv}$, so that when a process has received a barrier from a group, it means that it knows all the messages sent by that group until the time value stored in that barrier.

As mentioned before, we use consensus to deliver messages. Consider that each consensus instance $I$ from each group $I.grp$ receives a monotonically increasing unique integer identifier, without gaps, that is, for any two instances $I_i$ and $I_k$, such that $I_i.grp = I_k.grp$, if $I_i.id + 1 < I_k.id$, there is necessarily an instance $I_j : I_i.grp = I_j.grp = I_k.grp \wedge I_i.id < I_j.id < I_k.id$. No group runs two consensus instances in parallel: before initiating an instance of id $k+1$ each process checks whether the instance $k$ has already been decided, so some messages may wait to be proposed. When a process is allowed to initiate a new consensus instance, the pending messages may be proposed as a batch.%Consider also that each message $m$ sent by a group $G$ has a group sequence number $m.gs$ related to the order in which it is conservatively delivered, relatively to other messages also sent by $G$. As messages are conservatively delivered via consensus, the group sequence number of a message is equal to the id of the instance in which it was decided, that is, $m.gs = i \Leftrightarrow \exists I : I.id = i \wedge I.grp = m.src \wedge I.val = m$, where $I.val$ is the value decided by the instance $I$.

Since we are using the timestamp given at the creation of a message by its sender, it might occur that, after a message $m'$ has been proposed by a process $p$ in some consensus instance, a message $m : m.ts < m'.ts$ arrives at $p$. If $m$ is delivered with its original timestamp, the timestamp order is violated and there is no sense in using these timestamps for barriers. There are two possible solutions for that: either the message is simply discarded, and no violation to the timestamp order takes place, or we can change the timestamp of $m$ to something greater than the timestamp of $m'$. If uniform validity is to be ensured, discarding $m$ is not an option. As we need, then, to change the value of $m.ts$, two things should be noted: first, as we are using reliable FIFO channels, then the process which sent $m$ is different than that which sent $m'$, so inverting their order does not violate FIFO; finally, increasing a message timestamp must be done with caution, so that messages created by different groups at the same time have roughly the same timestamp and the barrier mechanism is efficient -- if a long sequence of messages have their timestamps increased, the last one of them may wait a long time until all the barriers required to deliver it have arrived.

% To allow for the timestamp of messages to be increased and still have them delivered as soon as possible, their timestamps are increased by an infinitesimal value. For that reason, each timestamp value will consist of a real-time clock value, and a sequence value, which is used only when messages need to have their timestamps changed. Also, to solve timestamp clashes, the id of the process which sent the message is also used. Therefore, we have that $m.ts = (rtc, seq, p_{id})$, where $rtc$ is some value related to the wallclock (real-time clock) of a process, $seq$ is a sequence number to define an order between messages with the same $rtc$ value and $p_{id}$ is the id of the process which sent $m$. Therefore, we have:
% \begin{align*}
% m.ts < m.ts~&\Leftrightarrow~m.ts.rtc < m'.ts.rtc\\
% &\vee (m.ts.rtc = m'.ts.rtc \wedge m.ts.seq < m'.ts.seq)\\
% &\vee (m.ts.rtc = m'.ts.rtc \wedge m.ts.seq = m'.ts.seq \wedge m.ts.p_{id} < m'.ts.p_{id})
% \end{align*}

To allow for the timestamp of messages to be increased and still have these messages delivered as soon as possible, their timestamps are increased by an infinitesimal value. For that reason, each timestamp value will consist of a real-time clock value, and a sequence value, which is used only when messages need to have their timestamps changed. Therefore, we have that $m.ts = (rtc, seq)$, where $rtc$ is some value related to real-time clock of a process and $seq$ is a sequence number to define an order between messages with the same $rtc$. Then we have:

\begin{align*}
m.ts < m'.ts \Longleftrightarrow m.ts.rtc < m'.ts.rtc \vee (m.ts.rtc = m'.ts.rtc \wedge m.ts.seq < m'.ts.seq)\\
%&\vee (m.ts.rtc = m'.ts.rtc \wedge m.ts.seq = m'.ts.seq \wedge m.ts.p_{id} < m'.ts.p_{id})
\end{align*}

The way each process $p$ of a group $G$ handles each message $m$ will depend on whether $G$ is the source group of $m$:

\begin{itemize}
  \item If $G$ is the source of $m$:
  
  When some process in $G$ \cms{}s $m$, it is first \rmc{} to the other processes of $G$. Then, when $m$ is \rmd{}ed at a process $p \in G$, $p$ checks whether the latest consensus instance $I_{k}$ in which it participated, or is trying to start, has already been decided -- if not, $p$ enqueues $m$ in a $propPending$ queue as the next message to be proposed by it in the consensus instance $I_{k+1}$, so other tasks can keep being executed. Then, once $I_{k}$ has been decided, $p$ may start a new instance. Before that, all messages in $propPending$ that have been already decided are discarded from $propPending$. The rest is proposed as a batch in $I_{k+1}$.
  
  Once $m$ has been decided, it is not immediately delivered to the application. Instead, $p$ checks whether some message $m' : m'.ts \geq m.ts$ has been decided previously. If that is the case, the value of $m.ts$ is changed to a value greater than the timestamp of any other message previously decided within $G$. Then, $m$ is inserted into a $barPending$ list for later being delivered, which will happen once every group $G'$ in $sendersTo(G)$ has already sent a message $barrier(G',G) = t_b$, such that $t_b \geq m.ts$. Only after that will $p$ know for sure that no message $m'' : m''.ts < m.ts$ will arrive from another group.
  
  After learning that $m$ has been decided, $p$ checks whether there is some other group which is also a destination of $m$. If that is the case, $p$ \rmc{}s $m$ to every \mbox{$p' \in (m.dst \setminus \{G\})$}.

%   
%   In this case, when $m$ is received by $p$, $p$ checks whether the latest consensus instance $I_{k}$ in which it participated, or is trying to start, has already been decided -- if not, $p$ enqueues $m$ in a $propPending$ queue as the next message being proposed by it in the consensus instance $I_{k+1}$, so other tasks can keep being executed. Then, once $I_{k}$ has been decided, $p$ may start a new instance. Before that, all messages in $propPending$ that have been already decided are discarded from $propPending$. The rest is proposed as a batch in $I_{k+1}$. Once $m$ is decided, it is not immediately delivered to the application. Instead, $p$ checks whether some message $m_{prv} : m_{prv}.ts \geq m.ts$ has been decided previously. If that is the case, the value of $m.ts$ is changed to a value greater than the timestamp of any other message previously decided within $G$. Then, $m$ is inserted into a $barPending$ list for later being delivered, which will happen once every group $G'$ in $sendersTo(G)$ has already sent a message $barrier(G',G) = t$, such that $t > m.ts$. This is done because there could be a message $m'$ yet to come from another group $G'$, such that $m'.ts < m.ts$.
% 
%   \item When $m$ is originated in $G$, but it has at least one group other than $G$ as a destination:
%   
%   In this case, when $m$ is received, $p$ tries to initiate a consensus instance within $G$ to decide $m$. If $p$ cannot start the proposal now, $m$ is enqueued in $propPending$ for being proposed later along with other pending messages. Then, once $p$ may start a new instance, all messages in $propPending$ that have been already decided are discarded from $propPending$. The rest is proposed as a batch in the new consensus instance. Once any message $m$ is decided, $p$ checks whether some message $m_{prv} : m_{prv}.ts > m.ts$ has been decided previously. If that is the case, the value of $m.ts$ is changed to a value greater than the timestamp of any other message previously decided within $G$. Then, if $G \in m.dst$, $m$ is inserted in the $barPending$ list. Besides, when $m$ is decided, $p$ sends $m$ to every \mbox{$p' \in (m.dst \setminus \{G\})$}. When $m$ is received by each $p' \in G'$, $p'$ checks whether it has ever inserted $m$ in its own $barPending$ list. If not, $p'$ inserts $m$ into $barPending$ and adjusts $barrier(G, G')$ to $m.ts$. To ensure that, once a message $m$ is received from another group $G$, every message $m' : m'.ts<m.ts$ also from $G$ has already been received, every message is sent through a lossless FIFO channel\footnote{An ordinary TCP connection would be enough to provide such FIFO lossless channel. Here, we use FIFO reliable multicast.}.
  
  \item When $G$ is one of the destinations of $m$, but $m$ was originated in some other group $G'$:
    
  Although every process in $G'$ sends this message, it is done via a FIFO reliable channel, so even if messages are \rmd{}ed twice at $p$, once $m$ is \rmd{}ed, every message $m' : m'.ts < m.ts$ from $G$ has also already been \rmd{}ed. As there may be multiple \rmd{}ies of $m$, only the first one is considered, upon which $m$ is inserted into the $barPending$ list of $p$. Besides, the value of $barrier(G',G)$ is set to $m.ts$, for $p$ knows that no more messages with lower timestamps will arrive from $G'$.
  
\end{itemize}

The messages in the \textit{barPending} list are always sorted in ascending order of their timestamps. When the first message $m$ in the $barPending$ list of a process $p \in G$ is such that $m.ts < barrier(G, G')$ for all $G' \in sendersTo(G)$, then $m$ is \cons{}ed by $p$ to the application as the next message. We claim that this delivery respects the FIFO total order\footnote{Proof needed.}.

%The possibility not covered here is when a message is sent from a group to another one which is not its neighbour. However, it is realistic for this context to assume that objects should be close to each other in the virtual environment to interact and that, as such, this kind of interaction is not supported. Nevertheless, one simple way to provide this kind of support could be by each group waiting for the barriers of every other group in the system, instead of only those of its neighbors.

A more formal description of the protocol is given in Algorithm \ref{algorithm:deliveryminimal}. We consider that three primitives are given: $getTime()$, which returns the current value of the local wallclock; $Propose(k, val)$, which proposes a value $val$ for the consensus instance of id $k$ within its group; and also $Decide(k, val)$, which is called when the consensus instance of id $k$ finishes. $Decide(k, val)$ is called for all the processes of the group that initiated it, when they learn that the value $val$ has been agreed upon in instance of id $k$. For the sake of simplicity, we assume that, for consensus instances within the same group, the values are decided in the same order of the instances id's\footnote{This can be easily done by delaying the callback of $Decide(k, val)$ while there is some unfinished consensus instance of id $k': k' < k$ from the same group.}. Finally, we also use a FIFO reliable multicast primitive \rmcast{$m$}{$groupSet$}, which \rmd{}s $m$ to all the processes in all the groups in $groupSet$ in one communication step, in FIFO order (e.g. the one described in \cite{ufrmcast1delta}).

Moreover, each process $p$ of group $G$ keeps some lists of messages:
\begin{itemize}
  %\item \textit{optPending}, which contains the messages waiting to be \mbox{\textit{\opt{}ed}} (optimistically delivered);
  \item \textit{propPending}, containing the messages waiting to be proposed by $p$;
  \item \textit{barPending}, with the messages ready to be \cons{}ed, but which may be waiting for barriers from the groups in $sendersTo(G)$;
  \item \textit{decided}, which contains the messages that have already been proposed and decided within $group(p)$;
  \item \textit{delivered}, which contains the messages that have been \cons{}ed already.
\end{itemize} 

%; and $gs$, which is $m$'s sequence number relatively to its group of origin. 

Something that must be noticed is that each message $m$ might not have its source group as a destination. Anyway, $m$ still has to be agreed upon in its group of origin $G$, so that its order among other messages from $G$ may be decided and for %$m.gs$ can be decided, and also for 
$m$ to be retrievable even in the presence of failures.% Because of that, to ensure that messages of this kind are also received by $group(p)$'s coordinator $c$, which then initiates the Paxos instance that allows for the conservative delivery of the message in all of its destinations, every message $m$ from $p$ must also be sent to $c$ (l. \ref{algline:sendcoord}). This way, when the clock value at the coordinator $time(c) > w(c) + m.ts$, $c$ will conservatively send $m$ to all the processes in $m.dst$. Finally, to avoid delivering a message $m$ in a group it is not addressed to, before OPT-Delivering it, each process must check whether it is one of $m$'s destinations or not (l. \ref{algline:notinterested}). In l. \ref{algline:sendcoord}, $m$ is sent to the whole group $G$, so that in the case of failure of $G$'s coordinator, it is more likely that the new coordinator will know about the existence of $m$.

\begin{algorithm}
\begin{distribalgo}[1]

\blankline
\INDENT {Initialization}
  \STATE $k \leftarrow 0$, $nextProp \leftarrow 0$, $decided \leftarrow \emptyset$, $delivered \leftarrow \emptyset$, $propPending \leftarrow \emptyset$, $barPending \leftarrow \emptyset$
  \INDENT{\textbf{for all} $G' \in sendersTo(G)$ \textbf{do}}
    \STATE $barrier(G',G) \leftarrow -\infty$ 
  \ENDINDENT
\ENDINDENT 

\blankline
\INDENT{\textit{To} \cms{} \textit{a message $m$}}
  \STATE $m.ts \leftarrow (getTime(),0)$ \label{algline:gettime}
  %\COMMENT{current wallclock value as the timestamp of $m$}
  \STATE \rmcast{$m$}{$\{G\}$} \label{algline:rmlocal}
%  \INDENT{\textbf{for all} $p' \in m.dst \cup \{G\}$ \textbf{do}}
%    \STATE send($p'$, $m$)    
%    \COMMENT{send optimistically $m$ to all involved processes}
%  \ENDINDENT
\ENDINDENT

\blankline
\INDENT{\textit{When} \rmdel{$m'$}}
  \IF{$G = m'.src$}
    \STATE $propPending \leftarrow propPending \cup \{m'\}$ \label{algline:addtoproppending}
  \ELSIF{$m' \notin barPending \wedge m' \notin delivered$} \label{algline:notbptwice}
    \STATE $barPending \leftarrow barPending \cup \{m'\}$ \label{algline:insbp1}
    \STATE $barrier(m'.src,G) \leftarrow m'.ts$ \label{algline:incbar}
  \ENDIF
\ENDINDENT

\blankline
\INDENT{\textit{When $\exists m \in propPending \wedge nextProp = k$}}
%  \STATE $propPending \leftarrow propPending \setminus \{m\}$
%  \IF {$m \notin decided \wedge \nexists m' \in decided: m'.ts > m.ts$}
    \STATE $propPending \leftarrow propPending \setminus decided$%(decided \cup \{m' : \exists m'' \in decided \wedge m'.ts < m''.ts \wedge m' \neq null\})$ 
    \label{algline:removedecided}
    \IF {$propPending \neq \emptyset$}
      \STATE $nextProp \leftarrow k + 1$
      \STATE Propose($k$,$propPending$) \label{algline:propose}
    \ENDIF
%  \ENDIF
\ENDINDENT

\blankline
\INDENT{\textit{When} Decide($k'$,$msgSet$)} \label{algline:decide}
%  \STATE $m.gs \leftarrow k$
  \INDENT{\textbf{while} $\exists m \in msgSet : (\forall m' \in msgSet : m \neq m' \Rightarrow m.ts < m'.ts)$ \textbf{do}} \label{algline:whiledecided}
    \STATE $msgSet \leftarrow msgSet \setminus \{m\}$
    \COMMENT{the messages are handled in ascending order of timestamp}
    \IF{$\exists m' \in decided : m'.ts \geq m.ts \wedge (\nexists m'' \in decided : m''.ts > m'.ts)$} \label{algline:conditionchangets}
      \STATE $m.ts \leftarrow (m'.ts.rtc, m'.ts.seq + 1)$ \label{algline:changetsafterdecision}
    \ENDIF     
    \STATE $decided \leftarrow decided \cup \{m\}$  \label{algline:addtodecided}
    \IF{$G \in m.dst$} \label{algline:checkcons}
      \STATE $barPending \leftarrow barPending \cup \{m\}$  \label{algline:insbp2}
    \ENDIF
    \STATE \rmcast{$m$}{$m.dst \setminus \{G\}$} \label{algline:rmothers}
  \ENDINDENT
  \STATE $nextProp \leftarrow k' + 1$
  \STATE $k \leftarrow k' + 1$
\ENDINDENT

\blankline
\INDENT{\textit{When $\exists m \in barPending : \forall G' \in sendersTo(G): m.ts < barrier(G',G)$\\ $\wedge\ \nexists m' \in barPending : m'.ts < m.ts$ }} \label{algline:inbarpending}
  \STATE $barPending \leftarrow barPending \setminus \{m\}$ \label{algline:rmfrombp}
  \IF{$m \neq null$}
    \STATE \consdel{$m$} \label{algline:consdeliver}
  \ENDIF
  \STATE $delivered \leftarrow delivered \cup \{m\}$ \label{algline:addtodelivered}

\blankline
\ENDINDENT

\caption{\cmsend{m} -- executed by every process $p$ from group $G$}
\label{algorithm:deliveryminimal}
\end{distribalgo}
\end{algorithm}

Assuming $\delta$ as the communication delay between every pair of processes, the time needed to decide a message $m$ after it has been \cms{} by some process is equal, in the worst case, to $\delta + 2\tconsm$, where $\delta$ is the time needed to \rmd{} a message and \tcons\ is the time needed to execute a consensus instance. This value is counted twice because $m$ may have been inserted into $propPending$ right after a consensus instance has been initiated. In that case, $m$ would have to wait such consensus to finish, to be then proposed and finally decided. However, it may also happen that $m$ has been inserted into $propPending$ right before some proposal has been made, so it would take only $\delta + \tconsm$ to decide $m$. As $m$ may go into $propPending$ anytime between the worst and the best case with the same probability, the average time needed for deciding $m$ would be equal to $\delta + 1.5\tconsm$. Nevertheless, the time needed to finally \cons{} $m$ will depend on when barriers are received from other groups.

\subsection{Addressing liveness}
\label{sec:liveness}

The problem with Algorithm \ref{algorithm:deliveryminimal} is that it does not guarantee liveness when a group has no message to receive from some other group and then keeps waiting for a new message to increase the barrier value and proceed with the delivery of new messages. However, liveness can be easily provided by sending periodic empty messages from $G$ to each $G' \in receiversFrom(G)$ to which no message has been sent for a specified time period. Section \ref{sec:nullperiodic} describes such approach. In section \ref{sec:nullondemand}, another approach, based on sending empty messages when requested, is presented. The trade-off between them concerns message delivery latency against number of control messages sent. In either case, the empty messages are handled as ordinary messages, except they are never delivered to the application.



\subsubsection{Sending empty messages periodically}
\label{sec:nullperiodic}

The simplest way to provide liveness to the delivery algorithm is by sending empty messages periodically. The time threshold \textit{barrierThreshold} defines how long a process waits for a meaningful message to be sent before sending an empty message to ensure that some other group is eventually unblocked. Algorithm \ref{algorithm:nullperiodic} describes this. When a message $m$ from group $G$ to some other group $G'$ has been \rmc{} by $p \in G$, $p$ knows that the other processes of $G$ did the same and that $m$ will be eventually received by the processes of $G'$, serving as barrier from $G$ to $G'$ (l. \ref{algline:incbar} of Algorithm \ref{algorithm:deliveryminimal}). However, when there is a long period after the last time when such kind of message has been created, $p$ decides to create some empty message to send to the processes of $G'$ with the sole purpose of increasing their barrier values and allow for the delivery of possibly blocked messages in $G'$.

\begin{algorithm}
\begin{distribalgo}[1]
\blankline
\INDENT {Initialization}
  \INDENT{\textbf{for all} $G' \in receiversFrom(G)$ \textbf{do}}
    \STATE $lastBarrierCreated(G') = -\infty$
  \ENDINDENT
\ENDINDENT

\blankline
\INDENT{\textit{When} \rmc{}ing a message $m$ to some group $G' \neq G$}
  \STATE $lastBarrierCreated(G') \leftarrow m.ts.rtc$
\ENDINDENT

\blankline
\INDENT{\textit{When $\exists G' \in receiversFrom(G): getTime() - lastBarrierCreated(G') > barrierThreshold$}}
  \STATE $null \leftarrow$ empty message
  \STATE $null.ts \leftarrow (lastBarrierCreated(G') + barrierThreshold, 0)$ \label{algline:samenullid}
  \STATE $null.src \leftarrow G$
  \STATE $null.dst \leftarrow \{G'\}$ 
  \STATE $propPending \leftarrow propPending \cup \{null\}$
  \COMMENT{saving that nothing was sent until null.ts}
\ENDINDENT 

\blankline
\caption{Achieving liveness by sending periodic messages; executed by every process $p$ of group $G$}
\label{algorithm:nullperiodic}
\end{distribalgo} 
\end{algorithm}

The problem with addressing liveness this way is that, in the worst case, $G'$ has decided a message $m$ and has just received the last barrier $b$ from $G$, such that $b < m.ts$. This would mean that, if $G$ has no messages to send to $G'$, $G'$ will have to wait, at least, for $barrierThreshold$ -- maybe just to receive some $b' : b' < m.ts$, having to wait again and so on. How long exactly it will take to \cons{} $m$ depends on many variables, such as how far in the past $m$ was created and how long it takes for some barrier $b: b > m.ts$ to arrive.% Because of that, the time between \cms{}ing and \cons{}ing $m$ be, in the worst case, $2w(p) + 4\tconsm + barrierThreshold$, where $w(p)$ is the wait window of the process $p \in G$, and \tcons\ is counted twice because there are two consensus proposals -- first in $G'$ regarding $m$, and then in $G$ regarding the empty message.

It is necessary to guarantee that a $null$ message will eventually be proposed, decided, and a barrier will be sent to some group which might be needing it, so that progression is guaranteed. Therefore, this kind of messages are created by every process in the group, since if any one of them does not have it, such message might never be decided. %Besides, they are excluded from the $propPending$ list only when decided in the group (l. \ref{algline:nullstays} of Algorithm \ref{algorithm:deliveryminimal}). Since they are obviously never delivered to the application, they can remain in such list and be decided even after some message with higher timestamp is decided. Not removing them unless they are decided ensures that they will be sent and that other groups will be able to increase their barrier values. % On the other hand, this brings another problem: if every process in $G$ creates a different $null$ message, many $null$ messages might have to be decided before a meaningful message.
To prevent the multiple $null$ messages -- created by different processes within the group -- of being decided, they could be created in a way such that the different processes can somehow figure out that two different $null$ messages are equivalent\footnote{This could be done by assuming no timestamp collisions and by using them to uniquely identify messages. Then, only one of the messages created with the same timestamp (l. \ref{algline:samenullid} of Algorithm \ref{algorithm:nullperiodic}) would be decided.}.




\subsubsection{Requesting empty messages}
\label{sec:nullondemand}

There is a way to provide liveness with a lower delay for delivering messages, although that would imply creating more messages and making deeper changes in the delivery algorithm. Let $blockers(m)$ be defined as the set of groups whose barrier is needed in order for some group to deliver $m$. More formally, \mbox{$blockers(m) = \{G_B \neq m.src : \exists G_{dst} \in m.dst \wedge G_B \in sendersTo(G_{dst})\}$}. The idea is that, once each group $G_B$ in $blockers(m)$ has sent\footnote{Here, by `sending', we mean that the message has been received at the destination.} a barrier $b > m.ts$ to all the groups belonging to \mbox{$m.dst \cap receiversFrom(G_B)$}, all possible destinations of $m$ can deliver it. This way, instead of relying on periodic messages, whenever a process $p$ in a group $G$ knows that a message $m$ has just been decided in some consensus instance within $G$, $p$ requests a barrier to every $p' \in blockers(m)$. This request is only sent after $m$ has been decided, because the timestamp of $m$ may have changed, which happens after the consensus. Such request is sent to the processes in the groups inside $blockers(m)$, so that they know that there is a message whose delivery will be blocked until they send a proper barrier to unblock it. Finally, a group never blocks the delivery of its own messages -- hence the condition $G_B \neq m.src$ -- because the message itself can be seen as a barrier from its source group.

When the process $p'$ of some group $G'$ receives a barrier request for a message $m$, %such that $G' \in blockers(m)$,
$p'$ knows that there are other groups depending on the barrier of $G'$ to deliver $m$. For that reason, it will immediately create a $null$ message with a timestamp equal to $m.ts$ and with $null.dst = m.dst$ $\cap$ $receiversFrom(G')$. Then, $p'$ will insert such message in its %$optPending$
$propPending$ queue. % -- to ensure that, once it goes to $propPending$, any message \mbox{$m': m'.ts < null.ts \wedge m'.src = G'$} is already there. As soon as $null.ts > now - w(p')$, the 
Once the $null$ message is proposed and decided in $G'$, each process of $G'$ will send it to every process in each group \mbox{$G \in m.dst \cap receiversFrom(G')$}. This way, any group which was waiting for a barrier from $G'$ to deliver $m$ will be able to do so as soon as it receives such $null$ message. The new delivery algorithm would be as described in \mbox{Algorithm {\ref{algorithm:nullondemand}}}.

\begin{algorithm}
\begin{distribalgo}[1]

\blankline
\INDENT {Initialization}
  \STATE $k \leftarrow 0$, $nextProp \leftarrow 0$, $decided \leftarrow \emptyset$, $delivered \leftarrow \emptyset$, $propPending \leftarrow \emptyset$, $barPending \leftarrow \emptyset$
  \INDENT{\textbf{for all} $G' \in sendersTo(G)$ \textbf{do}}
    \STATE $barrier(G',G) \leftarrow -\infty$ 
  \ENDINDENT
\ENDINDENT 

\blankline
\INDENT{\textit{To} \cms{} \textit{a message $m$}}
  \STATE $m.ts \leftarrow (getTime(),0)$
  %\COMMENT{current wallclock value as the timestamp of $m$}
  \STATE \rmcast{$m$}{$\{G\}$}
%  \INDENT{\textbf{for all} $p' \in m.dst \cup \{G\}$ \textbf{do}}
%    \STATE send($p'$, $m$)    
%    \COMMENT{send optimistically $m$ to all involved processes}
%  \ENDINDENT
\ENDINDENT

\blankline
\INDENT{\textit{When} \rmdel{$m'$}}
  \IF{$G = m'.src$}
    \STATE $propPending \leftarrow propPending \cup \{m'\}$
  \ELSIF{$m' \notin barPending \wedge m' \notin delivered$}
    \STATE $barrier(m'.src,G) \leftarrow m'.ts$ \label{algline:incbar}
    \IF {$G \in m'.dst$}
      \STATE $barPending \leftarrow barPending \cup \{m'\}$
    \ENDIF
    \IF{$G \in blockers(m') \wedge m' \neq null $}
      \STATE $null \leftarrow$ empty message
      \STATE $null.src \leftarrow G$
      \STATE $null.ts \leftarrow m'.ts$ \label{algline:nulltsmts}
      \STATE $null.dst \leftarrow m'.dst \cap receiversFrom(G)$
      \STATE $propPending \leftarrow propPending \cup \{null\}$
    \ENDIF
  \ENDIF
\ENDINDENT

\blankline
\INDENT{\textit{When $\exists m \in propPending \wedge nextProp = k$}}
%  \STATE $propPending \leftarrow propPending \setminus \{m\}$
%  \IF {$m \notin decided \wedge \nexists m' \in decided: m'.ts > m.ts$}
    \STATE $propPending \leftarrow propPending \setminus decided$%(decided \cup \{m' : \exists m'' \in decided \wedge m'.ts < m''.ts \wedge m' \neq null\})$ 
    \label{algline:nullstays}
    \IF {$propPending \neq \emptyset$}
      \STATE $nextProp \leftarrow k + 1$
      \STATE Propose($k$,$propPending$)
    \ENDIF
%  \ENDIF
\ENDINDENT

\blankline
\INDENT{\textit{When} Decide($k'$,$msgSet$)}
%  \STATE $m.gs \leftarrow k$
  \INDENT{\textbf{while} $\exists m \in msgSet : (\forall m' \in msgSet : m \neq m' \Rightarrow m.ts < m'.ts)$ \textbf{do}}
    \STATE $msgSet \leftarrow msgSet \setminus \{m\}$
    \COMMENT{the messages are handled in ascending order of timestamp}
    \IF{$\exists m' \in decided : m'.ts \geq m.ts \wedge (\nexists m'' \in decided : m''.ts > m'.ts)$}
      \STATE $m.ts \leftarrow (m'.ts.rtc, m'.ts.seq + 1)$ \label{algline:chgts}
    \ENDIF     
    \IF{$G \in m.dst$} \label{algline:checkcons}
      \STATE $barPending \leftarrow barPending \cup \{m\}$
    \ENDIF
    \STATE $decided \leftarrow decided \cup \{m\}$
    \IF{$m \neq null$}
      \STATE \rmcast{$m$}{$(m.dst \setminus \{G\}) \cup blockers(m)$} \label{algline:barreq} \COMMENT{the message is sent to blockers(m), as a barrier request}
    \ELSE
      \STATE \rmcast{$m$}{$m.dst$} \COMMENT{no need to unblock $null$, besides it would create infinite messages}
    \ENDIF
  \ENDINDENT
  \STATE $nextProp \leftarrow k' + 1$
  \STATE $k \leftarrow k' + 1$
\ENDINDENT

\blankline
\INDENT{\textit{When $\exists m \in barPending : \forall G' \in sendersTo(G): m.ts < barrier(G',G)$\\ $\wedge\ \nexists m' \in barPending : m'.ts < m.ts$ }}
  \STATE $barPending \leftarrow barPending \setminus \{m\}$
  \IF{$m \neq null$}
    \STATE \consdel{$m$}
  \ENDIF
  \STATE $delivered \leftarrow delivered \cup \{m\}$

\blankline
\ENDINDENT

\caption{\cmsend{m} requesting empty messages -- executed by every process $p$ from group $G$}
\label{algorithm:nullondemand}
\end{distribalgo}
\end{algorithm}
 
As discussed before, assuming $\delta$ as the communication delay between every pair or processes and \tcons{} as the time needed to run one consensus instance, we have a worst case time to decide a message within a group of $\delta + 2\tconsm$. If there is any destination of $m$ which is different from its source group, $m$ is \rmc{} to it after its final timestamp has been defined, which takes another $\delta$. At the same time (l. \ref{algline:barreq} of Alg. \ref{algorithm:nullondemand}), $m$ is \rmc{} also to the groups in $blockers(m)$, each of which then begins a consensus instance proposing an empty $null$ message. After deciding $null$, it is \rmc{} to the processes of the groups which might be needing a barrier to deliver $m$. This way, we can calculate the number of communication steps needed to deliver a message, which is $3\delta + 4\tconsm$ in the worst case and $3\delta + 2\tconsm$ in the best case, leading to an average case of $3\delta + 3\tconsm$.

Although we have bounded the delay to deliver a message, this came at the expense of creating a fairly high amount of control messages for requesting barriers. Unfortunately, this has to be done to guarantee that such $null$ message will eventually be proposed, decided, and a barrier will be sent to some group which might be needing it.
% 
% % Nevertheless, one possible way to implement the delivery for a command $C$ of this type would be to initiate a Paxos consensus instance in each group addressed by it, proposing $C$ and having as learns all servers in all involved groups. 
% 
% %In brief, our strategy is to combine state-machine replication (implemented with Paxos), used to handle object replicas, with Skeen's algorithm, used to select timestamps for commands that affect multiple objects.
% 
% \subsection{Recovering from mistakes}
% 
% Unfortunately, even with a very good delay estimation (e.g. on an environment with a low jitter), there is absolutely no guarantee that the multicast protocol described  in section \ref{sec:quasi} will deliver the game command messages optimistically and conservatively in the same order. When it doesn't, it is considered a \emph{mistake}. Every mistake of the optimistic delivery -- either a lost command message, or an out-of-order delivery -- will cause a rollback of the optimistic state of the objects and re-execution of some of the optimistically delivered commands.
% 
% To perform that, we consider that each object has an optimistic delivery queue, $Q_{opt}$. Whenever a command is optimistically delivered, the optimistic state is updated and the command is pushed in the back of $Q_{opt}$. Whenever a command $C_c$ is conservatively delivered, it updates the conservative state of each object in $obj(C_c)$ and, for each one of them, the algorithm checks whether it is the first command in $Q_{opt}$. If it is, $C_c$ is simply removed from $Q_{opt}$ and the execution continues. If it isn't, it means that $C_c$ was either optimistically delivered out of order, or it was simply never optmistically delivered. It then checks whether $Q_{opt}$ contains $C_c$. If it does, it means the command was optimistically deliverd out of order, and it is removed from the list -- if $Q_{opt}$ doesn't contain $C_c$, it was probably lost\footnote{Also, when $C_c$ is delivered, but it is not in $Q_{opt}$, the remaining possibility is the very unlikely case where the conservative delivery happened before the optimistic one. To handle this case, $C_c$ is stored in a list of possibly delayed optimistic delivery and, if it is ever optimistically delivered, the algorithm will know that it should only discard that command, instead of updating the optimistic state.}. Then, the optimistic state is overwritten with the conservative one and, from that state, all the remaining comands in $Q_{opt}$ are re-executed, leading to a new optimistic state for that object.
%  

\subsection{Optimistic delivery}
\label{sec:optdel}

Even if a reliable multicast primitive is used to send every message to each one of its destinations, guaranteeing its arrival, messages from different senders may arrive in different orders at different destinations, so consensus is necessary to decide which one should be considered by all processes. However, we can predict the final delivery order using the timestamps assigned to the messages by their senders: if each process $p$ waits long enough before proposing some message $m$, every message $m' : m'.ts < m.ts$ will arrive eventually and $p$ will be able to propose them in the same order of their initial timestamps, achieving total order without needing any consensus for that.

The problem is then how to define the length of such wait window for each message $m$ such that it guarantees that every message prior to $m$ will have already been received when the window time has elapsed. As the message delay is unpredictable in asynchronous systems, we make an optimistic assumption:

\begin{center}
\emph{A2: every process $p$ knows a value $w(p)$, which is at least the maximum sum of the message delay bound plus the clock deviation between $p$ and any process $p'$ which could send a message to $p$.}
\end{center}

More formally, if $p \in G$, we can define $w(p)$ as $max_{p' \in sendersTo(G)}(\delta(p,p')+\epsilon(p,p'))$, where $\delta(p,p')$ is the maximum time a message takes to go all the way from $p$ to $p'$ and $\epsilon(p,p')$ is the difference between the clocks of $p$ and $p'$, so that clock deviations can be accounted for\footnote{If this difference is less than zero, it means that the clock value in $p'$ is higher than that in $p$, so $p$ actually has to wait less time for messages from $p'$, as they will have higher timestamps because of the clock deviation.}. The clock deviation is mentioned in this assumption because the timestamp $m.ts$ of each message $m$ is assigned by its sender according to its local clock and we want that, once a message $m$ has been proposed, no message $m' : m'.ts < m.ts$ arrives afterwards. If our optimistic assumption considered only the message transmission delay, such property would not be guaranteed by it.

However, the assumption may not hold, so deliveries made based on it have to be confirmed. There would be then two deliveries for each message: an optimistic one, done within one communication step, and a conservative one, which may follow one of the algorithms described earlier. The difference is that, after a message $m$ was \rmd{}ed at $p$, instead of proposing it, $p$ inserts it into an $optPending$ list, which is sorted in ascending order of the timestamps of the messages in it. Then, $p$ waits until its own wallclock has a value greater than $m.ts.rtc + w(p)$, after which $p$ both proposes $m$ and \opt{}s (optimistically delivers) it. If \emph{A2} holds, then all messages sent by $m.src$ and received after $m$ has been \opt{}ed will have a timestamp greater than $m.ts$.

The optimistic assumption allows for even further improvement. If it holds, the timestamp of the messages will never be changed (i.e. l. \ref{algline:chgts} of Alg. \ref{algorithm:nullondemand} will never be executed). Therefore, if Algorithm \ref{algorithm:nullondemand} is being used, there is no need to wait until a message $m$ has been decided to know its final timestamp and only then request barriers to groups in $blockers(m)$. After the wait window for $m$ has elapsed, such barrier request can already be sent.

If \emph{A2} fails to hold and some message $m$ is received by a process $p$ after a message \mbox{$m' : m'.ts > m.ts$} has been already \opt{}ed and proposed by $p$, then the optimistic delivery algorithm made a mistake, which the application can figure out by the different delivery orders and take action to correct whatever problem this mistake might have caused. Besides, when such thing happens, it means that the timestamp of $m$ has been changed by the conservative delivery algorithm and that, maybe, a new barrier request must be sent to $blockers(m)$ when this new timestamp is defined.

The delivery time of each message $m$ will now depend on whether the assumption \emph{A2} holds or not while $m$ is being handled by the algorithm. If it does hold, it will be \opt{}ed in the correct order within $w(p)$ and, as a barrier request was done in parallel with the conservative delivery algorithm, it will take $w(p) + 2\tconsm + \delta$ to \cons{} $m$ in the worst case. If it does not hold, after $w(p)$, $m$ may be \opt{}ed in an invalid order and, since its timestamp may have changed, a new barrier request may have to be done. Therefore, the worst case conservative message delivery time when the optimistic assumption does not hold and some message is delivered out of order would be $2w(p) + 4\tconsm + \delta$.

Figure \ref{fig:optdel} illustrates both cases, when the optimistic assumption holds and otherwise. Three groups are shown: $G$, $G'$ and $G_b$, where $sendersTo(G) = \{G_b\}$, $sendersTo(G') = \{G\}$ and \mbox{$sendersTo(G_b) = \emptyset$}. A message $m : m.src = G \wedge m.dst = \{G, G'\}$ is \cms{} and, at the same time, a barrier request is sent to the only group in $blockers(m)$, which is $G_b$. In (a), the optimistic assumption holds, so no message $m' : m'.ts < m.ts$ arrives after the proposal of $m$; in (b), however, it is necessary to make a second barrier request.

\begin{figure} 
  \centering
  \includegraphics[width=0.8\linewidth]{images/optdel}
  \caption{Execution examples when the optimistic assumption holds (a) and when its failure to hold causes a violation of the timestamp order (b)}
  \label{fig:optdel}
\end{figure}

% 
% \begin{algorithm}
% \begin{distribalgo}[1]
% 
% \blankline
% \INDENT {Initialization}
%   \STATE $k \leftarrow 0$, $nextProp \leftarrow 0$, $decided \leftarrow \emptyset$, $propPending \leftarrow \emptyset$, $optPending \leftarrow \emptyset$, $barPending \leftarrow \emptyset$
%   \INDENT{\textbf{for all} $G' \in sendersTo(G)$ \textbf{do}}
%     \STATE $barrier(G',G) \leftarrow -\infty$ 
%   \ENDINDENT
% \ENDINDENT 
% 
% \blankline
% \INDENT{\textit{To send a message $m$} -- \cmsend{m}}
%   \STATE $m.ts \leftarrow getTime()$  
%   \COMMENT{current wallclock value as the timestamp of $m$}
%   \STATE \rmcast{$m$}{$m.dst \cup \{G\} \cup blockers(m)$}
% %  \INDENT{\textbf{for all} $p' \in m.dst \cup \{G\} \cup blockers(m)$ \textbf{do}}
% %    \STATE send($p'$, $m$)    
% %    \COMMENT{send optimistically $m$ to all involved processes}
% %  \ENDINDENT
% \ENDINDENT
% 
% \blankline
% \INDENT{\textit{When} \rmdel{$m'$}}
%   \IF {$G \neq m'.src$ $\wedge$ $\exists G' \in (m'.dst \cap receiversFrom(G))$}
%     \STATE $null \leftarrow$ empty message
%     \STATE $null.src \leftarrow G$  \COMMENT{some other group needs a barrier from this one}
%     \STATE $null.ts \leftarrow m'.ts$ \label{algline:nulltsmts}
%     \STATE $null.dst \leftarrow m'.dst \cap receiversFrom(G)$
%     \STATE $optPending \leftarrow optPending \cup \{null\}$
%   \ENDIF
%   \IF {$m'.ts < getTime() - w(p) \vee G \notin m'.dst$}
%     \STATE discard $m'$
%     \COMMENT{late commands probably lead to out-of-order delivery}
%   \ELSE
%     \STATE $optPending \leftarrow optPending$ $\cup$ $\{m'\}$
%   \ENDIF
% \ENDINDENT
% 
% \blankline
% \INDENT{\textit{When $\exists m \in optPending : getTime() > m.ts + w(p)$ $\wedge\ \nexists m' \in optPending: m'.ts < m.ts$}}
%   \STATE $optPending \leftarrow optPending \setminus \{m\}$
%   \IF {$G \in m.dst \wedge m \neq null$}
%     \STATE \optdel{$m$}  
%   \ENDIF
%   \IF {$G = m.src$}
%     \STATE $propPending \leftarrow propPending \cup \{m\}$
%   \ENDIF
% \ENDINDENT
% 
% \blankline
% \INDENT{\textit{When $\exists m \in propPending \wedge nextProp = k$}}
% %  \STATE $propPending \leftarrow propPending \setminus \{m\}$
% %  \IF {$m \notin decided \wedge \nexists m' \in decided: m'.ts > m.ts$}
%     \STATE $propPending \leftarrow propPending \setminus (decided \cup \{m' : \exists m'' \in decided \wedge m'.ts < m''.ts \wedge m' \neq null\})$ \label{algline:keepnull}
%     \IF {$propPending \neq \emptyset$}
%       \STATE $nextProp \leftarrow k + 1$
%       \STATE Propose($k$,$propPending$)
%     \ENDIF
% %  \ENDIF
% \ENDINDENT
% 
% \blankline
% \INDENT{\textit{When} Decide($k$,$msgSet$)}
% %  \STATE $m.gs \leftarrow k$
%   \STATE $decided \leftarrow decided \cup msgSet$
%   \INDENT{\textbf{for all} $m \in msgSet : G \in m.dst \wedge m \neq null$ \textbf{do}} \label{algline:checkcons}
%     \STATE $barPending \leftarrow barPending \cup \{m\}$
%   \ENDINDENT
%   \INDENT{\textbf{while} $\exists m \in msgSet : (\forall m' \in msgSet : m \neq m' \Rightarrow m.ts < m'.ts)$ \textbf{do}}
%     \INDENT{\textbf{for all} $p' \in m.dst \setminus \{G\}$ \textbf{do}}
%       \STATE send($p'$, $\{m, \text{`cons'}\}$)
%       \COMMENT{this message is sent through a FIFO lossless channel}
%     \ENDINDENT
%     \STATE $msgSet \leftarrow msgSet \setminus \{m\}$
%     \COMMENT{the messages are sent in ascending order of timestamp}
%   \ENDINDENT
%   \STATE $nextProp \leftarrow k + 1$
%   \STATE $k \leftarrow k + 1$  
% \ENDINDENT
% 
% \blankline
% \INDENT{\textit{When} receive($\{m',\{\text{`cons'}\}$)}  
%   \IF {$m' \notin\ barPending \wedge m' \notin\ delivered \wedge m' \neq\ null$}
%     \STATE $barPending \leftarrow barPending \cup \{m\}$
%   \ENDIF
%   \STATE $barrier(m'.src,G) \leftarrow max(m'.ts, barrier(m'.src,G))$  \COMMENT{channels are FIFO, but there are different senders}
% \ENDINDENT
% 
% \blankline
% \INDENT{\textit{When $\exists m \in barPending : \forall G' \in sendersTo(G): m.ts < barrier(G',G)$\\ $\wedge\ \nexists m' \in barPending : m'.ts < m.ts$ }}
%   \STATE $barPending \leftarrow barPending \setminus \{m\}$
%   \STATE \consdel{$m$}
%   \STATE $delivered \leftarrow delivered \cup \{m\}$
% 
% \blankline
% \ENDINDENT
% 
% \caption{\cmsend{m} -- executed by every process $p$ from group $G$}
% \label{algorithm:nullondemand}
% \end{distribalgo}
% \end{algorithm}



\subsection{Parallel instances of consensus}
\label{sec:parallel}

We can further optimize the delivery algorithm. One major problem with proposing messages with consensus is that the previous algorithms wait until a consensus instance has been finished to start a new one, so that no message is proposed twice. However, even if a message is proposed and accepted twice, each process may choose to consider only the first time (i.e. the consensus instance with lowest id) when a message $m$ has been proposed. This would require some more local processing and could cause some unnecessary traffic due to messages being proposed in different consensus instances. The worst case delivery time of a message $m$, when using the optimistic delivery and barrier requests, would be $2w(p) + 2\tconsm + \delta$. It must be noted, however, that this represents the case when the optimistic assumption fails to hold and $m$ has its timestamp changed. Otherwise, the conservative delivery time would be $w(p) + \tconsm + \delta$.

The basic idea would be that, whenever a process $p$ has a pending message $m$ that it received, it will propose it in some instance $I$ as soon as its clock has a value greater than $m.ts.rtc + w(p)$. As $p$ cannot foresee whether $m$ will be decided in $I$ or not, it keeps the double $(m,I.id)$ in a $trying$ list. When $I$ terminates, $(m,I.id)$ is removed from $trying$ and $p$ checks whether $m$ has been decided -- which might have happened also in some instance $I' \neq I$ in the meantime -- by checking its $decided$ list. If not, $p$ proposes $m$ again in some consensus instance $I''$ and inserts $(m,I''.id)$ into $trying$.

Even if the consensus instances are run in parallel, we consider that they make a callback to \emph{Decide()} in ascending order of instance id. This can be easily done by the consensus implementation using a sequence number. Whenever a message $m$ is agreed upon in some consensus instance $I$, any later decision of $m$ in some instance \mbox{$I' : I'.id > I.id$} is merely ignored.



\subsection{Using Paxos with a leader for consensus}
\label{sec:paxos}

Although ensuring termination of consensus in an asynchronous system is not possible \cite{fischer1985idc}, the Paxos \cite{lamport1998ptp} algorithm can guarantee the termination of an instance $I$ as long as some assumptions are held:

\begin{itemize}
  \item the maximum message delay bound $\delta$ is known;
  \item at some point in the execution of $I$, there is a leader which does not fail until a value has been chosen\footnote{Lamport demonstrates in \cite{lamport1998ptp} that, if the time needed to elect a leader is $T_{el}$, the time needed to conclude a consensus instance would be at most $T_{el} + 9\delta$ after the last leader failure during the execution of $I$.};
  \item during the whole execution of $I$, more than half of the processes are correct, that is, if the number of faulty processes is $f$ and the total number of processes is $n$, $f < \lceil \frac{n}{2} \rceil$;
  \item enough messages are successfully received, that is, for each phase of the execution of $I$, a majority of processes succesfully receive the leader's message or the leader successfully receives the reply (be it a confirmation or a negative acknowledgement) from a majority of processes.
\end{itemize}

Paxos uses the abstraction of \emph{proposers}, \emph{acceptors} and \emph{learners}. In short, the acceptors are the processes which have to agree upon some value given by the proposers. The learners are those who are notified about which value has been accepted. With a leader, Paxos can achieve consensus in most instances, except the first one since the last leader change, in $3\delta$ -- forwarding a proposal to the leader, sending it to the other processes (acceptors) and receiving a confirmation. Each acceptor can send the confirmation to every learner, so that each learner can figure out by itself that a value has been agreed upon once it receives a confirmation from a majority of acceptors.

In the context of our \cms{} primitive, the first communication step of Paxos -- forwarding a message $m$ to the leader -- is already done by means of \rmc{}ing each message to a set of processes that includes every process in $m$'s group of origin. The last phase, which consists of every learner receiving the confirmation of a majority of acceptors, can also include the $\delta$ contained in the conservative message delivery time we analysed before: instead of waiting for a message to be decided and only then notifying other groups, the acceptors of a group can also send the confirmation to processes in other groups, so that also they can infer the first group's decision right away. This implies that, for each consensus instance run within a group $G$, each process in the groups of $receiversFrom(G)$ would be a learner for that instance. Figure \ref{fig:paxosmanylearnergroups} illustrates this: process $p_1$ from group $G$, whose leader is $p_3$, \cms{}s $m$; in the last phase of the consensus protocol, the processes in $G' \in receiversFrom(G)$ receive the confirmation message from the acceptors of $G$, so no extra communication step is needed to notify them about the final timestamp of $m$.

As $m$ was \rmc{} in the beginning, there is no need to send all of its contents again in the consensus instance. Instead, only the timestamp of $m$ is proposed, since this is the information that must be agreed upon -- and which may change if the optimistic assumption does not hold and some other message of higher timestamp is delivered before $m$. In any case, as all messages agreed upon in $G$ are notified to $G'$, also the processes of $G'$ are able to infer the final timestamp of each message from $G$.

As we are making an optimistic assumption -- that each $p$ waits for a time $w(p)$ long enough so that no timestamps must be changed -- for the message delivery, the barriers are being requested to other groups in parallel, since $m$ is also \rmc{} to $blockers(m)$ in the first communication step of our protocol. If such assumption holds, the barriers received will have a greater timestamp than $m$ and, thus, the conservative delivery of $m$ will take place $w(p) + 2\delta$ after it has been sent. If the clocks are perfectly synchronized and $w(p)$ does correspond to the maximum interprocess communication delay $\delta$, the time needed to conservatively deliver a message using this algorithm would be $3\delta$.

Finally, we can guarantee a conservative delivery time of $3\delta$, if no message had its timestamp changed, because the barrier requests for that message were made based on its initial timestamp. If the timestamp has changed, then a new barrier request may have to be made to ensure the delivery of that message. Unfortunately, to guarantee the delivery of the message, such request can be done only after the final timestamp has been decided: once the source group of a message $m$ noticed a change in $m.ts$, it sends another barrier request to $blockers(m)$. This request is handled in a way very similar to a conservative delivery, in the sense that, once it is received by a process, a null message is proposed, decided and then sent back to the destinations of $m$. This would take extra $3\delta$, so the worst case conservative delivery time would be $6\delta$.

Note, however, that for this worst case scenario to happen it would be necessary for the leader $p$ of group $G$ to: (1) not know some value greater than or equal to $w(p)$; (2) have received and proposed some message $m' : m'.ts > m.ts$ before $m$ and (3) not have received any barrier with value greater than the new timestamp of $m$. Even after changing the timestamp of $m$, it may be not necessary to request a new barrier from each group in $sendersTo(G)$, because some other barrier -- possibly requested because of some other message -- with a value higher than the new timestamp of $m$ may have been received already.

\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{images/paxos3d}
  \caption{Deciding the final timestamp and notifying other groups in three communication steps}
  \label{fig:paxosmanylearnergroups}
\end{figure}



\subsection{Relaxing validity and discarding stale messages}
\label{sec:discard}

Although unlikely to happen, the worst case delivery time of \cms{} when using Paxos with a leader for consensus and requesting barriers in the beginning of the protocol is $6\delta$. It is so because some messages may need to have their initial timestamp changed as a possible consequence of the optimistic assumption \emph{A2} not holding. However, a simple way to eliminate the possibility of having to change timestamps is by not considering messages whose delivery order does not follow the order of the initial timestamps.

Although discarding messages which do not follow the initial timestamp order conflicts with the properties we have defined for the \cms{} primitive, we describe it here because then every message would be delivered within $3\delta$, in the worst case. The validity property would now be changed to:

\textbf{Optimistic Uniform Validity}: if a process \cms{}s $m$ and the optimistic assumption \emph{A2} holds, then one of the correct processes that is a destination of $m$ eventually \cons{}s $m$.

The problem with changing the original uniform validity property is that it could make the multicast primitive impracticable for some applications. Nevertheless, some other applications not only do not require messages to be delivered if they arrive out of order, but also it is better not to deliver such messages at all -- such as real-time streams of audio or video or online real-time multiplayer games.


\section{Proof of correctness}
\label{sec:proofs}

Here, we prove that the \cms{} primitive ensures the properties defined in section \ref{sec:model} -- uniform validity, uniform agreement, uniform integrity, uniform total order and FIFO order. To do this, we prove that Algorithm \ref{algorithm:deliveryminimal}, when used along with Algorithm \ref{algorithm:nullperiodic}, ensures these properties.





\subsection{Uniform Validity}

%===           ====================================
%===   LEMMA   ====================================
%===           ====================================
\begin{lems} \label{lemma:mcastbarpending}
Once a message has been \cms{}, it will be inserted into the $barPending$ list of all the correct processes to which such message has been addressed.
\end{lems}

\begin{proof}
In Algorithm \ref{algorithm:deliveryminimal}, whenever a process in a group $G$ \cms{}s a message, it is first \rmc{} to all processes in $G$ (l. \ref{algline:rmlocal}). From the uniform agreement property of the \rmc{} primitive, every correct process from $G$ \rmd{}s $m$. Once $m$ is \rmd{}ed by each process $p \in G$, it is inserted into the $propPending$ list of that process, to be included in the next proposal from $p$. As every process from $G$ received $m$ and enqueued it for being proposed, and since $m$ is only removed from $propPending$ when decided (l. \ref{algline:removedecided}), every processes of $G$ will propose it at some point and $m$ will eventually be decided. At this point, if $G \in m.dst$, every correct process of $G$ will insert $m$ into its $barPending$ list (l. \ref{algline:insbp2}). Besides, each correct process in $G$ \rmc{}s $m$ to all other destination groups that $m$ might be adressed to.

Let $p'$ be any process in a destination group $G'$ of the message $m$, such that $G' \neq G$. In this case, once $m$ is \rmd{}ed at $p'$, it inserts such message into the $barPending$ list, unless it has already done so (lines \ref{algline:notbptwice} and \ref{algline:insbp1}).
\end{proof}



%===           ====================================
%===   LEMMA   ====================================
%===           ====================================
\begin{lems} \label{lemma:barrierperiodic}
  Given a message $m$ in the $barPending$ list of a correct process $p$, from group $G$, eventually every group $G' \in sendersTo(G)$ will have sent $barrier(G',G) > m.ts$ to $p$.
\end{lems}

\begin{proof}Every process $p'$ keeps executing Algorithm \ref{algorithm:nullperiodic}, thus sending ever-increasing barrier values to all processes in $receiversFrom(group(p'))$. Also, if $G \in receiversFrom(G')$, then $G' \in sendersTo(G)$. This means that, at some point, all correct processes of each group in $sendersTo(G)$ will have inserted a message -- be it $null$ or not -- in their $propPending$ lists, with a timestamp greater than, or equal to, that of $m$. As this is done by every process in each of the groups in $sendersTo(G)$, and a message is removed from $propPending$ only when decided, then eventually $null$ will be decided and \rmc{} to $G$. From the uniform validity property of \rmc{}, such messages will be delivered by $p$, which will insert them into its $barPending$ list. From the algorithm, the timestamps of the messages are no longer changeable after they have been inserted into $barPending$ so, eventually, $p$ will have in such list a barrier with a value greater than or equal to $m.ts$ from each group in $sendersTo(G)$. 
\end{proof}

%===           ====================================
%===   LEMMA   ====================================
%===           ====================================
\begin{lems} \label{lemma:groupfifo}
If a process $p$ from a group $G$ has received a message $m$ from another group $G' \neq G$, then $p$ has also received any message $m'$ from $G'$, where $m'.ts < m.ts$.
\end{lems}

\begin{proof}
Every process $p'$ from $G'$ sends messages to the processes of $G$, including $p$, using a FIFO channel, via the \rmc{} primitive, in the same order in which messages are decided within $G'$. Also, the agreement property of consensus ensures that all processes from $G'$ will decide the same messages in each consensus instance $k$. Finally, $p'$ \rmc{}s to $G$ every message $m : m.src = G' \wedge G \in m.dst$ (l. \ref{algline:rmothers} of Algorithm \ref{algorithm:deliveryminimal}).

Assume, by way of contradiction, that $p$ received a message $m':m'.ts < m.ts$ from some process $p'' \in G'$ after having received $m$ from $p'$. As $m'.src = m.src$, this means that $p'$ either will send $m'$ afterwards, contradicting the fact that the processes in $G'$ agree on each batch of messages decided and send them to $G$ in the same FIFO order, or that $p'$ will not send $m'$ at all, contradicting the uniform validity property of the \rmc{} primitive. Therefore, the assumption is false and the lemma is valid.
\end{proof}

%===           ====================================
%===   LEMMA   ====================================
%===           ====================================
\begin{lems} \label{lemma:alwaysbpdel}
Once a message has been inserted into either the $barPending$ list or the $delivered$ list of a given process, it will always belong to one of them.
\end{lems}

\begin{proof}
Immediate from the algorithm, considering that a message is never removed from the $delivered$ list, and that it is removed from $barPending$ (l. \ref{algline:rmfrombp}) right before being inserted into $delivered$ (l. \ref{algline:addtodelivered}).
\end{proof}

%===           ====================================
%===   LEMMA   ====================================
%===           ====================================
\begin{lems} \label{lemma:oncedecidednotsmaller}
  Once a process inserts a message $m$ from some group into its $barPending$ list, no message $m' : m'.ts < m.ts$ from the same group will be inserted into the same $barPending$ list afterwards.
\end{lems}

\begin{proof}
Let $p$ be a process from the group $G$ which sent $m$. Before inserting $m$ into the $decided$ list (l. \ref{algline:addtodecided} of Algorithm \ref{algorithm:deliveryminimal}), $p$ checks whether there is already some other message with an equal or lower timestamp in such list. If that is the case, the timestamp of $m$ is changed to a value greater than that of any other message already within $decided$. Only then $m$ may be inserted into the $barPending$ list of $p$ (l. \ref{algline:insbp2}). Therefore, $p$ inserts messages from other processes in $group(p)$ into its $barPending$ list in ascending order of timestamps. Besides, each process from $G$ \rmc{}s $m$ to the other destinations of $m$ in this same order (l. \ref{algline:rmothers}).

Regarding groups other than the source of the message, let $p'$ be any process that is a destination of $m$, such that $p' \in G' \wedge G' \neq G$. The process $p'$ inserts $m$ into its $barPending$ list in line \ref{algline:insbp1}. Considering that every process in a group sends that group's messages to other groups in the same order in which they are decided, that once a group has received some message from another group, any message prior to that one from the same group has also already been received (from Lemma \ref{lemma:groupfifo}), and that no message is inserted twice in the $barPending$ list of any process (from line \ref{algline:notbptwice} and Lemma \ref{lemma:alwaysbpdel}), we can infer that, once $p'$ inserts $m$ into its $barPending$ list, no message $m' : m'.ts < m.ts$ from $G$ will be inserted into the same $barPending$ list afterwards.
\end{proof}

%===           ====================================
%===   LEMMA   ====================================
%===           ====================================
\begin{lems} \label{lemma:oncebpwilldel}
Once a message $m$ has been inserted into the $barPending$ list of a process $p$, it will eventually be removed from such list and, if $m$ is different from $null$, it will be delivered by $p$.
\end{lems}

\begin{proof}
Eventually, $p$ will have received a barrier from every group in $sendersTo(group(p))$ with a value greater than the timestamp of $m$ (from Lemma \ref{lemma:barrierperiodic}). Once this happens, as any barrier is also a message, no more messages with a timestamp lower than that of $m$ will be inserted into the $barPending$ list of $p$ (from Lemma \ref{lemma:oncedecidednotsmaller}). Let $barReady$ be the set of $m$ plus all messages from $barPending$ whose timestamps are lower than that of $m$, that is, $barReady = \{m\} \cup \{m' : m' \in barPending \wedge m'.ts < m.ts\}$.

We can infer that no more messages will be included in this set, meaning that any other message that might be later inserted into $barPending$ will have a timestamp greater than that of any message in $barReady$. Besides, the barrier received for $m$ also apply to all the other messages in this set, since their timestamps are lower than that of $m$. We can, therefore, prove that all these messages will eventually be delivered by induction on the position $i$ of each message $m_i$ in $barReady$, in ascending order of timestamps.\\
\\
\noindent Base case ($i=1$): Let $m_1$ be the first message in $barReady$. It means that $\nexists m \in barPending : m.ts < m_1.ts$. The message $m_1$ has the lowest timestamp in the list and all the necessary barriers have been received already. Therefore, $m_1$ satisfies all conditions from line \ref{algline:inbarpending} of Algorithm \ref{algorithm:deliveryminimal} and will be removed from $barPending$. If it is different from $null$, it will also be delivered.\\
\\
\noindent Induction step: Suppose that $m_{i}$ will eventually be removed from $barPending$. Once this happens, it means that $m_{i}$ was the first message in the list. Since no more messages have been inserted into $barReady$, as soon as $m_{i}$ is removed, $m_{i+1}$ will be the new first one. Then, as $m_{i+1}$ will have the lowest timestamp in $barReady$, it will also have the lowest timestamp of $barReady$. As all barriers necessary for $m$ have already been received and $m_{i+1}.ts \leq m.ts$, it will satisfy both conditions of line \ref{algline:inbarpending} from Algorithm \ref{algorithm:deliveryminimal}. Thus, $m_{i+1}$ will be removed from $barPending$ -- and delivered, if it is different from $null$. \end{proof}


%===                 ==============================
%===   PROPOSITION   ==============================
%===                 ==============================
\begin{props} \label{props:validity}
Once a process \cms{}s a message, then all correct processes that are destinations of that message eventually deliver it.
\end{props}

\begin{proof}
Immediate from Lemma \ref{lemma:mcastbarpending}, Lemma \ref{lemma:oncebpwilldel}, and from the assumption that the application will not \cms{} a $null$ message -- not in the \cms{} protocol level at least; if the application needs to \cms{} an empty message, in the protocol level it would not be handled as a $null$ message.
\end{proof}





\subsection{Uniform Integrity}





%===                 ==============================
%===   PROPOSITION   ==============================
%===                 ==============================
\begin{props} \label{props:integrity}
If a message $m$ was delivered to process $p$ of group $G$, then it has (1) been \cms{} before, (2) $G \in m.dst$ and (3) it has not been \cons{}ed by $p$ before.
\end{props}

\begin{proof}
For a message $m$ to be delivered (l. \ref{algline:consdeliver}), it must be contained in the $barPending$ list (from the condition in line \ref{algline:inbarpending}).  There are two possibilities to when $m$ has been inserted into such list:
\begin{itemize}
  \item $m$ has been originated in the same same group of $p$, that is, $p \in m.dst$, which means $m$ was inserted into $barPending$ in line \ref{algline:insbp2} of Algorithm \ref{algorithm:deliveryminimal}, or
  \item $m$ has been sent from a group $G \neq G'$, which means that it was inserted into $barPending$ in line \ref{algline:insbp1}. 
\end{itemize}

In line \ref{algline:insbp2}, $m$ is inserted into $barPending$ only if $G \in m.dst$, which satisfies condition (2), and if it was decided in some consensus instance within $G$. To have been decided within $G$, from the properties of consensus \cite{lamport1998ptp}, we know that it must have been proposed by some process of $G$, which happens in line \ref{algline:propose}. In line \ref{algline:propose}, for a message to be proposed, it must be in the $propPending$, as its contents are the value proposed. For a message to be in the $propPending$ list, it must have been inserted there, which happens only in line \ref{algline:addtoproppending}. For l. \ref{algline:addtoproppending} to be executed, $m$ must have been \rmd{}ed and $G$ must be the source group of $m$, that is, $m.src = G$. For a message to be \rmc{} by a process to its own group, a \cmsend{$m$} call must have been made -- which satisfies condition (1) --, for line \ref{algline:rmlocal} is the only one where a process \rmc{}s a message to its own group. 

Also, for a message to be inserted into $propPending$ (l. \ref{algline:addtoproppending}) it cannot have been decided already (l. \ref{algline:removedecided}). We assume here that a process can only make a proposal for consensus instance $k$ when it knows all the values decided in all instances prior to $k$. Therefore, when a process proposes a message, it knows all the messages which were already decided in previous consensus instances. As a decided message is inserted into a $decided$ list (l. \ref{algline:addtodecided}, which is always executed after a decision), a process cannot propose a message which was decided already and, therefore, a message cannot be decided twice (in two different consensus instances). As a message is inserted into $barPending$ by processes of its own group of origin only when decided (l. \ref{algline:insbp2}), it cannot be inserted twice, thus it cannot be delivered twice, satisfying condition (3).

As for processes from destination groups which are not from the source group of $m$, they will never execute line \ref{algline:insbp2}, since they never decide on $m$. However, processes of the group $m.src$, which is the source of $m$, will \rmc{} $m$ to every $G'$ which is a destination of $m$ other than $G$ (l. \ref{algline:rmothers}). When a process in $G'$ \rmd{}s $m$, it checks whether $m$ was already inserted into $barPending$ or $delivered$, where $delivered$ is the list of all messages which were ever \cmd{}ed. Once a message has been inserted into \mbox{$barPending \cup delivered$}, it stays there forever -- a message is only removed from $barPending$ in line \ref{algline:rmfrombp}, right after what it is then inserted into $delivered$, in line \ref{algline:addtodelivered}. Therefore, also messages which arrive from other groups are never inserted twice into $barPending$. As each message is removed from $barPending$ right before being \cmd{}ed, it is never delivered twice, satisfying (3).

For line \ref{algline:insbp1}, $m$ is inserted into $barPending$ of process $p'$ of group $G'$ when it has been \rmd{}ed, and only if $m.src \neq G'$. For a process $p \in G \neq G'$ to \rmc{} $m$, $m$ must have been decided within $G$, which means that it was proposed within $G$, therefore it was \cms{} -- satisfying condition (1) -- by $G \neq G'$ to $G'$, which, from line \ref{algline:rmothers}, necessarily belongs to $m.dst$, satisfying condition (2).

Finally, as for Algorithm \ref{algorithm:nullperiodic}, $null$ messages are never delivered, so they will never violate the uniform integrity property.
\end{proof}






\subsection{Uniform Agreement}

%===                 ==============================
%===   PROPOSITION   ==============================
%===                 ==============================
\begin{props} \label{props:agreement}
If a correct process which is a destination of a message $m$ delivers it, then all correct processes that are also destinations of $m$ deliver it as well.
\end{props}

\begin{proof}
Immediate from Proposition \ref{props:integrity}, Lemma \ref{lemma:mcastbarpending} and Lemma \ref{lemma:oncebpwilldel}.
\end{proof}






\subsection{Atomic Order}




%===           ====================================
%===   LEMMA   ====================================
%===           ====================================
\begin{lems} \label{lemma:agreetimestamps}
If two correct processes are both destinations of a message $m$, then they agree on its final timestamp $m.ts$.
\end{lems}

\begin{proof}
Let $p$ be the process that is \cms{}ing $m$. We can prove this lemma by demonstrating that any other process $p'$ will agree with $p$ on the timestamp of $m$. Let us first consider the case of $p'$ belonging to the same group as $p$. We can prove by induction on the identifier $k$ of each consensus instance within $group(p)$:\\

\noindent Base case ($k=1$): As this is the first consensus instance of the group, it means that the $decided = \emptyset$. From the agreement property of consensus, we know that $p$ and $p'$ decided the same contents for $msgSet$ \mbox{(l. \ref{algline:decide})}. Each message included in such agreed set also includes an initial timestamp field. As the $decided$ set is empty, such timestamps are not changed in neither $p$ or $p'$ (l. \ref{algline:conditionchangets}). Therefore, both processes consider the same timestamp value for every message. Besides, as the $msgSet$ is the same for both, the $decided$ set remains identical for both $p$ and $p'$.\\

\noindent Induction step: Suppose that $p$ and $p'$ have already learnt the decisions of instance $k$, their $decided$ sets remained identical and they decided the same timestamp value of each message sent from some process in their group so far. As we assume that all processes within a group learn the decisions in the same consensus instace identifier order, then both $p$ and $p'$ will next learn the decision of the same instance $k+1$. From the agreement property of consensus, the $msgSet$ decided is the same for both processes. In the Algorithm \ref{algorithm:deliveryminimal}, the timestamps may be changed after the consensus decision only in line \ref{algline:changetsafterdecision}, based on what is already in the $decided$ set (l. \ref{algline:conditionchangets}). As the $msgSet$ and $decided$ sets are each identical in $p$ and $p'$, they will make the exact same change to the timestamp of each message in the \textit{while} loop (l. \ref{algline:whiledecided} to l. \ref{algline:rmothers}). Therefore, they also agree on the timestamps of each message decided on consensus instance $k+1$ and their $decided$ sets remain identical.\\

Now, consider the case of $p'$ not belonging to the same group of $p$. Let $q$ be any process of $group(p)$. After setting the final timestamp of $m$ (l. \ref{algline:whiledecided} to l. \ref{algline:rmothers}), $q$ \rmc{}s $m$ to $group(p')$ (l. \ref{algline:rmothers}). Once $p'$ \rmd{}s $m$, it never changes the timestamp of $m$, which already contains the final value, set by $q$ in accordance with $p$. As any two processes on the same group from which $m$ has been multicast agree on its timestamp, and since any process from other group which is also a destination of $m$ agree on its timestamp as well, than any two processes that are destinations of $m$ agree on its timestamp.
\end{proof}




%===           ====================================
%===   LEMMA   ====================================
%===           ====================================
\begin{lems} \label{lemma:respecttimestamps}
If two messages $m$ and $m'$ have both a correct process $p$ as a destination, and $m.ts < m'.ts$, then $p$ delivers $m'$ after delivering $m$.
\end{lems}

\begin{proof}
Consider Algorithm \ref{algorithm:deliveryminimal}. Suppose, by way of contradiction, that $m'$ has already been delivered by $p$, whereas $m$ has not. Message $m$ might have already been inserted into $barPending$ or not. In the former case, $m'$ could not have been delivered, since $m.ts < m'.ts$, thus it would not satisfy the condition from line \ref{algline:inbarpending} until $m$ has been delivered, so we have a contradiction in the case that $m$ was already in $barPending$.

The other case is if $m$ has not been inserted into $barPending$. From line \ref{algline:inbarpending}, we know that $p$ has received some barrier $b$ from every group in $sendersTo(group(p))$. Therefore, from Lemma \ref{lemma:oncedecidednotsmaller}, and since a barrier is also a message, we know that any new message that arrives at $p$ will have a timestamp greater than $m'.ts$. As $m$ has arrived after $m'$, then $m.ts > m'.ts$, which is also a contradiction.

We have proven that the timestamp order will not be violated by $p$. Considering that, once a message has been multicast, it will be delivered (Proposition \ref{props:validity}), then we know that all messages will be delivered by $p$, and in the correct timestamp order.\end{proof}




%===                 ==============================
%===   PROPOSITION   ==============================
%===                 ==============================
\begin{props} \label{props:atomicorder}
If processes $p$ and $p'$ are both in $m.dst$ and $m'.dst$, then $p$ delivers $m$ before $m'$ if, and only if, $p'$ delivers $m$ before $m'$.
\end{props}

\begin{proof}
Immediate from Lemma \ref{lemma:agreetimestamps}, Lemma \ref{lemma:respecttimestamps} and Proposition \ref{props:agreement}.
\end{proof}



\subsection{FIFO Order}





%===           ====================================
%===   LEMMA   ====================================
%===           ====================================
\begin{lems} \label{lemma:fifofinalts}
If a process $p$ \cms{}s $m$, then $m'$, then the final values of their timestamps will be such that $m.ts < m'.ts$.
\end{lems}

\begin{proof}
From lines \ref{algline:gettime} and \ref{algline:rmlocal}, and the properties of the \rmc{} primitive, we know that all correct processes \rmd{} $m$ and then $m'$, which means that each process $p'$ from $group(p)$ also inserts them into its $propPending$ list in this same order.

Suppose, by way of contradiction, that $m'$ is decided before $m$. This implies that some process $p$ proposed a message set that included $m'$, but not $m$. As $p$ inserted $m$ before $m'$ in its $propPending$ list, it means that $m$ was removed by $p$ from such list before being included in some proposed message set. However, the only possibility of removing a message from $propPending$ is on line \ref{algline:removedecided}, which means that $m$ already belonged to the $decided$ set, so it had been decided before $m'$, which is a contradiction. Therefore, $m'$ is not decided before $m$.

This also means that $m'$ is not inserted into the $decided$ list before $m$ has already been inserted. From line \ref{algline:gettime}, we know that the initial timestamp of $m$ is already smaller than that of $m'$. The only way to change this order is by making the final timestamp $m.ts$ bigger than $m'.ts$ on line \ref{algline:changetsafterdecision}. Even if this happens, as $m'$ is inserted into $decided$ after $m$, from line \ref{algline:conditionchangets}, we know that the final timestamp of $m'$ will be made greater than that of $m$.
\end{proof}






%===                 ==============================
%===   PROPOSITION   ==============================
%===                 ==============================
\begin{props} \label{props:fifoorder}
If $p$ \cms{}s $m$ and then $m'$, then no process $p'$ in both $m.dst$ and $m'.dst$ delivers $m'$ before delivering $m$.
\end{props}

\begin{proof}
Immediate from Lemma \ref{lemma:respecttimestamps} and Lemma \ref{lemma:fifofinalts}.
\end{proof}





\section{Related work}

\cite{sousa2002oto}: optimistic total order bcast in wans: for the opt-delivery to work properly, requires that the delay between each pair of processes stay constant (ours only requires that it never goes beyond $w(p)$ for each process $p$\ldots). sequencer based (no tolerance for failures of the sequencer). not mentioning multicast.

\section{Experimental results}

\section{Conclusion}

%\bibliographystyle{latex8}
%\bibliography{main}
\bibliographystyle{acm}
\bibliography{gftommog}
\end{document}

