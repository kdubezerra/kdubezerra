\newcommand{\ggp}{ProGReGA}
\newcommand{\ggpmeaning}{proportional greedy region growing algorithm}
\newcommand{\ggpk}{\mbox{\ggp-KH}}
\newcommand{\ggpkmeaning}{proportional greedy region growing algorithm keeping heaviest cell}
\newcommand{\ggpf}{\ggp-KF}
\newcommand{\ggpfmeaning}{proportional greedy region growing algorithm keeping usage fraction}
\newcommand{\bfa}{BFBCT}
\newcommand{\bfameaning}{best-fit based cell transference}
\newcommand{\kl}{Kernighan-Lin}
\newcommand{\klalg}{Kernighan-Lin}
\newcommand{\wtodiv}{weight\_to\_divide}
\newcommand{\freecap}{free\_capacity}
\newcommand{\rlist}{region\_list}
\newcommand{\clist}{cell\_list}
\newcommand{\locgroup}{local\_group}
\newcommand{\avguse}{average\_usage}
\newcommand{\wlocal}{local\_weight}
\newcommand{\caplocal}{local\_capacity}
%\newcommand{\wshare}{por\text{\emph{\c{c}}}\tilde{a}o\_da\_carga}
\newcommand{\wshare}{weight\_share}
\newcommand{\wlose}{weight\_to\_lose}
\newcommand{\destreg}{destination\_regions}
\newcommand{\regcap}{free\_capacity}
\newcommand{\wtoreg}{weight\_to\_this\_region}
\newcommand{\misccite}[2]{Available at: #2}
\newcommand{\gamecite}[2]{Available at: #2}

%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2006/03/15
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
%\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
%gsave
%newpath
%  20 20 moveto
%  20 220 lineto
%  220 220 lineto
%  220 20 lineto
%closepath
%2 setlinewidth
%gsave
%  .4 setgray fill
%grestore
%stroke
%grestore
%\end{filecontents*}
%
\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallextended]{svjour3}     % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}         % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}
\usepackage[latin1]{inputenc}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{times}
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%
\begin{document}
%[TODO:ajustar TODAS as \refs]
\title{A load balancing scheme for massively multiplayer online games %\thanks{}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{Carlos E. B. Bezerra         \and
        Cludio F. R. Geyer %etc.
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{Carlos Eduardo Benevides Bezerra, Cludio Fernando Resin Geyer \at
							Universidade Federal do Rio Grande do Sul \\
              Av. Bento Gonalves, 9500, Porto Alegre, Brazil \\
              Tel.: +55-51-84065986\\
              Fax.: +55-51-33087308\\
              \email{carlos.bezerra@inf.ufrgs.br, geyer@inf.ufrgs.br}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
%           \and
%           Cl�udio Fernando Resin Geyer \at
%           		Universidade Federal do Rio Grande do Sul \\
%              Av. Bento Gon�alves, 9500, Porto Alegre, Brazil \\
%              Tel.: +55-51-99011155\\
%              \email{geyer@inf.ufrgs.br}
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
%ORIGINAL ABSTRACT
%MMOGs, or massively multiplayer online games, are applications which require much network bandwidth to function properly. In a distributed MMOG server architecture, with heterogeneous resources, the server nodes may become easily overloaded by the high demand from the players for state updates. Much work has been done in order to distribute the load on the server nodes, but this load is usually defined as the number of players on each server, what is not an ideal measure. Also, the heterogeneity of the system is frequently overlooked. In this work, we propose a balancing scheme which has two main goals: allocate load on the servers proportionally to the each one's power and reduce as much as possible the overhead from the distribution, considering the load as the occupied bandwidth of each server. It is divided in three phases: local selection of servers, balancing and refinement. Four algorithms were proposed, from which \ggp\ is the best for overhead reduction and \ggpf\ is the most suited for reducing player migrations between servers. We also make a review of related works and some comparisons were made, where our approach performed better.
%
%SHRUNK ABSTRACT
In a distributed MMOG (massively multiplayer online game) server architecture, the server nodes may become easily overloaded by the high demand from the players for state updates. Many works propose algorithms to distribute the load on the server nodes, but this load is usually defined as the number of players on each server, what is not an ideal measure. Also, the possible heterogeneity of the system is frequently overlooked. We propose a balancing scheme with two main goals: allocate load on server nodes proportionally to the each one's power and reduce the inter-server communication overhead, considering the load as the occupied bandwidth of each server. Four algorithms were proposed, from which \ggp\ is the best for overhead reduction and \ggpf\ is the most suited for reducing player migrations between servers. We also make a review of related works and some comparisons were made, where our approach performed better.

\keywords{MMOGs \and load balancing \and distributed server \and graph partitioning}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\section{Introduction}
\label{sec:intro}



The main characteristic of massively multiplayer online games is the large number of players, having dozens, or even hundreds, of thousands of participants simultaneously. This large number of players interacting with one another generates a traffic on the support network which may grow quadratically compared to the number of players \cite{chen2006gta}, in the worst case (Figure \ref{fig:quadratic}).

\begin{figure}
  \centering
  \includegraphics[width=0.6\linewidth]{images/quadratic}
  \caption{Quadratic growth of traffic when avatars are close to each other}
  \label{fig:quadratic}
\end{figure}

When using a client-server architecture, it is necessary that the server intermediates the communication between each pair of players -- assuming that the game is intended to provide guarantees of consistency and resistance to cheating. Obviously, this server will have a large communication load, thus, it must have enough resources (available bandwidth) to meet the demand of the game. We consider here that the main resource to analyse is the available bandwidth, for this is the current bottleneck for MMOGs \cite{feng2007wnn}.

The problem is that, when using a distributed server, it must be delegated to each server node a load proportional to its power. Thus, no matter to which server each player is connected, their game experience will be similar, regarding the response time for their actions and the time it takes to be notified of actions from other players as well as of state changes in the virtual environment of the game.
	
An initial idea might be to distribute the players among servers, so that the number of players on each server would be proportional to that server's bandwidth. However, this distribution would not work, for the burden caused by players also depends on how they are interacting with one another. For example, if the avatars of two players are too distant from each other, probably there will be no interaction between them and therefore the server needs only to update each one of them with the result of their own actions. However, if these avatars are close to each other, each player should be updated not only of his own actions, but also of the actions of the other player.
	
Normally, players can freely move their avatars throughout the game world. This makes possible the formation of \emph{hotspots} \cite{ahmed2008mol}, around which the players are more concentrated than in other regions of the virtual environment (Figure \ref{fig:avatarsdistribution}). Moreover, many massively multiplayer online RPGs not only permit but also stimulate, to some extent, the formation of these points of interest. In the worlds of these MMORPGs, there are entire cities, where the players meet to chat, exchange virtual goods or even fight, and there are also desertic areas, with few attractions for the players, and where the number of avatars is relatively small compared to other places of the environment.

\begin{figure}
  \centering
  \includegraphics[width=1.0\linewidth]{images/avatarsdistribution}
  \caption{Distribution of avatars with and without hotspots}
  \label{fig:avatarsdistribution}
\end{figure}

For this reason, it is not enough just to divide the players between servers, even if this division is proportional to the resources of each one of them. First, in some cases the usage of the server's bandwidth may be square to the number of players, while in others it may be linear. It is shown in \cite{chen2006gta} that, in a group of avatars who are neighbors of one another, the rate of packets sent to each player is proportional to the number of avatars in that group (as in Fig. \ref{fig:quadratic}). This reason alone is enough to define a new criterion for load balancing.

Moreover, there is another important issue: the overhead of the distribution. As the servers need to communicate with one another, there must be a way to minimize this traffic, reducing the waste of resources of the server system. The load balancing scheme for MMOGs must, then, prevent the presence of hotspots from degrading the quality of the game beyond a tolerable limit.

Differently from other works, we propose here a balancing scheme which considers the upload bandwidth occupation of the server as the load to distribute, what is done among servers with different levels of resources, also reducing the inter-server communication overhead by using a greedy graph partition growing algorithm.

%[TODO:falar das pr�xima se��es]

\section{Related work}
\label{sec:related}

The servers receive the action performed by a player, calculate its outcome and send it to all interested players, who are usually those whose avatars are close to the avatar of the first player. If two players are split between different servers, each of these need not only to send the state update to the player served by it, but it has also to send the update to the server to which the other player is connected. This server, in turn, forwards that state update to the other player (Figure \ref{fig:overheadgeneration}).

\begin{figure}
 \centering
 \includegraphics[width=0.8\textwidth]{images/overheadgeneration}
 \caption{Overhead caused by the interaction of players connected to different servers}
 \label{fig:overheadgeneration}
\end{figure}

It is perceived, then, that each state will be sent twice for each pair of players who communicate through different servers. This overhead not only causes the waste of resources of the servers, but it also increases the delay to update the status of the replica of the game in the players' machines, damaging the interaction between them.
	
Therefore, players who are interacting with each other should, ideally, be connected to the same server. However, it is possible that all players are linked through relations of interaction. For example, two avatars of two different players, may be distant from each other, but both could be interacting with a third avatar, between them. Anyway, it is still necessary to divide the players among servers. The question is how many pairs of players and which of them will be divided into different server nodes. It is therefore necessary to decide a criterion to group players. Many works have been done in the past -- such as \cite{devleeschauwer2005dma,lu2006lbm,chen2005lad,duong2003dls,ahmed2008mol} --  trying to find a near optimal, yet fast, load balancing technique.

In \cite{devleeschauwer2005dma}, for example, a few algorithms are proposed. Their idea is to transfer regions managed by overloaded servers to  lightly loaded ones, in a way such that the maximum overload among the servers is reduced. Some very interesting principles are used, as the concepts of microcells and macrocells (which will be described in the next section). However, their model has some differences to ours. For instance, they consider the number of players as the load to distribute, heterogeneous systems are not supported, and the algorithm they use to refine an existing partitioning is simulated annealing. This one may be a little too general, considering that there are algorithms specific to partitioning, such as \cite{kernighan1970ehp} or \cite{fiduccia1982lth}, which may perform better. Finally, some of the algorithms proposed in \cite{devleeschauwer2005dma} do not consider the communication overhead between servers.

It is proposed in \cite{lu2006lbm} a load balancing of cpu usage among the nodes of a cluster. The load balancing is done by an ``off the shelf'' NAT load balancer, which distributes the players' connections among the cluster nodes in a round-robin manner. Thus, each cluster node will end up with the same number of players, on the average. This approach, although it does balance the number of clients per cluster node, communication between the server nodes is not considered, for they are connected via a high-speed and low latency network. Furthermore, in this work we are not concerned with cpu usage, but bandwidth occupation.%OK

Chen et al. propose, in \cite{chen2005lad}, a load shedding technique, in which an overloaded server attempts do shed its load to its neighbors. After finding a lightly loaded neighbor server -- if there is one -- it transfers some of its boundary microcells to that neighbor. To form the group of microcells to transfer, a microcell from the border is chosen, and others are added in a breadth-first search (BFS) order. A very similar work, which also uses BFS, is described in \cite{duong2003dls}. However, these models present a few points which could be improved. For example, a server is considered overloaded when a certain number $N$ of players is reached. As we said before, this is not the best measure, since the load on a server may vary completely, depending on how these $N$ players are distributed across the region managed by the server. Also, the use of BFS to merge two partitions or split one of them may not be ideal. Some other algorithm for graph partitioning applied to distributed systems \cite{kernighan1970ehp,fiduccia1982lth,karypis1999fah,hendrickson1995isg} could be used, for most of these algorithms were designed exactly to balance load and minimize dependence between nodes.

Ahmed and Shirmohammadi propose a microcell oriented load balancing model \cite{ahmed2008mol}. To balance the load, their algorithm, first, finds all clusters of microcells which are managed by the overloaded server. After that, the smallest cluster (in number of microcells) is selected and then, from that cluster, it is chosen the microcell with the lowest communication with other microcells managed by the same server. The chosen microcell is then transferred to the least loaded server. This process is repeated while the server is still overloaded and there are servers which can handle the extra load of the microcells being transferred. The authors define the load on a server, as opposed to other load balancing schemes, as the summing of the message rate of every player that a server must handle, which is a much more realistic measure than the number of players on the server. Also, their model for load balancing tries to minimize the inter-server communication, improving the overall system performance. Their model will be compared to ours, for it takes into consideration many of the aspects that we consider. The comparison will be performed through some simulations, which are described in section \ref{sec:simulations}.

Next, some principles, defined in previous works, will be presented. Based on some of these principles, and on research and implementation carried out, it will be defined the load balancing scheme proposed here.

\subsection{Microcells and macrocells}
\label{sec:micro}

%O balanceamento de carga entre servidores de jogos online maci�amente multijogador � fortemente dependente da distribui��o dos avatares dos jogadores atrav�s do ambiente virtual. Al�m disso, a depender da concentra��o de avatares, pode-se alternar entre uma fun��o de crescimento de tr�fego linear e uma fun��o quadr�tica. Sendo assim, � necess�rio lidar com a localidade dos avatares, de maneira a otimizar o uso de largura de banda do sistema servidor, minimizando, tanto quanto poss�vel, o overhead causado pela comunica��o entre jogadores ligados a servidores diferentes.

One way to explore the locality of the players is by grouping them according to the position occupied by their avatars in the virtual environment. %The question would be how to form such groups. One way of doing this would be dividing the world of the game in several cells connected to one another. Each cell would be a part of the world, with its own content and characteristics, which would be assigned to a server node. The easiest way to do this is with a grid of cells of the same size and shape.
%
%[TODO:footnote?]Por�m, o formato e a disposi��o destas c�lulas ir� influenciar no tr�fego gerado pelas mesmas entre os servidores. Por exemplo, um ambiente bidimensional poderia ser dividido em uma grade de c�lulas quadradas. Neste caso, cada uma destas c�lulas teria oito vizinhos, em m�dia -- c�lulas nas bordas do mapa poderiam ter cinco ou tr�s vizinhos apenas. Quanto mais servidores vizinhos, maior o tr�fego entre servidores, e maior o overhead causado por esta comunica��o. A distribui��o ideal, ent�o, seria utilizando c�lulas hexagonais, cada uma com seis vizinhos. Estudos comprovam que esta � a divis�o em c�lulas iguais que permite o menor n�mero de vizinhos por c�lula [TODO:ref]. Outra possibilidade seria utilizando fileiras alternadas de c�lulas quadradas, onde cada fileira seria deslocada o equivalente � metade do comprimento de uma c�lula.
%
%[TODO:figura com diferentes tipos de divis�o:sqr/hex/shift]
%
%**	
%An important aspect of this design is that the concept of cell is transparent to the players. They see a wide, single and contiguous world, even if they are repeatedly crossing the boundaries between different cells. Obviously, this requires that the cells communicate, updating and notifying each other of events that occurred near the border between them, and of the migration of players from one to the other.
%
%Although this approach with cells distribute the load among several servers, there are no guarantees that this distribution will be uniform, because of the high mobility of players and the existence of hotspots.
One of the ideas proposed in the literature \cite{devleeschauwer2005dma} follows the principle of dividing the virtual environment in cells of fixed size and position. These cells are relatively small -- or \textbf{microcells} -- and they can be grouped, forming an area called \textbf{macrocell}. Each macrocell is then assigned to a different server, which will manage not a large cell of fixed size and position, but a variable set of small cells. These microcells can then be moved dynamically between different macrocells, maintaining the load on each one of the servers under a tolerable limit.

%[TODO: tirar todas as contra��es!]
Obviously, the microcells designated to the same server node do not generate additional traffic to synchronize with each other, but the synchronization overhead of the macrocell is unpredictable, because the number of neighbors of each one of them is not foreknown, for its shape is variable. However, it was demonstrated \cite{devleeschauwer2005dma} that this overhead is compensated by a better distribution of the load between servers in the game. %Figure [TODO: ref] illustrates the division of a virtual environment in two-dimensional microcells.
%It is illustrated in [TODO: ref] in the grouping of these micro macroc�lulas dynamics, which can adapt to the distribution of avatars.

%[TODO: figuraS com microc�lulas e macroc�lulas - fazer vetorial ou copiar? depende do tempo que tiver depois de terminar o texto. divisao em micro e agrupamento em macro]

\subsection{Load balancing in local scope}
\label{sec:local}
	
In \cite{lee2003sdl}, it is also proposed a scheme for dynamic load balancing for the servers of a multi-server virtual environment. Following the scheme proposed by the authors, an overloaded server starts the process by selecting a number of other servers to be part of the load redistribution. The set of selected servers depends on the load level of the initiating server as well as on the amount of idle resources of the other servers. After the formation of this set, its elements allocate portions of the virtual environment using a graph partitioning algorithm, so that the servers involved have similar final load.

To achieve this goal, the authors also subdivided the virtual environment in rectangular \textbf{cells} -- similar to the microcells --, where the number of servers is much smaller than the number of cells. The cells are grouped into \textbf{regions} -- or macrocells -- and each region is managed by one server (Figure \ref{fig:macromicro}). Each server handles all the interactions between avatars located in the region assigned to it. It receives the inputs of the players controlling these avatars and sends back to them the up-to-date game state. 

\begin{figure}
 \centering
 \includegraphics[width=0.4\textwidth]{images/macromicro}
 \caption{Cells grouped into four regions (R$_1$, R$_2$, R$_3$ and R$_4$)}
 \label{fig:macromicro}
\end{figure}

Two cells are called adjacent (or neighbors) if they share a border. Similarly, two regions -- and the servers assigned to them -- are called adjacent (neighbors) if there is a pair of adjacent cells, each of which belonging to one of the two regions. The workload of a cell was defined as the number of avatars present in that cell. The authors assumed that all players receive state updates of the same length and in the same frequency, so that the burden of processing (computing and communication) that a cell requires from a server is proportional to the number of users in that cell. The workload of a region and its designated server is defined as the sum of the individual workloads of the cells which form the region. Each server periodically evaluates its workload and exchange this information with its neighbors. They have assumed, too, that these servers are connected through a high-speed network. Thus, the overhead to exchange workload information among neighbors is limited and considered negligible compared to other costs of the distribution. For the same reason, they also assumed as negligible the overhead of communication between servers in different regions when players are interacting.

The main aspect of the solution proposed by the authors was the use of local information (the server that initiated the balancing process and its neighbors), rather than global information (involving all servers in the balance). When a server is overloaded, it searches for lightly loaded servers close to it in the overlay network. A breadth-first lookup for lightly loaded neighbor servers -- as proposed in \cite{duong2003dls} -- causes a small overhead, but it may not solve the problem efficiently in a few steps, as overloaded servers tend to be adjacent. The global approach, in turn, is able to divide the workload in the most balanced way possible, but its complexity may become too high.

The solution proposed by the authors is then by involving only a subset of servers, such that its cardinality varies according to the need (if the neighbors of the server which triggered the load balancing are also overburdened, more servers are selected). However, this set is formed in a more clever way than by simply using a breadth-first search. The algorithm used to find the servers is described in the next section.

\subsubsection{Selection of a local server group to balance the load}
\label{sec:regselect}
	
A server starts the balancing when the load assigned to it is beyond its capacity. This server selects a number of other servers to get involved with the distribution. First, it chooses the least loaded server among its neighbors and sends a request that he participates in the load balancing. The chosen server rejects the request if it is already involved in another balancing group, otherwise it responds to the server with the load information of its own neighbors. If the selected neighbor server is unable to absorb all the extra workload of the initiating server, the selection is performed again among the neighbors not only of the overloaded server, but also the neighbors of the already selected servers. The selection continues until the workload of the first server can be absorbed -- that is, the workload of all selected servers becomes smaller than a certain limit.

Figure \ref{fig:lee2} illustrates the operation of the algorithm. All servers have the same capacity, each one being able to handle 100 users. First, the initiator server, $S_6$ is inserted into SELECTED and its neighbors ($S_2, S_5, S_7$ and $S_{10}$) are added to CANDIDATES (Figure \ref{fig:lee2}(a)). So $S_7$, which has the lowest workload among the servers in CANDIDATES, is selected and invited to participate in the load distribution. When $S_7$ sends to $S_6$ the workload information of its neighbors ($S_3, S_6, S_8$ and $S_{11}$), it is inserted into SELECTED and its neighbors, except $S_6$, are added to CANDIDATES (Figure \ref{fig:lee2}(b)). Now, $S_{11}$, which has the lowest workload among servers in CANDIDATES, is selected and invited to participate in the load distribution. However, $S_{11}$ rejects the invitation, because it is involved in another distribution, initiated by $S_{12}$. Thus, $S_{11}$ is removed from CANDIDATES and $S_{10}$ is selected because it now has the lowest workload among all servers in CANDIDATES (Figure \ref{fig:lee2}(c)). This process continues until the average workload is under a pre-defined threshold (Figure \ref{fig:lee2}(d) and Figure \ref{fig:lee2}(e)).

\begin{figure}
 \centering
 \includegraphics[width=1.04\textwidth]{images/localselection}
 \caption{Selecting the group of servers for local rebalance}
 \label{fig:lee2}
\end{figure}

After forming the local server set, the initiating server performs a load rebalancing in such group, using some graph partitioning algorithm. To map the virtual environment to a graph, each cell is represented by a vertex, whose weight equals to the number of avatars in that cell; and every two vertices which represent adjacent cells are connected by an edge. %Though the authors do not provide much detail, the next section will do a brief introduction to graph partitioning algorithms and its use in distributed systems.

%\subsubsection{Using graph partitioning for task distribution}
%\label{sec:regselect}
%
%Um problema cl�ssico de aloca��o de tarefas em sistemas distribu�dos � o da depend�ncia entre elas [TODO:refsDEdistGRAPH]. Tarefas dependentes entre si fazem com que os processadores nos quais elas est�o sendo executadas tenham que se comunicar para que o processamento possa continuar. Isso gera dois problemas principais: em primeiro lugar, o processamento como um todo � atrasado por causa do tempo de espera de cada transmiss�o e recebimento de mensagens -- supondo que a comunica��o entre os processos seja por meio de mensagens, como � o caso do MPI [TODO:ref].
%
%Para resolver este problema, s�o utilizados grafos, da seguinte maneira: o conjunto de tarefas a realizar � mapeado em um grafo com pesos. Cada v�rtice representa uma tarefa e cada aresta representa a comunica��o entre as tarefas. O peso de cada v�rtice representa o custo de processamento e o peso da aresta a carga de comunica��o. Para fazer a distribui��o, � feito um particionamento do grafo gerado. Cada parti��o ter� um conjunto de tarefas que ser�o executadas no mesmo nodo e, conseq�entemente, o atraso de comunica��o entre elas ser� relativamente pequeno [TODO:refbli]. No entanto, as arestas do grafo que ligam parti��es diferentes representam comunica��o entre diferentes nodos. A Figura [TODO:ref] ilustra essa situa��o.
%
%[TODO:figura do grafo de tarefas e depend�ncias, assim como particionamento com corte de arestas e diferentes particionamentos levando a diferentes cortes de aresta]
%
%Os algoritmos de particionamento do grafo de tarefas, geralmente, buscam atingir dois objetivos: gerar parti��es de peso aproximadamente igual, ou seja, cada nodo ter� uma carga computacional semelhante � dos outros; e minimizar o corte de aresta, ou seja, fazer com que a depend�ncia entre os conjuntos de tarefas seja a menor poss�vel, reduzindo a comunica��o entre os nodos de processamento. Por corte de aresta, entende-se o somat�rio dos pesos de todas as arestas que ligam v�rtices que est�o em parti��es diferentes. [TODO:reffig]
%
%O problema de particionamento de grafos � NP-completo [TODO:ref]. Contudo, j� foi feita bastante pesquisa nessa �rea, resultando em heur�sticas que obt�m boas solu��es, muitas vezes se aproximando de valores �timos [TODO:ref]. Uma das heur�sticas mais conhecidas � a de Kernighan e Lin \cite{kernighan1970ehp}, que tem como objetivo, partindo de duas parti��es iniciais quaisquer, chegar a duas parti��es com peso semelhante e corte de aresta reduzido. O algoritmo de Fiduccia e Mattheyses \cite{fiduccia1982lth} incrementa a solu��o de Kernighan e Lin, generalizando-a para hipergrafos, al�m de permitir que cada parti��o tenha uma fra��o diferente do peso total do hipergrafo.
%
%Existem outros algoritmos mais recentes, como os baseados em divis�o espectral [TODO:ref-33-e-20-karypisirreggraphs]. Este � computacionalmente caro, por envolver complexos de �lgebra linear, precisando autovetor associado ao menor autovalor da matrix laplaciana associada ao grafo [TODO:ref]. No entanto, o particionamento resultante � considerado excelente para uma vasta gama de problemas [TODO:ref]. Existe tamb�m a abordagem em v�rios n�veis [TODO:citemultilevel], atrav�s da simplifa��o do grafo por meio de contra��o dos mesmos e sobreposi��o das arestas correspondentes. Com o grafo mais simples, � aplicado algum algoritmo de particionamente e ent�o ele se desdobra, j� particionado, at� o grafo original. Eventualmente, refinamentos no particionamento podem ser necess�rios. Esta �ltima t�cnica � especialmente �til em grafos com grande n�mero de v�rtices, na ordem de centenas a milhares, ou mais. Na figura [TODO:ref] � ilustrado esse particionamento em v�rios n�veis.
%
%[TODO:figura do multilevel]
%
%Contudo, MMOGs s�o geralmente aplica��es de tempo-real, al�m de a carga imposta sobre os servidores mudar constantemente em tempo de execu��o. Por esse motivo, o algoritmo de particionamento utilizado deve ser r�pido, tornando invi�vel o uso da divis�o espectral. � proposto neste trabalho utilizar um algoritmo guloso, mais simples, definido em [TODO:aOUTRArefdekarypis], que pode n�o atingir solu��es t�o boas quanto as da divis�o espectral, por�m � consideravelmente mais r�pido. Al�m disso, o custo para encontrar uma solu��o muito pr�xima do �timo n�o se justifica no contexto de MMOGs, pelo fato dos pesos mudarem constantemente, precisando de um novo particionamento em relativamente pouco tempo. J� quanto ao particionamento em v�rios n�veis, seu uso n�o foi considerado necess�rio pois o n�mero de v�rtices do grafo que representar� o ambiente virtual � relativamente pequeno.
%
%%TODO:ver esse "defini��es e parametros"
%Nas pr�ximas se��es, ser� apresentada a solu��o proposta neste trabalho para balanceamento de carga, come�ando pelas defini��es e par�metros utilizados, assim como ser� descrito como o problema foi mapeado para grafos e quais os objetivos e crit�rios do esquema proposto.

\section{Proposed load balancing scheme}
\label{sec:scheme}

In the previous section it was presented some existing works regarding load balancing in MMOGs when using multiple servers to provide the support network. The load balancing scheme proposed in this work is based on some of the principles in the literature. One of them is the division of the virtual environment in microcells, for later grouping in macrocells. This is a relatively simple way of addressing the issue of the avatars' movement dynamics through the game world, by transferring the microcells dynamically according to need.

It will also be used the idea of balancing based only on local information -- each server, when needing to reduce its workload, selects only a few other servers to join a local load rebalancing. Thus, we can greatly reduce the complexity of balancing because it will not be necessary that all servers in the game exchange messages among themselves every time that any one of them is overloaded.

To define our load balancing approach, we cannot ignore that, usually, the traffic generated by the players is not simply linear, but square for each cluster of players. Such misunderstanding can generate considerable differences between the actual load of each server and the load estimated by the balancing algorithm. Another point to consider is the overhead, both in the delay of sending messages, as in the use of bandwidth of the servers, when players connected to different servers are interacting with each other. Some works assume that the servers are all in the same high-speed and low latency local-area network, and therefore overhead is negligible. However, when considering a geographically distributed server system, this assumption cannot be made. This overhead must be taken into account, no matter which load balancing algorithm is being used.

Another important point is that the main criterion we use when balancing the load of MMOG servers is the bandwidth, and not processing power. Several games, such as Age of Empires \cite{ageofempires}, include simulations of virtual environments with hundreds or thousands of entities, which are performed smoothly on current personal computers. However, if this game was multiplayer and each of these entities was controlled by a different player on the Internet, it would most likely generate a traffic amount which would hardly be supported by a domestic connection \cite{feng2007wnn}.

%TODO: explicar porque cresce linearmente
Moreover, the upload bandwidth must be taken into account, much more than download. This happens for two reasons: first, the usage of the download bandwidth of each server node grows linearly with the number of players connected to it, while the usage of the upload bandwidth may have a quadratic growth, getting quickly overwhelmed; second, domestic connections -- which are majority in volunteer peer-to-peer systems -- usually have an upload bandwidth much lower than the download one.

There are also other issues which must not be overlooked. One of them is that the server system is probably not homogenous -- considering that it is geographically distributed with, likely, different connections to the Internet. Therefore, one cannot assume that the servers have the same amount of cpu power or network bandwidth. % Another problem, specific to the algorithm proposed by \cite{lee2003sdl}, is that the criterion to allocate to each server a load equivalent to 90\% of its capacity in order to avoid constant rebalancing is weak. There are no guarantees that the server system has 11.11\% more total capacity than the necessary. On the contrary, it should adapt to situations of widespread overload. Moreover, the criterion for stopping is weak because the algorithm does not stop when the whole system is loaded above 90\% of its capacity, or if the overloaded server has no neighbors capable of receiving more load.
In the next section, we make some definitions that will be necessary to specify our load balancing scheme.


%[TODO:introduzir as se��es]
	
%However, an important idea that was suggested was the use of graphs to represent the virtual environment, and the use of graph partitioning algorithms to perform load balancing. In the following section, will be a brief introduction about this principle, which is the basis of load balancing scheme proposed here.

\subsection{Definitions}
\label{sec:def}

We also use the idea of mapping the virtual environment on a graph. The graph will then be partitioned to distribute the workload of the game between the different servers. It is necessary first to define some terms which will be used on the proposed algorithms.

%TODO:definir um por um em detalhes, depois enumer�-los no par�grafo acima ^ para o leitor n�o se perder

\begin{itemize}
	\item \textbf{Server}: here, server is defined as a node belonging to the distributed system to serve the game. Each server can be assigned a single region;
	\item \textbf{Server power}: the server power, $p(S)$ is a numerical value proportional to the server's upload bandwidth;
	\item \textbf{Server power fraction}: given a set of servers $Servers$ = $\{S_1, S_2, ..., S_n\}$, the power fraction of a server $S$, $frac_p(S)$, is equal to its power divided by the summed power of all servers in $Servers$:
	
	%**
		\begin{center}
			$frac_p(S) = \frac{\displaystyle p(S)}{\displaystyle\sum_{i=1}^{n} p(S_i)}$
		\end{center}
		
	\item \textbf{System power}: the total power of the system, $P_{total}$, equals the sum of the powers of the $n$ servers which form it:
	
		\begin{center}
			$\displaystyle P_{total} = \sum_{i=1}^{n} p(Si)$
		\end{center}
	
	\item \textbf{Cell}: similar to the microcells, it is considered here the environment being divided into small cells, each one with fixed size and position. If two cells share a border, they are said to be \textbf{adjacent} or \textbf{neighbors};
	\item \textbf{Region}: the cells are grouped, forming what is called regions. Usually these areas are contiguous, although in some cases the subgraph that represents them may be disconnected, resulting in the presence of cells isolated from each other. Each region is assigned to a server, and only one, and $s(R)$ is the server associated to the region $R$. It may be referred throughout the text to region's ``power'', which in fact refers to the power of the server associated with that region, i.e. $p(s(R))$;
	%[TODO:ver se realmente precisa do item intera��o, ou se nao eh melhor usar relevancia mesmo]
	\item \textbf{Relevance}: the relevance of an avatar $A_j$ to another one, $A_i$, determines the frequency of updates of the state of $A_j$ the server should send to the player controlling $A_i$ \cite{bezerra2008a3}. It may be represented by the function $R(A_i,A_j)$;
	\item \textbf{Avatar's weight}: to each avatar there are various other entities (here, we only consider avatars) of the game, each with a frequency of state updates that need to be sent to the player who controls that avatar. Thus, for each avatar $A$ , its individual weight -- or of upload bandwidth that the server uses to send state updates to its player -- $w_a(A)$ depends on which other entities are relevant to it, and how much. 
	%**
	Let $\{A_1, A_2, ..., A_t\}$ be the set of all avatars in the virtual environment, we have:
	
		\begin{center}
			$\displaystyle w_a(A) = \sum_{i=1}^{t} R(A,Ai)$
		\end{center}
				
	\item \textbf{Cell's weight}: here, the total weight of a cell (or the use of upload bandwidth of its server) will be equal to the sum of the individual weights of the avatars in it. Consider cell $C$, where the avatars $\{A_1, A_2, ..., A_n\}$ are present. Also, consider that the avatars $\{A_1, A_2, ..., A_t\}$ are all the avatars in the virtual environment. The weight of this cell, $w_c(C)$, is:
	
		\begin{center}		
			$\displaystyle w_c(C) = \sum_{i=1}^{n} w(Ai) = \sum_{i=1}^{n} \sum_{j=1}^{t} R(A_i,A_j)$
		\end{center}
		
	\item \textbf{Region's weight}: the weight of a region is the sum of the weights of the cells that compose it. Let $R$ be the region formed by $\{C_1, C_2, ..., C_p\}$. The weight of $R$ is:
	
		\begin{center}
			$\displaystyle w_r(R) = \sum_{i=1}^{p} w_c(Ci)$
		\end{center}
		
		\item \textbf{Region's weight fraction}: given a set of regions $Regions  = \{R_1, R_2, ..., R_n\}$, the weight fraction of $R$, relative to $Regions$, is:
	
		\begin{center}
			$frac_r(R) = \frac{\displaystyle w_r(R)}{\displaystyle\sum_{i=1}^{n} w_r(R_i)}$
		\end{center}
		
	\item \textbf{Region's resource usage}: fraction that indicates how much of the power of the server of that region is being used. It is defined by:
	
		\begin{center}
			$u(s(R)) = \frac{\displaystyle w_r(R)}{\displaystyle p(s(R))}$	
		\end{center}
		
	\item \textbf{World weight}: the total weight of the game, $W_{total}$, will be used as a parameter for the partitioning of the virtual environment. It is defined as the sum of the weights of all cells. Let $\{C_1, C_2, ..., C_w\}$ be the set of all cells in which the game world is divided, we have:
	
		\begin{center}
			$\displaystyle W_{total} = \sum_{i=1}^{w} w_c(Ci)$
		\end{center}
	
	%explicar o pq da carga ser isso (upload)
	
	\item \textbf{System usage}: fraction that indicates how much resources of the system as a whole is being used. It is defined by:

		\begin{center}
			$\displaystyle U_{total} = \frac{W_{total}}{P_{total}}$
		\end{center}
	
	\item \textbf{Cell interaction}: the interaction between two cells is equal to the sum of all interactions between pairs of avatars where each one of them is located in one of these cells. The interaction between cells $C_i$ and $C_j$ is given by:
	
		\begin{center}
			$\displaystyle Int_c(C_i,C_j) = \sum_{i=1}^{m} \sum_{j=1}^{n} R(A_i,A_j)$,
			
			where $A_i$ is in $C_i$ and $A_j$ is in $C_j$.
		\end{center}
	
	\item \textbf{Overhead between two regions}: if there is only one server and one region, comprising the entire virtual environment of the game, the use of the upload bandwidth of the server will be proportional to $W_{total}$. However, due to its distribution among various servers, there is the problem of having players from different regions interacting with each other very close to the border between the regions (Figure \ref{fig:interactingregions}). Because of that, each state update of these players' avatars will be sent twice. For example, let $A_i$ be the avatar of the player $P_i$, connected to the server $S_i$, and $A_j$ the avatar of the player $P_j$, connected to the server $S_j$. In order for $P_i$ to interact with $P_j$, it is necessary that $S_i$ sends the state of $A_i$ to $S_j$, which then forwards to $P_j$. The same happens on the other way around. The overhead between regions $R_i$ and $R_j$ is equal, therefore, to the sum of interactions between pairs of cells where each one of them is in one of these regions. If $R_i$ and $R_j$ have respectively $m$ and $n$ cells, we have that the interaction -- or overhead -- between them is given by:
	
	  \begin{center}
			$\displaystyle Int_r(R_i,R_j) = \sum_{i=1}^{m} \sum_{j=1}^{n} Int_c(C_i,C_j)$,
			
			where $C_i \in R_i$ e $C_j \in R_j$.
	  \end{center}

	\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{images/interactingregions}
	\caption{Players interacting across a border between regions}
	\label{fig:interactingregions}
	\end{figure}
  	
  \item \textbf{Total Overhead}: the total overhead on the server system is calculated as the sum of overheads between each pair of regions. So we have:

    \begin{center}
      $\displaystyle OverHead = \sum_{i} \sum_{j, j \neq i} Int_r(Ri,Rj)$
    \end{center}

\end{itemize}

As the concepts needed to understand the proposed load balancing scheme have been defined, now it will be described how the virtual environment is mapped on a weighted graph, which will then be partitioned. Let $GW = (V,E)$ be a graph that represents the game world, where $V$ is the set of vertices and $E$ is the set of edges connecting vertices. Each component of this graph, and what it represents, is described below:

\begin{itemize}
	\item \textbf{Vertex}: each vertex in the graph represents a cell in the virtual environment;
	\item \textbf{Edge}: each edge in the graph connects two vertices that represent adjacent cells;
	\item \textbf{Partition}: each partition of the graph $GW$ -- a subset of the vertices of $GW$, plus the edges that connect them -- represents a region;
	\item \textbf{Vertex weight}: the weight of each vertex is equal to the weight of the cell that it represents;
	\item \textbf{Edge weight}: the weight of the edge connecting two vertices is equal to the interaction between the cells represented by them;
	\item \textbf{Partition weight}: the weight of a partition is equal to the sum of the weights of its vertices, i.e. the weight of the region that it represents;
	\item \textbf{Edge-cut}: the edge-cut in a partitioning is equal to the sum of the weights of all the edges which connect vertices from different partitions. This value is equal to the sum of the overheads between each pair of regions. Thus, the edge-cut of the graph $GW$ is equal to the total overhead on the server system.
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{images/mapping}
\caption{Mapping of the virtual environment on a graph}
\label{fig:mapping}
\end{figure}

Figure \ref{fig:mapping}(a) illustrates how the mapping is done with square cells, while figure \ref{fig:mapping}(b) shows how it would be with hexagonal cells. The objective of the balancing scheme proposed here is to assign to each server a weight proportional to its capacity, reducing as much as possible the edge-cut of the graph that represents the virtual environment and, consequently, reduce the overhead inherent to the distribution of the game on multiple servers. Although this is an NP-complete problem \cite{feder1999cgp}, efficient heuristics will be used to reduce this overhead. In the following sections the algorithms proposed in this work will be presented.

\subsection{Proposed algorithms}
\label{sec:alg}
	
It is considered that an initial division of the virtual environment has already been made. Each server should then check regularly if there is an imbalance and trigger the algorithm. Although the overhead resulting from the distribution of the virtual environment is part of the workload on servers, there is no way to know it beforehand without executing the repartitioning first. For this reason, the ``weight'' to be distributed does not include this extra overhead.

When there is an unbalanced region, it is selected a local group of regions, similar to what was shown in section \ref{sec:local}, but with some changes (section \ref{sec:alg:localselect}). After this selection, it will be used an algorithm whose parameters are only the loads of the cells and their interactions, for such data is available prior to distribute. Finally, with the regions already balanced, the algorithm of Kernighan and Lin \cite{kernighan1970ehp} will be used to refine the partitioning, reducing the edge-cut and, thus, the overhead, while keeping the balance.

The proposed scheme is then divided into three phases:

\begin{enumerate}
	\item Select the group of local regions;
	\item Balance these regions, assigning to each one a weight which is proportional to the power of its server;
	\item Refine the partitioning, reducing the overhead.
\end{enumerate}

% [TODO: see if the put option or have not disbal tolerance, both here and in the transfer (BFA) / overhead (kl)]
% [: Independent that I can for the graphics and implementation "version without disbal tolerance with X"]
A decision to this balancing scheme is that a region $R$ is considered overloaded only when the use of its resources is greater than the total use of the system, also considering a certain tolerance, $tol$, to avoid constant rebalancing. Thus, the server starts the balancing of $R$ when, and only when, $u(s(R)) > U_{total} \times tol$. Thus, even if the system as a whole is overburdened, a similar quality of game will be observed among the different regions, dividing the excessive weight between all servers fairly. What can be done when $U_{total} > 1$ is gradually reduce the amount of information sent in each state update, leaving for the application the task of extrapolating the missing information based on previous updates.
% [TODO: advantages and disadvantages by then]

Another important aspect is that each server always has an associated region. What might happen would be a region being empty -- without any cells -- and its server not participating in the game. This is useful when the total capacity of the server system is much greater than the total load of the game, or $ P_{total} \gg W_{total}$. In this case, the introduction of more servers would only increase the communication overhead of the system, without improving its quality -- except when introduced to provide fault tolerance.

The algorithms were developed oriented to regions, instead of servers, in order to be more legible, because of the constant transfers of cells. Moreover, it becomes easier to extend, in the future, the balancing model used here to allow more than one server managing the same region. The proposed algorithms are described as follows. The one in section \ref{sec:alg:localselect} is for phase 1, the sections \ref{sec:alg:ggp} to \ref{sec:alg:bfa} are alternatives for phase 2 and the algorithm in section \ref{sec:alg:kl} is the refinement of phase 3.

\subsubsection{Local regions selection}
\label{sec:alg:localselect}

The algorithm for selection of regions (Algorithm \ref{alg:local}) aims to form a set of regions such that the average usage of resources of the servers of these regions is below a certain limit. Starting from the server that has started the balancing, its neighboring regions with the least usage of resources are added. When the average usage is less than 1, or less than $ U_{total}$ (line \ref{alg:local:condition}), the selection ends and phase 2 begins, with the region set as input. These two conditions are justified because there are two possibilities: $U_{total} \leq 1$ and $U_{total} > 1$.
	
In the case when $U_{total} \leq 1$, there is sufficient power in the system so that all servers have a usage smaller than 100\%. Thus, regions are added to the group until all the servers involved are using fewer resources than they have. However, when $U_{total} > 1$, there is no way to all servers be using less than 100\% of its resources at the same time. Thus, it is sufficient that all servers are similarly overburdened, and that some kind of adjustment is made, which will probably be a reduction in the information sent to players in each state update. Although this approach seems to lead the system to an inconsistent state, due to the lack of available bandwidth, the $U_{total}$ is calculated based on the theoretical value of a region's weight. In practice, the system as a whole will take two measures: first, the frequency at which state updates are sent to players is diminished and, second, it will deny access to new players who try to join the game. Denying access when the game is overpopulated with players is the usual policy adopted by some MMOGs.

If even after all the neighbors, and the neighbors of the neighbors and so on, are selected, the criterion is not met, empty regions -- belonging to idle servers -- will be inserted in the group (line \ref{alg:local:idleserver}) because the overhead of interaction between regions introduced by them is justified by the need for more resources.

\begin{algorithm}
\caption{Local regions selection}
\label{alg:local}
\begin{algorithmic}[1]
	 \STATE $\locgroup \leftarrow \{R\}$
	 \STATE $\wlocal \leftarrow w_r(R)$
	 \STATE $\caplocal \leftarrow p(s(R))$
	 \STATE $\avguse \leftarrow \frac{\wlocal}{\caplocal}$
	 \WHILE{$\avguse > max(1, U_{total})$} \label{alg:local:condition}
	 		\IF{there is any not selected region neighbor to one of $\locgroup$}
	 			 \STATE $R \leftarrow$ not selected region neighbor to one of $\locgroup$, with smallest $u(s(R))$
	 		\ELSIF{there is any empty region} \label{alg:local:idleserver}
	 			 \STATE $R \leftarrow$ empty region with highest $p(s(R))$
	 		\ELSE
	 			 \STATE stop. no more regions to select.
	 		\ENDIF
	 		\STATE $\wlocal \leftarrow \wlocal + w_r(R)$
	 		\STATE $\caplocal \leftarrow \caplocal + p(s(R))$
	 		\STATE $\avguse \leftarrow \frac{\wlocal}{\caplocal}$
	 		\STATE $\locgroup \leftarrow \locgroup \cup \{R\}$
	 \ENDWHILE
	 \STATE run phase 2 passing $\locgroup$ as input.
\end{algorithmic}
\end{algorithm}

\subsubsection{\ggp} %repart
\label{sec:alg:ggp}
	
\textbf{\ggp}, or \ggpmeaning, seeks to allocate the heaviest cells to the regions managed by the most powerful servers. As input, the algorithm receives a list of the regions to balance. Details are shown in Algorithm \ref{alg:ggp}.


\begin{algorithm}
\caption{\ggp}
\label{alg:ggp}
\begin{algorithmic}[1]
	 \STATE $\wtodiv \leftarrow 0$ \label{alg:ggp:begingetlocalinfo}
	 \STATE $\freecap \leftarrow 0$
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wtodiv \leftarrow \wtodiv + w_r(R)$
	 		\STATE $\freecap \leftarrow \freecap + p(s(R))$
	 		\STATE temporarily free all cells from $R$ \label{alg:ggp:freeallcells}
	 \ENDFOR \label{alg:ggp:endgetlocalinfo}
	 \STATE sort $\rlist$ in decreasing $p(s(R))$ order \label{alg:ggp:sortregions}
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wshare \leftarrow \wtodiv \times \frac{p(s(R))}{\freecap}$ \label{alg:ggp:fraction}
	 		\WHILE{$w_r(R) < \wshare$} \label{alg:ggp:whilefraction}
	 		   \IF{there is any cell from $R$ neighboring a free cell}
	 		   		\STATE $R \leftarrow R \cup \{$neighbor free cell with the highest $Int_c(C)$$\}$ \label{alg:ggp:freeneighbor}
	 		   \ELSIF{there is any free cell}
	 		   		\STATE $R \leftarrow R \cup \{$heaviest free cell$\}$ \label{alg:ggp:freeheavycell}
	 		   \ELSE
	 		   		\STATE stop. no more free cells.
	 		   \ENDIF
	 		\ENDWHILE
	 \ENDFOR
\end{algorithmic}
\end{algorithm}

Like we said, it is passed as input a list of the regions whose load will be rebalanced. This makes possible the use of this algorithm both in local and global scope, just by choosing between passing some regions or all regions of the environment. The distribution is based on information from that set of regions, whose total weight and total power are calculated in lines \ref{alg:ggp:begingetlocalinfo} to \ref{alg:ggp:endgetlocalinfo}. To be redistributed later, all cells associated with these regions are released (line \ref{alg:ggp:freeallcells}).

To provide a partitioning which is balanced, proportional and with low edge-cut since the second phase of the balancing, the regions are sorted in decreasing order of server power (line \ref{alg:ggp:sortregions}). The \ggp\ then runs through this list, seeking to assign heavier cells to more powerful servers.%, while charges for areas with weak cell servers least loaded.

In line \ref{alg:ggp:fraction}, it is calculated the weight share for each region, considering the total weight that is being divided and the total power of the servers of those regions. The server power fraction of a region, $\frac{p(s(R))}{\freecap}$ should be the same fraction of weight that must be attributed to it. Even if this weight is greater than the power of that server, resulting in an overload, all the servers are similarly overloaded, satisfying the criterion of balance that has been defined. The condition for the end of the allocation of new cells in a region is that its weight is greater than or equal to its weight share.

It is important to notice that the while condition (line \ref{alg:ggp:whilefraction}) may lead to the assignment of a cell whose weight is higher than the weight share left on the region. However, it is very unlikely to assign to a region its exact weight share, so it is preferable to surpass this value, guaranteeing that every cell will be assigned to some region. Also, assigning to a region a weight which is higher than its calculated share does not imply that it will become overloaded. First, the weight share of a region is not equal to the power of its server. When there are enough resources, the region's weight share will be smaller than its capacity. Furthermore, as \ggp\ is a greedy algorithm, the heaviest cells will be assigned first, to the most powerful servers.

%The choice of cells to include in the region tries to put the most interacting pairs of cells in the same regions, reducing the overhead.% In each step, the algorithm not only tries to get a neighbor cell, but also the one with the highest that not only is free from a nearby cell already present in the region, but whose edge linking them is the heaviest possible. %Figure [TODO: reffig] shows an example of the steps of the growth of a region to achieve its share of the load balancing.

%A escolha de c�lulas para incluir na regi�o busca fazer com que cada uma das arestas mais pesadas do grafo $GW$ ligue v�rtices da mesma parti��o, reduzindo o corte de aresta e, assim, o overhead. A cada passo � dada prefer�ncia a escolher a c�lula livre que n�o apenas seja vizinha de uma c�lula j� presente na regi�o, mas tamb�m cuja aresta ligando-as seja a mais pesada poss�vel. A Figura \ref{fig:ggp} mostra um exemplo dos passos do crescimento de uma regi�o at� atingir a sua parcela de carga no balanceamento.

The criterion to choose a cell to include in the region is to make the heaviest edges on the graph $GW$ connect vertices in the same partition, reducing the edge-cut and, thus, the overhead. In each step, it is selected the cell which not only is adjacent to a cell already present in the region, but whose edge connecting them is the heaviest possible. This algorithm is based on a principle similar to the one used in GGGP \cite{karypis1999fah}, a greedy algorithm for graph partitioning. The objective of GGGP is to split a graph in two partitions of the same weight, while reducing the edge-cut with the heaviest edge heuristics. Figure \ref{fig:ggp} illustrates the steps of growth of a region until it reaches its load share.

%TODO: referenciar karypis e kumar, wow e outros jogos (eve-online, warhammer e cabal)
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{images/ggp}
\caption{Growth of a partition (region) with \ggp}
\label{fig:ggp}
\end{figure}

In the example of Figure \ref{fig:ggp}, there are two servers, $S_1$ and $S_2$, where $p(S_1) = 30$ and $p(S_2) = 18$. The total weight of the environment being repartitioned is $W_{total} = 32$. For the division to be proportional to the capacity of each server, the weights assigned to $S_1 $ and $S_2$ are 20 and 12, respectively. The selection starts with the vertex of weight 6 (free cell with the highest weight) and, after that, at each step the vertex connected by the heaviest edge is added to the partition. The selected edges and the vertices belonging to the new partition are highlighted.

In the first step of the cycle starting in line \ref{alg:ggp:whilefraction}, if the region does not have any cell yet, \ggp\ gets the heaviest free cell (line \ref{alg:ggp:freeheavycell}). The same occurs when a region is compressed between the borders of other regions and has no free neighbor, getting cells from somewhere else (Figure \ref{fig:compressed}). This may generate fragmented regions and possibly increase the overhead of the game. However, this happens more often in the last steps of the distribution, when most of the cells would be already allocated to some region. Because the algorithm is greedy, when it reaches that stage of its execution, the free cells would probably the lightest cells of the environment, causing little overhead.

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{images/compressed}
\caption{Formation of disconnected partition (fragmented region)}
\label{fig:compressed}
\end{figure}

\subsubsection{\ggpk} %v3

A possible undesirable effect of the \ggp\ algorithm is that by releasing all the cells and redistributing them, it might happen that one or more regions completely change their place, causing several players to disconnect from their servers and reconnect to a new one. To try to reduce the likelihood of such event, we propose a variation of the algorithm, called \textbf{\ggpk} (\ggpkmeaning). This new algorithm (shown in Algorithm \ref{alg:ggpk}) is similar to the original version, except that each region maintains its heaviest cell (lines \ref{alg:ggpk:saveheaviestcell} and \ref{alg:ggpk:getbackheaviestcell}), from which a region similar to the previous one can be formed, so that several players will not need to migrate to other server. However, to keep one of the cells of each region, it might be preventing a better balancing to occur. Also, the fixation of that cell might cause fragmented regions, increasing the overhead.

\begin{algorithm}
%\renewcommand{\ALG}{Algoritmo}
\caption{\ggpk}
\label{alg:ggpk}
\begin{algorithmic}[1]
	 \STATE $\wtodiv \leftarrow 0$
	 \STATE $\freecap \leftarrow 0$
	 \FOR{each $R$ in $\rlist$}
	 		\STATE $\wtodiv \leftarrow \wtodiv + w_r(R)$
	 		\STATE $\freecap \leftarrow \freecap + p(s(R))$
	 		\STATE $c \leftarrow $ heaviest cell from $R$ \label{alg:ggpk:saveheaviestcell}
	 		\STATE temporarily free all cells from $R$
	 		\STATE $R \leftarrow R \cup \{c\}$ \label{alg:ggpk:getbackheaviestcell}
	 \ENDFOR
	 \STATE sort $\rlist$ in decreasing $p(s(R))$ order \label{alg:ggp:sortregions}
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wshare \leftarrow \wtodiv \times \frac{p(s(R))}{\freecap}$
	 		\WHILE{$w_r(R) < \wshare$} \label{alg:ggpk:whilefraction}
	 		   \IF{there is any cell from $R$ neighboring a free cell}
	 		   		\STATE $R \leftarrow R \cup \{$neighbor free cell with the highest $Int_c(C)$$\}$
	 		   \ELSIF{there is any free cell}
	 		   		\STATE $R \leftarrow R \cup \{$heaviest free cell$\}$ \label{alg:ggpk:freeheavycell}
	 		   \ELSE
	 		   		\STATE stop. no more free cells.
	 		   \ENDIF
	 		\ENDWHILE
	 \ENDFOR
\end{algorithmic}
\end{algorithm}

\subsubsection{\ggpf} %v4
%[TODO: por desvantagens em outra se��o posteriores]
Another way of trying to minimize the migration of players between servers because of the rebalancing is the \textbf{\ggpf}, or \ggpfmeaning\ (Algorithm \ref{alg:ggpf}). In this algorithm, each region will gradatively release its cells in increasing order of weight, until its weight fraction is less than or equal to the power fraction of its server. Thus, the heaviest cells remain on the same server and, therefore, most players do not need to migrate. After that, the cells that were released are redistributed among the regions with lowest server resource usage (line \ref{alg:ggpf:usageorder}). The disadvantage of this algorithm is, as in \ggpk, the possibility of fragmenting the regions, with many isolated cells, increasing the overhead.

\begin{algorithm}
\caption{\ggpf}
\label{alg:ggpf}
\begin{algorithmic}[1]
	 \STATE $\wtodiv \leftarrow 0$
	 \STATE $\freecap \leftarrow 0$
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wtodiv \leftarrow \wtodiv + w_r(R)$
	 		\STATE $\freecap \leftarrow \freecap + p(s(R))$
	 		\STATE $\clist \leftarrow $ list of cells from $R$ in increasing order of weight
	 		\WHILE{$frac_r(R) > frac_p(s(R))$}
	 			 \STATE $C \leftarrow$ first element from $\clist$
	 			 \STATE remove $C$ from $R$
	 			 \STATE remove $C$ from $\clist$
	 		\ENDWHILE
	 \ENDFOR
	 \STATE sort $\rlist$ in increasing order of $u(s(R))$ \label{alg:ggpf:usageorder}
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wshare \leftarrow \wtodiv \times \frac{p(s(R))}{\freecap}$
	 		\WHILE{$w_r(R) < \wshare$} \label{alg:ggpf:whilefraction}
 		   	 \IF{there is any cell from $R$ neighboring a free cell}
	 		   		\STATE $R \leftarrow R \cup \{$neighbor free cell with the highest $Int_c(C)$$\}$
	 		   \ELSIF{there is any free cell}
	 		   		\STATE $R \leftarrow R \cup \{$heaviest free cell$\}$ \label{alg:ggpf:freeheavycell}
	 		   \ELSE
	 		   		\STATE stop. no more free cells.
	 		   \ENDIF
	 		\ENDWHILE
	 \ENDFOR\end{algorithmic}
\end{algorithm}

\subsubsection{\bfa} %v2
\label{sec:alg:bfa}

The \textbf{\bfa} (\bfameaning) is proposed here as an alternative to \ggp\ and its variants. The objective of the algorithm is to check what is the weight excess in each region and transfer it to free regions whose capacity is the closest to that value. This is done by transferring cells whose weight is the closest to free capacity of the receiving region, observed two restrictions: first, the total weight transferred can not be larger than the free capacity of the destination region and, second, we should not transfer a load greater than the necessary to eliminate the overload. The second restriction is justified because a weight transfer larger than necessary would probably result in a larger amount of migrating players. The exception to this rule is when a cell is heavier than the other, not for having more avatars, but because they are closer, with quadratic traffic growth between them. Algorithm \ref{alg:bfa} describes in detail the operation of \bfa.


\begin{algorithm}
\caption{\bfa}
\label{alg:bfa}
\begin{algorithmic}[1]

	 \FOR{each region $R_i$ in $\rlist$}
			\STATE $\wlose \leftarrow w_r(R_i) - W_{total} \times frac_p(s(R_i))$ \label{alg:bfa:wlose}
			\STATE $\destreg \leftarrow \rlist - \{R_i\}$
			\STATE sort $\destreg$ in decreasing order of $u(s(R))$ \label{alg:bfa:sort}
			\FOR{each region $R_j$ in $\destreg$}
				 \STATE $\regcap \leftarrow frac_p(s(R_j)) \times W_{total} - w_r(R_j)$ \label{alg:bfa:freecap}
				 \STATE $\wtoreg \leftarrow min(\wlose, \regcap)$ \label{alg:bfa:min}
				 \WHILE{$\wtoreg > 0$}
				 		\IF{$R_i$ has a cell $C$ such that $w_c(C) \leq \wtoreg$}
				 			 \STATE $C \leftarrow$ cell from $R_i$ with weight closest to, but not larger than, $\wtoreg$ \label{alg:bfa:bestfit}
				 			 \STATE $R_i \leftarrow R_i - \{C\}$
				 			 \STATE $R_j \leftarrow R_j \cup \{C\}$
				 			 \STATE $\wtoreg \leftarrow \wtoreg - w_c(C)$
				 			 \STATE $\wlose \leftarrow \wlose - w_c(C)$
				 		\ELSE
				 			 \STATE continue with next $R_j$. \label{alg:bfa:continue}
				 		\ENDIF
				 \ENDWHILE
			\ENDFOR			
	 \ENDFOR

\end{algorithmic}
\end{algorithm}


\subsubsection{Refining with the \kl\ algorithm}
\label{sec:alg:kl}
	
After balancing the load between servers in phase 2, all the servers will have a similar resource usage ratio. However, the algorithm in phase 2 cannot measure the final interaction between regions before repartitioning. This may lead to a partitioning that, although every server uses a similar percentage of its upload bandwidth to its clients, there may be a high inter-server communication overhead, causing a waste of resources of the server system.

To attenuate this problem, it is proposed here to use the algorithm of Kernighan and Lin \cite{kernighan1970ehp}. This algorithm receives as input the graph that represents the virtual environment. Given a pair of regions (partitions), \kl\ searches for pairs of cells (vertices) that, when exchanged between their regions, the overhead (edge-cut) is reduced.

%Let $R_A$ and $R_B$ be two regions and $a$ a cell such that $a \in R_A$. The external interaction of $a$ is defined as $E(a) = \sum_{b \in R_b} Int_c (a, b)$ and the internal interaction is defined as $I(a) = \sum_{a' \in R_A} Int_c(a, a')$. The cell $a$ is prone to change regions if its interaction with $R_B$ is greater than its interaction with $R_A$, i.e. $D(a) = E(a) - I(a) > 0$. Assuming that there is a cell $b \in R_B$ such that $D(a) + D(b) - 2 \times Int_c(a, b) > 0 $, the exchange will reduce the overhead between the regions. The term $D(a) + D(b) - 2 \times Int_c(a, b)$ is referred as $gain(a, b)$, because it represents the gain (reduction of overhead) of swapping the regions of $a$ and $b$.

In the case of a virtual environment distributed among various regions, generally more than two, \kl\ is run for each pair of regions. Moreover, after each swap performed by the algorithm, the balance must be kept -- otherwise, a completely unbalanced partitioning, with the lowest possible overhead, could be reached. The \kl\ algorithm is widely known in the area of distributed systems, so details will not be provided here. Consider only that it returns a value of $true$ if any change was made and $false$ otherwise. It runs for all pairs of regions. until it returns a value of false, indicating that no exchange will provide additional gain. Algorithm \ref{alg:kl} shows how the \kl\ algorithm is called.

%swapped = true;
%while swapped = true;
%	swapped = false;
%  for (each region R_i in reglist) {
%    for (each region R_j in reglist) {      
%      if kernighan-lin(R_i, R_j) = true
				  %swapped = true;
%    }
%  }
%}

\begin{algorithm}
\caption{\kl}
\label{alg:kl}
\begin{algorithmic}[1]

	\STATE $swapped \leftarrow$ \textbf{true}
	\WHILE{$swapped =$ \textbf{true}}
		\STATE $swapped \leftarrow$ \textbf{false}
		\FOR{each region $R_i$ in $\rlist$}
			\FOR{each region $R_j$ in $\rlist$}
				\IF{$Kernighan$-$Lin(R_i, R_j) =$ \textbf{true}}
					\STATE $swapped \leftarrow$ \textbf{true}
				\ENDIF
			\ENDFOR
		\ENDFOR
	\ENDWHILE

\end{algorithmic}
\end{algorithm}


\section{Simulations and results}
\label{sec:simulations}
%definir cada caso da simula��o e o porqu� dele, em que influenciam os parametros e o que se quer tirar de conclus�o
%mostrar quais parametros foram fixados em cada caso, o seu valor e o porqu� destes para destes par�metros terem sido fixados
%resultados: analisar, falar em ganhos em %, e buscar raz�es para estes ganhos/perdas.
%gr�ficos
%   I: migra��oXinstante, linhas, cada linha � um tipo de balanceamento
%	 II: migra��oXtipo de balanceamento, barras empilhadas: barra de baixo: walk migrations; barra de cima: still migrations
% III: desvio de u(S)Xinstante
%  IV: (wtotal+overhead)X(servidor(divido em tipos de bal. carga). barras p/ cada servidor: p(s); TB1 (carga + overhead); TB2 (c+oh); ... TBn (c+oh)
%   V: overheadXinstante(linhas, cada uma um tipo de bal.)
% N�O ENTRA, � DISPENS�VEL E N�O � BONITO OU SIMPLES DE FAZER (teria que ser um para cada tipo de balanceamento) -----> VI: weightXinstante (linhas: wtotal, w1, w2, ..., wnservs)


To perform the simulation of the load balancing, a virtual environment was simulated with various avatars. At first, the avatars are distributed uniformly throughout the virtual environment. As the simulation begins, they start to move according to the random waypoint model \cite{bettstetter2004spr}. However, the choice of which waypoint to go was not completely random. Three hotspots were defined, and there was a probability for the avatar to choose one of these hotspots as its next waypoint. Although this may be not very realistic, its purpose was to force an uneven distribution of avatars in the virtual environment, putting to test the load balancing algorithms. Those who take account of the existence of hotspots form the regions on this basis, reducing the distribution overhead.

As we said in section \ref{sec:related}, we also compare our algorithms to the one proposed by Ahmed and Shirmohammadi \cite{ahmed2008mol}. However, it is very important to observe that some changes have been made before simulating. First, the authors divide the virtual environment in hexagonal cells, and we simulate their algorithm on a grid-like division, with square cells. Moreover, as we consider an heterogeneous system, each server $S_i$ presents its own message rate threshold, $T_i^m$.
%
Nonetheless, we keep what we consider the core of their approach, which is the selection of the smallest cell cluster managed by the overloaded server, followed by the selection of the cell of that cluster which has the lowest interaction with other cells of the same cluster and, finally, the transference of the selected cell to the least loaded server.

The environment consisted of a two-dimensional space, divided into 225 cells, forming a matrix of order 15. There were 750 avatars. Each cell always belonged to some region, although it could be transferred to another region. There were eight servers ($S_1, S_2, ..., S_8$), each one of them associated to a region, each of which could have 0 to all 225 cells. The capacity of all servers was different, with $P(S_i) = i \times 20000$. Thus, it was possible to test whether the distribution obeyed the criterion of proportional load balancing. Each session of simulated game was 20 minutes long. The total weight of the game was purposely set in a way that it was greater than the total capacity of the system, forcing the triggering of the load balancing.

The evaluation of the load balancing algorithms was done in a more abstract level, taking into consideration the formulae defined in section \ref{sec:def}. The results presented here are calculated using those definitions -- the inter-server communication, for example, is the $OverHead$ defined in that section --, while the simulator software puts the avatars in movement, executing the load balancing algorithms as necessary, i.e. when the weight of a region violates the balance criteria defined in section \ref{sec:alg}.

\begin{figure}[!t]
  \centering
  \includegraphics[width=1.0\linewidth]{images/baloverall_ah}
  \caption{Overall comparison of proposed load balancing algorithms}
  \label{gra:baloverall}
\end{figure}

In Figure \ref{gra:baloverall}, we can see that all the algorithms simulated met the proportionality criterion in load balancing. However, some of them introduced more overhead than the others. The reason for this is the fragmented regions. The lower the number of fragments the regions have, the lower is this overhead because there are fewer boundaries between regions.

Observe that the algorithm \ggp\ is the one with the lowest overhead of all, as it was designed precisely to create the most possible contiguous regions, searching cells connected by the highest interactions, to minimize the algorithm overhead. The \bfa\ algorithm, however, was developed in order to distribute the load based on a best-fit allocation, seeking to balance it as much as possible, ignoring, in phase 2, the existence of interactions between cells and regions. For this reason, the \bfa\ was the one which created most fragmentation in the regions and thus most overhead between the servers.

% [TODO: fix the part of graphs etc., that you do not use more rating. section of the store for kl unify the terminology. dry settings]

Figure \ref{gra:baloverhead} shows the change in the total overhead on the server system, depending on playing time. It was observed that the overhead generated by each balancing algorithm varies relatively little with time, and the \ggp\ is the one which gives the lowest overhead in any moment of the game, and \bfa\ has the largest overhead of all, for almost the entire simulation. The algorithms \ggpk\ and \ggpf\ alternate with intermediate values of overhead. 

Ahmed's algorithm, in turn, presented the second highest average overhead. The most probable reason for this is the choice of the least loaded server to receive a microcell being transferred from an overloaded server. Though this is an obvious choice in terms of load balance, it does not consider that the least loaded server may have no microcell adjacent to the microcell being transferred, creating a fragmented region and, thus, increasing the overhead on the system.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.75\linewidth]{images/baloverhead_ah}
  \caption{Overhead introduced by each balancing algorithm during the game session}
  \label{gra:baloverhead}
\end{figure}

However, the introduction of overhead is not the only criterion considered. Fig. \ref{gra:balmigxtb} shows how was the migration of users between servers throughout the simulated game session, for each algorithm. The value of migration has been divided in two: \emph{walking migration}, which occurs when a player migrates to a new server because he moved his avatar from one region to another, and \emph{still migration}, which occur when a player exchanges servers without having moved. This kind of migration occurs because the cell where his avatar was has been transferred to another region as a result of a rebalancing of the load of the game. Walking migrations are more likely to happen when the regions are not contiguous.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.9\linewidth]{images/balmigxtb_ah}
  \caption{Players migrating while still or walking depending on algorithm}
  \label{gra:balmigxtb}
\end{figure}

	
We can see that \ggp\ is the one which has fewer walk migrations, precisely because their regions are contiguous. However, the fact of not trying to minimize the transfer of cells -- the \ggp\ main objective is to minimize the overhead -- the number of migrations is still the largest of all its variations, lower only than \bfa, which was also the worst algorithm on the user migration criterion. The strategy of \ggpk, and more strongly in the \ggpf, to maintain the maximum possible number of cells when rebalancing, has as a result the lowest numbers of migration of players of all the proposed algorithms.

The algorithm proposed by Ahmed had even less migrations than \ggpf. Though the number of walk migrations is the second highest -- as expected from a more fragmented partitioning --, the number of still migrations is almost negligible. We believe that a clever choice of cells to transfer led to this result. Cells which interact less with other cells will, probably, contain less avatars and, then, transferring them will not cause many player migrations.

% deviation
Another detail to be considered is the uniformity of distribution: all servers must have an usage rate as similar as possible so that the distribution is considered fair. To measure this uniformity, the standard deviation, $\sigma$, was calculated for $u(S)$ of all servers for each simulated algorithm. Figure \ref{gra:baldeviation} shows the variation of $\sigma{}(u(S))$ over time.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.75\linewidth]{images/baldeviation_ah}
  \caption{Deviation of the ideal usage value}
  \label{gra:baldeviation}
\end{figure}

To summarize the evaluated algorithms, we have: \ggp, which introduced an overhead that increased the system load by 13\% on the average, but it presents the second highest number of migrations of players, and the least fair load distribution; \ggpk, whose overhead increases the system load by 28\%, but it presents the third best number of migrations and its distribution is one the most fair; \ggpf, whose load increase is of 22\%, with the second lowest number of migrations and is also one of the most fair algorithms; and we also have \bfa, which increased the load by 34\%, with the highest number of migrations and not as fair as \ggpk\ or \ggpf. Finally, Ahmed's algorithm increased the system load by 29\%, on the average, with the least number of migrations and a fairness level varying a lot over time.

Although the servers presented the largest variation in the resources usage rate, the \ggp\ was the one with the least overall real weight (which includes overhead: $W_{total} + OverHead$) of all simulated algorithms. Its variant \ggpf\ had the second lowest number of user migrations, along with the second lowest overhead and a fair load distribution, on the average, when compared to the other algorithms. Which of these two is better depends on the specific game. In a real-time game, users constantly migrating between servers can introduce delay and hinder the interaction between players.  \ggpf, or Ahmed's algorithm, would be more suited for this situation. However, when it is not possible to use some kind of ``graceful degradation'' to reduce the quality of the game and save up the servers' resources, \ggp\ would be the best option.

\section{Conclusions and future work}

It was proposed here a load balancing scheme for distributed MMOG servers, taking into account the use of upload bandwidth of the server nodes. We considered important aspects such as the quadratic growth of the traffic when the avatars are close to one another, and the distribution overhead when players connected to different servers are interacting. The scheme, which is divided into three phases, proposed different algorithms for phase 2 (the balancing phase), and \ggp\ presented the lowest overhead of all, while \ggpf\ presented the second fewest migrations of players between servers, along with the second lower overhead introduced and a fair load distribution. For this reason, we recommend the use of \ggpf\ for most cases. However, in some situations where the system load must be reduced as much as possible, \ggp\ would perform better.

As a future work, %the algorithms can be further refined, if the load balancing is considered for an average of the load in a period -- in the last minutes, for example -- rather than the instantaneous value. Thus, it would avoid unnecessary rebalancing that would be caused by an oscilating weight. Another possible future work is to 
one could create a load balancing scheme where there will be not only one server node, but a group of server nodes managing each region. In this case, ways to balance the load on the system, considering this two-level distribution, may be investigated.

%\paragraph{Paragraph headings} Use paragraph headings as needed.
%\begin{equation}
%a^2+b^2=c^2
%\end{equation}
%
%% For one-column wide figures use
%\begin{figure}
%% Use the relevant command to insert your figure file.
%% For example, with the graphicx package use
%%  \includegraphics{example.eps}
%% figure caption is below the figure
%\caption{Please write your figure caption here}
%\label{fig:1}       % Give a unique label
%\end{figure}
%%
%% For two-column wide figures use
%\begin{figure*}
%% Use the relevant command to insert your figure file.
%% For example, with the graphicx package use
%%  \includegraphics[width=0.75\textwidth]{example.eps}
%% figure caption is below the figure
%\caption{Please write your figure caption here}
%\label{fig:2}       % Give a unique label
%\end{figure*}
%%
%% For tables use
%\begin{table}
%% table caption is above the table
%\caption{Please write your table caption here}
%\label{tab:1}       % Give a unique label
%% For LaTeX tables use
%\begin{tabular}{lll}
%\hline\noalign{\smallskip}
%first & second & third  \\
%\noalign{\smallskip}\hline\noalign{\smallskip}
%number & number & number \\
%number & number & number \\
%\noalign{\smallskip}\hline
%\end{tabular}
%\end{table}

\begin{acknowledgements}
This work was supported by the National Research Council (CNPq) and by the Coordination of Improvement of Higher Education (CAPES), both Brazilian research funding agencies.
% FINEP and
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
\bibliography{dissertation}   % name your BibTeX data base

% Non-BibTeX users please use
%\begin{thebibliography}{}
%%
%% and use \bibitem to create references. Consult the Instructions
%% for authors for reference list style.
%%
%\bibitem{RefJ}
%% Format for Journal Reference
%Author, Article title, Journal, Volume, page numbers (year)
%% Format for books
%\bibitem{RefB}
%Author, Book title, page numbers. Publisher, place (year)
%% etc
%\end{thebibliography}

\begin{figure}[h]
%% Use the relevant command to insert your figure file.
%% For example, with the graphicx package use
	\includegraphics[width=0.3\linewidth]{images/Fig-Bezerra.jpg}

	\textbf{Carlos Eduardo Benevides Bezerra} is a full-time Ph.D. student at UFRGS (Universidade Federal do Rio Grande do Sul). He obtained his M.Sc. from the same university in 2009 and his B.Sc. degree from UFBA (Universidade Federal da Bahia) in 2007. His research interests include massively multiplayer online games, interest management algorithms, parallel and distributed algorithms, peer-to-peer networks and computational geometry.
%% figure caption is below the figure
%\caption{Please write your figure caption here}
\label{fig:cebb}       % Give a unique label
\end{figure}

\begin{figure}[h]
%% Use the relevant command to insert your figure file.
%% For example, with the graphicx package use
  \includegraphics[width=0.3\linewidth]{images/Fig-Geyer.jpg}

  \textbf{Cludio Fernando Resin Geyer} is an associate professor at the Informatics Institute of the Federal University of Rio Grande do Sul. His research interests include massively multiplayer games, grid computing and ubiquitous computing. He received his Ph.D. in informatics from Joseph Fourier University. He is a member of ACM and of the Brazilian Computer Society (SBC).


%% figure caption is below the figure
%\caption{Please write your figure caption here}
\label{fig:geyer}       % Give a unique label
\end{figure}

\end{document}
% end of file template.tex

