\newcommand{\ggp}{ProGReGA}
\newcommand{\ggpmeaning}{proportional greedy region growing algorithm}
\newcommand{\ggpk}{\mbox{\ggp-KH}}
\newcommand{\ggpkmeaning}{proportional greedy region growing algorithm keeping heaviest cell}
\newcommand{\ggpf}{\ggp-KF}
\newcommand{\ggpfmeaning}{proportional greedy region growing algorithm keeping usage fraction}
\newcommand{\bfa}{BFBCT}
\newcommand{\bfameaning}{best-fit based cell transference}
\newcommand{\kl}{Kernighan-Lin}
\newcommand{\klalg}{Kernighan-Lin}
\newcommand{\wtodiv}{weight\_to\_divide}
\newcommand{\freecap}{free\_capacity}
\newcommand{\rlist}{region\_list}
\newcommand{\clist}{cell\_list}
\newcommand{\locgroup}{local\_group}
\newcommand{\avguse}{average\_usage}
\newcommand{\wlocal}{local\_weight}
\newcommand{\caplocal}{local\_capacity}
%\newcommand{\wshare}{por\text{\emph{\c{c}}}\tilde{a}o\_da\_carga}
\newcommand{\wshare}{weight\_share}
\newcommand{\wlose}{weight\_to\_lose}
\newcommand{\destreg}{destination\_regions}
\newcommand{\regcap}{free\_capacity}
\newcommand{\wtoreg}{weight\_to\_this\_region}
\newcommand{\misccite}[2]{Available at: #2}
\newcommand{\gamecite}[2]{Available at: #2}

\chapter{A graph partitioning based technique}

In this work, \cite{bezerra2009lbs} propose a balancing scheme with two main goals: allocate load on server nodes proportionally to each one's power and reduce the inter-server communication overhead, considering the load as the occupied bandwidth of each server. Four algorithms were proposed, from which \ggp\ is the best for overhead reduction and \ggpf\ is the most suited for reducing player migrations between servers. The authors also made some comparisons with a state-of-the-art related work, where their approach performed better.

\section{Related work}
\label{sec:related}

The servers receive the action performed by a player, calculate its outcome and send it to all interested players, who are usually those whose avatars are close to the avatar of the first player. If two players are split between different servers, each of these need not only to send the state update to the player served by it, but it has also to send the update to the server to which the other player is connected. This server, in turn, forwards that state update to the other player (Figure \ref{fig:overheadgeneration}).

\begin{figure}
 \centering
 \includegraphics[width=0.8\textwidth]{images/overheadgeneration}
 \caption{Overhead caused by the interaction of players connected to different servers}
 \label{fig:overheadgeneration}
\end{figure}

It is perceived, then, that each state will be sent twice for each pair of players who communicate through different servers. This overhead not only causes the waste of resources of the servers, but it also increases the delay to update the status of the replica of the game in the players' machines, damaging the interaction between them.
	
Therefore, players who are interacting with each other should, ideally, be connected to the same server. However, it is possible that all players are linked through relations of interaction. For example, two avatars of two different players, may be distant from each other, but both could be interacting with a third avatar, between them. Anyway, it is still necessary to divide the players among servers. The question is how many pairs of players and which of them will be divided into different server nodes. It is therefore necessary to decide a criterion to group players. Many works have been done in the past -- such as \cite{devleeschauwer2005dma,lu2006lbm,chen2005lad,duong2003dls,ahmed2008mol} --  trying to find a near optimal, yet fast, load balancing technique.

In \cite{devleeschauwer2005dma}, for example, a few algorithms are proposed. Their idea is to transfer regions managed by overloaded servers to  lightly loaded ones, in a way such that the maximum overload among the servers is reduced. Some very interesting principles are used, as the concepts of microcells and macrocells (which will be described in the next section). However, their model has some differences to the one presented in this work. For instance, they consider the number of players as the load to distribute, heterogeneous systems are not supported, and the algorithm they use to refine an existing partitioning is simulated annealing. This one may be a little too general, considering that there are algorithms specific to partitioning, such as \cite{kernighan1970ehp} or \cite{fiduccia1982lth}, which may perform better. Finally, some of the algorithms proposed in \cite{devleeschauwer2005dma} do not consider the communication overhead between servers.

It is proposed in \cite{lu2006lbm} a load balancing of cpu usage among the nodes of a cluster. The load balancing is done by an ``off the shelf'' NAT load balancer, which distributes the players' connections among the cluster nodes in a round-robin manner. Thus, each cluster node will end up with the same number of players, on the average. This approach, although it does balance the number of clients per cluster node, communication between the server nodes is not considered, for they are connected via a high-speed and low latency network. Furthermore, the authors were concerned only with cpu usage, and not bandwidth occupation, which is the most important aspect in this context.

Chen et al. propose, in \cite{chen2005lad}, a load shedding technique, in which an overloaded server attempts do shed its load to its neighbors. After finding a lightly loaded neighbor server -- if there is one -- it transfers some of its boundary microcells to that neighbor. To form the group of microcells to transfer, a microcell from the border is chosen, and others are added in a breadth-first search (BFS) order. A very similar work, which also uses BFS, is described in \cite{duong2003dls}. However, these models present a few points which could be improved. For example, a server is considered overloaded when a certain number $n$ of players is reached. As we said before, this is not the best measure, since the load on a server may vary completely, depending on how these $n$ players are distributed across the region managed by the server. Also, the use of BFS to merge two partitions or split one of them may not be ideal. Some other algorithm for graph partitioning applied to distributed systems \cite{kernighan1970ehp,fiduccia1982lth,karypis1999fah,hendrickson1995isg} could be used, for most of these algorithms were designed exactly to balance load and minimize dependence between nodes.

The model presented by \cite{ahmed2008mol} -- and described in the previous chapter -- has been compared to the one of \cite{bezerra2009lbs}, for they share many design considerations.

Next, some principles, defined in other works, will be presented. Based on some of these principles, and on research and implementation carried out, the authors defined the load balancing scheme presented in this chapter.

\subsection{Microcells and macrocells}
\label{sec:micro}

%O balanceamento de carga entre servidores de jogos online maci�amente multijogador � fortemente dependente da distribui��o dos avatares dos jogadores atrav�s do ambiente virtual. Al�m disso, a depender da concentra��o de avatares, pode-se alternar entre uma fun��o de crescimento de tr�fego linear e uma fun��o quadr�tica. Sendo assim, � necess�rio lidar com a localidade dos avatares, de maneira a otimizar o uso de largura de banda do sistema servidor, minimizando, tanto quanto poss�vel, o overhead causado pela comunica��o entre jogadores ligados a servidores diferentes.

One way to explore the locality of the players is by grouping them according to the position occupied by their avatars in the virtual environment. %The question would be how to form such groups. One way of doing this would be dividing the world of the game in several cells connected to one another. Each cell would be a part of the world, with its own content and characteristics, which would be assigned to a server node. The easiest way to do this is with a grid of cells of the same size and shape.
%
%[TODO:footnote?]Por�m, o formato e a disposi��o destas c�lulas ir� influenciar no tr�fego gerado pelas mesmas entre os servidores. Por exemplo, um ambiente bidimensional poderia ser dividido em uma grade de c�lulas quadradas. Neste caso, cada uma destas c�lulas teria oito vizinhos, em m�dia -- c�lulas nas bordas do mapa poderiam ter cinco ou tr�s vizinhos apenas. Quanto mais servidores vizinhos, maior o tr�fego entre servidores, e maior o overhead causado por esta comunica��o. A distribui��o ideal, ent�o, seria utilizando c�lulas hexagonais, cada uma com seis vizinhos. Estudos comprovam que esta � a divis�o em c�lulas iguais que permite o menor n�mero de vizinhos por c�lula [TODO:ref]. Outra possibilidade seria utilizando fileiras alternadas de c�lulas quadradas, onde cada fileira seria deslocada o equivalente � metade do comprimento de uma c�lula.
%
%[TODO:figura com diferentes tipos de divis�o:sqr/hex/shift]
%
%**	
%An important aspect of this design is that the concept of cell is transparent to the players. They see a wide, single and contiguous world, even if they are repeatedly crossing the boundaries between different cells. Obviously, this requires that the cells communicate, updating and notifying each other of events that occurred near the border between them, and of the migration of players from one to the other.
%
%Although this approach with cells distribute the load among several servers, there are no guarantees that this distribution will be uniform, because of the high mobility of players and the existence of hotspots.
One of the ideas proposed in the literature \cite{devleeschauwer2005dma} follows the principle of dividing the virtual environment in cells of fixed size and position. These cells are relatively small -- or \textbf{microcells} -- and they can be grouped, forming an area called \textbf{macrocell}. Each macrocell is then assigned to a different server, which will manage not a large cell of fixed size and position, but a variable set of small cells. These microcells can then be moved dynamically between different macrocells, maintaining the load on each one of the servers under a tolerable limit.

%[TODO: tirar todas as contra��es!]
Obviously, the microcells designated to the same server node do not generate additional traffic to synchronize with each other, but the synchronization overhead of the macrocell is unpredictable, because the number of neighbors of each one of them is not foreknown, for its shape is variable. However, it was demonstrated \cite{devleeschauwer2005dma} that this overhead is compensated by a better distribution of the load between servers in the game. %Figure [TODO: ref] illustrates the division of a virtual environment in two-dimensional microcells.
%It is illustrated in [TODO: ref] in the grouping of these micro macroc�lulas dynamics, which can adapt to the distribution of avatars.

%[TODO: figuraS com microc�lulas e macroc�lulas - fazer vetorial ou copiar? depende do tempo que tiver depois de terminar o texto. divisao em micro e agrupamento em macro]

\subsection{Load balancing in local scope}
\label{sec:local}
	
In \cite{lee2003sdl}, it is also proposed a scheme for dynamic load balancing for the servers of a multi-server virtual environment. Following the scheme proposed by the authors, an overloaded server starts the process by selecting a number of other servers to be part of the load redistribution. The set of selected servers depends on the load level of the initiating server as well as on the amount of idle resources of the other servers. After the formation of this set, its elements allocate portions of the virtual environment using a graph partitioning algorithm, so that the servers involved have similar final load.

To achieve this goal, the authors also subdivided the virtual environment in rectangular \textbf{cells} -- similar to the microcells --, where the number of servers is much smaller than the number of cells. The cells are grouped into \textbf{regions} -- or macrocells -- and each region is managed by one server (Figure \ref{fig:macromicro}). Each server handles all the interactions between avatars located in the region assigned to it. It receives the inputs of the players controlling these avatars and sends back to them the up-to-date game state. 

\begin{figure}
 \centering
 \includegraphics[width=0.4\textwidth]{images/macromicro}
 \caption{Cells grouped into four regions (R$_1$, R$_2$, R$_3$ and R$_4$)}
 \label{fig:macromicro}
\end{figure}

Two cells are called adjacent (or neighbors) if they share a border. Similarly, two regions -- and the servers assigned to them -- are called adjacent (neighbors) if there is a pair of adjacent cells, each of which belonging to one of the two regions. The workload of a cell was defined as the number of avatars present in that cell. The authors assumed that all players receive state updates of the same length and in the same frequency, so that the burden of processing (computing and communication) that a cell requires from a server is proportional to the number of users in that cell. The workload of a region and its designated server is defined as the sum of the individual workloads of the cells which form the region. Each server periodically evaluates its workload and exchange this information with its neighbors. They have assumed, too, that these servers are connected through a high-speed network. Thus, the overhead to exchange workload information among neighbors is limited and considered negligible compared to other costs of the distribution. For the same reason, they also assumed as negligible the overhead of communication between servers in different regions when players are interacting.

The main aspect of the solution proposed by the authors was the use of local information (the server that initiated the balancing process and its neighbors), rather than global information (involving all servers in the balance). When a server is overloaded, it searches for lightly loaded servers close to it in the overlay network. A breadth-first lookup for lightly loaded neighbor servers -- as proposed in \cite{duong2003dls} -- causes a small overhead, but it may not solve the problem efficiently in a few steps, as overloaded servers tend to be adjacent. The global approach, in turn, is able to divide the workload in the most balanced way possible, but its complexity may become too high.

The solution proposed by the authors is then by involving only a subset of servers, such that its cardinality varies according to the need (if the neighbors of the server which triggered the load balancing are also overburdened, more servers are selected). However, this set is formed in a more clever way than by simply using a breadth-first search. The algorithm used to find the servers is described in the next section.

\subsubsection{Selection of a local server group to balance the load}
\label{sec:regselect}
	
A server starts the balancing when the load assigned to it is beyond its capacity. This server selects a number of other servers to get involved with the distribution. First, it chooses the least loaded server among its neighbors and sends a request that he participates in the load balancing. The chosen server rejects the request if it is already involved in another balancing group, otherwise it responds to the server with the load information of its own neighbors. If the selected neighbor server is unable to absorb all the extra workload of the initiating server, the selection is performed again among the neighbors not only of the overloaded server, but also the neighbors of the already selected servers. The selection continues until the workload of the first server can be absorbed -- that is, the workload of all selected servers becomes smaller than a certain limit.

Figure \ref{fig:lee2} illustrates the operation of the algorithm. All servers have the same capacity, each one being able to handle 100 users. First, the initiator server, $S_6$ is inserted into SELECTED and its neighbors ($S_2, S_5, S_7$ and $S_{10}$) are added to CANDIDATES (Figure \ref{fig:lee2}(a)). So $S_7$, which has the lowest workload among the servers in CANDIDATES, is selected and invited to participate in the load distribution. When $S_7$ sends to $S_6$ the workload information of its neighbors ($S_3, S_6, S_8$ and $S_{11}$), it is inserted into SELECTED and its neighbors, except $S_6$, are added to CANDIDATES (Figure \ref{fig:lee2}(b)). Now, $S_{11}$, which has the lowest workload among servers in CANDIDATES, is selected and invited to participate in the load distribution. However, $S_{11}$ rejects the invitation, because it is involved in another distribution, initiated by $S_{12}$. Thus, $S_{11}$ is removed from CANDIDATES and $S_{10}$ is selected because it now has the lowest workload among all servers in CANDIDATES (Figure \ref{fig:lee2}(c)). This process continues until the average workload is under a pre-defined threshold (Figure \ref{fig:lee2}(d) and Figure \ref{fig:lee2}(e)).

\begin{figure}
 \centering
 \includegraphics[width=1.04\textwidth]{images/localselection}
 \caption{Selecting the group of servers for local rebalance}
 \label{fig:lee2}
\end{figure}

After forming the local server set, the initiating server performs a load rebalancing in such group, using some graph partitioning algorithm. To map the virtual environment to a graph, each cell is represented by a vertex, whose weight equals to the number of avatars in that cell; and every two vertices which represent adjacent cells are connected by an edge.



\section{Proposed load balancing scheme}
\label{sec:scheme}

In the previous section it was presented some existing works regarding load balancing in MMOGs when using multiple servers to provide the support network. The load balancing scheme proposed in this work is based on some of the principles in the literature. One of them is the division of the virtual environment in microcells, for later grouping in macrocells. This is a relatively simple way of addressing the issue of the avatars' movement dynamics through the game world, by transferring the microcells dynamically according to need.

It will also be used the idea of balancing based only on local information -- each server, when needing to reduce its workload, selects only a few other servers to join a local load rebalancing. Thus, we can greatly reduce the complexity of balancing because it will not be necessary that all servers in the game exchange messages among themselves every time that any one of them is overloaded.

To define our load balancing approach, we cannot ignore that, usually, the traffic generated by the players is not simply linear, but square for each cluster of players. Such misunderstanding can generate considerable differences between the actual load of each server and the load estimated by the balancing algorithm. Another point to consider is the overhead, both in the delay of sending messages, as in the use of bandwidth of the servers, when players connected to different servers are interacting with each other. Some works assume that the servers are all in the same high-speed and low latency local-area network, and therefore overhead is negligible. However, when considering a geographically distributed server system, this assumption cannot be made. This overhead must be taken into account, no matter which load balancing algorithm is being used.

Another important point is that the main criterion we use when balancing the load of MMOG servers is the bandwidth, and not processing power. Several games, such as Age of Empires \cite{ageofempires}, include simulations of virtual environments with hundreds or thousands of entities, which are performed smoothly on current personal computers. However, if this game was multiplayer and each of these entities was controlled by a different player on the Internet, it would most likely generate a traffic amount which would hardly be supported by a domestic connection \cite{feng2007wnn}.

%TODO: explicar porque cresce linearmente
Moreover, the upload bandwidth must be taken into account, much more than download. This happens for two reasons: first, the usage of the download bandwidth of each server node grows linearly with the number of players connected to it, while the usage of the upload bandwidth may have a quadratic growth, getting quickly overwhelmed; second, domestic connections -- which are majority in volunteer peer-to-peer systems -- usually have an upload bandwidth much lower than the download one.

There are also other issues which must not be overlooked. One of them is that the server system is probably not homogenous -- considering that it is geographically distributed with, likely, different connections to the Internet. Therefore, one cannot assume that the servers have the same amount of cpu power or network bandwidth. % Another problem, specific to the algorithm proposed by \cite{lee2003sdl}, is that the criterion to allocate to each server a load equivalent to 90\% of its capacity in order to avoid constant rebalancing is weak. There are no guarantees that the server system has 11.11\% more total capacity than the necessary. On the contrary, it should adapt to situations of widespread overload. Moreover, the criterion for stopping is weak because the algorithm does not stop when the whole system is loaded above 90\% of its capacity, or if the overloaded server has no neighbors capable of receiving more load.
In the next section, we make some definitions that will be necessary to specify our load balancing scheme.


%[TODO:introduzir as se��es]
	
%However, an important idea that was suggested was the use of graphs to represent the virtual environment, and the use of graph partitioning algorithms to perform load balancing. In the following section, will be a brief introduction about this principle, which is the basis of load balancing scheme proposed here.

\subsection{Definitions}
\label{sec:def}

We also use the idea of mapping the virtual environment on a graph. The graph will then be partitioned to distribute the workload of the game between the different servers. It is necessary first to define some terms which will be used on the proposed algorithms.

%TODO:definir um por um em detalhes, depois enumer�-los no par�grafo acima ^ para o leitor n�o se perder

\begin{itemize}
	\item \textbf{Server}: here, server is defined as a node belonging to the distributed system to serve the game. Each server can be assigned a single region;
	\item \textbf{Server power}: the server power, $p(S)$ is a numerical value proportional to the server's upload bandwidth;
	\item \textbf{Server power fraction}: given a set of servers $Servers$ = $\{S_1, S_2, ..., S_n\}$, the power fraction of a server $S$, $frac_p(S)$, is equal to its power divided by the summed power of all servers in $Servers$:
	
	%**
		\begin{center}
			$frac_p(S) = \frac{\displaystyle p(S)}{\displaystyle\sum_{i=1}^{n} p(S_i)}$
		\end{center}
		
	\item \textbf{System power}: the total power of the system, $P_{total}$, equals the sum of the powers of the $n$ servers which form it:
	
		\begin{center}
			$\displaystyle P_{total} = \sum_{i=1}^{n} p(Si)$
		\end{center}
	
	\item \textbf{Cell}: similar to the microcells, it is considered here the environment being divided into small cells, each one with fixed size and position. If two cells share a border, they are said to be \textbf{adjacent} or \textbf{neighbors};
	\item \textbf{Region}: the cells are grouped, forming what is called regions. Usually these areas are contiguous, although in some cases the subgraph that represents them may be disconnected, resulting in the presence of cells isolated from each other. Each region is assigned to a server, and only one, and $s(R)$ is the server associated to the region $R$. It may be referred throughout the text to region's ``power'', which in fact refers to the power of the server associated with that region, i.e. $p(s(R))$;
	%[TODO:ver se realmente precisa do item intera��o, ou se nao eh melhor usar relevancia mesmo]
	\item \textbf{Relevance}: the relevance of an avatar $A_j$ to another one, $A_i$, determines the frequency of updates of the state of $A_j$ the server should send to the player controlling $A_i$ \cite{bezerra2008a3}. It may be represented by the function $R(A_i,A_j)$;
	\item \textbf{Avatar's weight}: to each avatar there are various other entities (here, we only consider avatars) of the game, each with a frequency of state updates that need to be sent to the player who controls that avatar. Thus, for each avatar $A$ , its individual weight -- or of upload bandwidth that the server uses to send state updates to its player -- $w_a(A)$ depends on which other entities are relevant to it, and how much. 
	%**
	Let $\{A_1, A_2, ..., A_t\}$ be the set of all avatars in the virtual environment, we have:
	
		\begin{center}
			$\displaystyle w_a(A) = \sum_{i=1}^{t} R(A,Ai)$
		\end{center}
				
	\item \textbf{Cell's weight}: here, the total weight of a cell (or the use of upload bandwidth of its server) will be equal to the sum of the individual weights of the avatars in it. Consider cell $C$, where the avatars $\{A_1, A_2, ..., A_n\}$ are present. Also, consider that the avatars $\{A_1, A_2, ..., A_t\}$ are all the avatars in the virtual environment. The weight of this cell, $w_c(C)$, is:
	
		\begin{center}		
			$\displaystyle w_c(C) = \sum_{i=1}^{n} w(Ai) = \sum_{i=1}^{n} \sum_{j=1}^{t} R(A_i,A_j)$
		\end{center}
		
	\item \textbf{Region's weight}: the weight of a region is the sum of the weights of the cells that compose it. Let $R$ be the region formed by $\{C_1, C_2, ..., C_p\}$. The weight of $R$ is:
	
		\begin{center}
			$\displaystyle w_r(R) = \sum_{i=1}^{p} w_c(Ci)$
		\end{center}
		
		\item \textbf{Region's weight fraction}: given a set of regions $Regions  = \{R_1, R_2, ..., R_n\}$, the weight fraction of $R$, relative to $Regions$, is:
	
		\begin{center}
			$frac_r(R) = \frac{\displaystyle w_r(R)}{\displaystyle\sum_{i=1}^{n} w_r(R_i)}$
		\end{center}
		
	\item \textbf{Region's resource usage}: fraction that indicates how much of the power of the server of that region is being used. It is defined by:
	
		\begin{center}
			$u(s(R)) = \frac{\displaystyle w_r(R)}{\displaystyle p(s(R))}$	
		\end{center}
		
	\item \textbf{World weight}: the total weight of the game, $W_{total}$, will be used as a parameter for the partitioning of the virtual environment. It is defined as the sum of the weights of all cells. Let $\{C_1, C_2, ..., C_w\}$ be the set of all cells in which the game world is divided, we have:
	
		\begin{center}
			$\displaystyle W_{total} = \sum_{i=1}^{w} w_c(Ci)$
		\end{center}
	
	%explicar o pq da carga ser isso (upload)
	
	\item \textbf{System usage}: fraction that indicates how much resources of the system as a whole is being used. It is defined by:

		\begin{center}
			$\displaystyle U_{total} = \frac{W_{total}}{P_{total}}$
		\end{center}
	
	\item \textbf{Cell interaction}: the interaction between two cells is equal to the sum of all interactions between pairs of avatars where each one of them is located in one of these cells. The interaction between cells $C_i$ and $C_j$ is given by:
	
		\begin{center}
			$\displaystyle Int_c(C_i,C_j) = \sum_{i=1}^{m} \sum_{j=1}^{n} R(A_i,A_j)$,
			
			where $A_i$ is in $C_i$ and $A_j$ is in $C_j$.
		\end{center}
	
	\item \textbf{Overhead between two regions}: if there is only one server and one region, comprising the entire virtual environment of the game, the use of the upload bandwidth of the server will be proportional to $W_{total}$. However, due to its distribution among various servers, there is the problem of having players from different regions interacting with each other very close to the border between the regions (Figure \ref{fig:interactingregions}). Because of that, each state update of these players' avatars will be sent twice. For example, let $A_i$ be the avatar of the player $P_i$, connected to the server $S_i$, and $A_j$ the avatar of the player $P_j$, connected to the server $S_j$. In order for $P_i$ to interact with $P_j$, it is necessary that $S_i$ sends the state of $A_i$ to $S_j$, which then forwards to $P_j$. The same happens on the other way around. The overhead between regions $R_i$ and $R_j$ is equal, therefore, to the sum of interactions between pairs of cells where each one of them is in one of these regions. If $R_i$ and $R_j$ have respectively $m$ and $n$ cells, we have that the interaction -- or overhead -- between them is given by:
	
	  \begin{center}
			$\displaystyle Int_r(R_i,R_j) = \sum_{i=1}^{m} \sum_{j=1}^{n} Int_c(C_i,C_j)$,
			
			where $C_i \in R_i$ e $C_j \in R_j$.
	  \end{center}

	\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{images/interactingregions}
	\caption{Players interacting across a border between regions}
	\label{fig:interactingregions}
	\end{figure}
  	
  \item \textbf{Total Overhead}: the total overhead on the server system is calculated as the sum of overheads between each pair of regions. So we have:

    \begin{center}
      $\displaystyle OverHead = \sum_{i} \sum_{j, j \neq i} Int_r(Ri,Rj)$
    \end{center}

\end{itemize}

As the concepts needed to understand the proposed load balancing scheme have been defined, now it will be described how the virtual environment is mapped on a weighted graph, which will then be partitioned. Let $GW = (V,E)$ be a graph that represents the game world, where $V$ is the set of vertices and $E$ is the set of edges connecting vertices. Each component of this graph, and what it represents, is described below:

\begin{itemize}
	\item \textbf{Vertex}: each vertex in the graph represents a cell in the virtual environment;
	\item \textbf{Edge}: each edge in the graph connects two vertices that represent adjacent cells;
	\item \textbf{Partition}: each partition of the graph $GW$ -- a subset of the vertices of $GW$, plus the edges that connect them -- represents a region;
	\item \textbf{Vertex weight}: the weight of each vertex is equal to the weight of the cell that it represents;
	\item \textbf{Edge weight}: the weight of the edge connecting two vertices is equal to the interaction between the cells represented by them;
	\item \textbf{Partition weight}: the weight of a partition is equal to the sum of the weights of its vertices, i.e. the weight of the region that it represents;
	\item \textbf{Edge-cut}: the edge-cut in a partitioning is equal to the sum of the weights of all the edges which connect vertices from different partitions. This value is equal to the sum of the overheads between each pair of regions. Thus, the edge-cut of the graph $GW$ is equal to the total overhead on the server system.
\end{itemize}

\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{images/mapping}
	\caption{Mapping of the virtual environment on a graph}
	\label{fig:mapping}
\end{figure}

Figure \ref{fig:mapping}(a) illustrates how the mapping is done with square cells, while figure \ref{fig:mapping}(b) shows how it would be with hexagonal cells. The objective of the balancing scheme proposed here is to assign to each server a weight proportional to its capacity, reducing as much as possible the edge-cut of the graph that represents the virtual environment and, consequently, reduce the overhead inherent to the distribution of the game on multiple servers. Although this is an NP-complete problem \cite{feder1999cgp}, efficient heuristics will be used to reduce this overhead. In the following sections the algorithms proposed in this work will be presented.

\subsection{Proposed algorithms}
\label{sec:alg}
	
It is considered that an initial division of the virtual environment has already been made. Each server should then check regularly if there is an imbalance and trigger the algorithm. Although the overhead resulting from the distribution of the virtual environment is part of the workload on servers, there is no way to know it beforehand without executing the repartitioning first. For this reason, the ``weight'' to be distributed does not include this extra overhead.

When there is an unbalanced region, it is selected a local group of regions, similar to what was shown in section \ref{sec:local}, but with some changes (section \ref{sec:alg:localselect}). After this selection, it will be used an algorithm whose parameters are only the loads of the cells and their interactions, for such data is available prior to distribute. Finally, with the regions already balanced, the algorithm of Kernighan and Lin \cite{kernighan1970ehp} will be used to refine the partitioning, reducing the edge-cut and, thus, the overhead, while keeping the balance.

The proposed scheme is then divided into three phases:

\begin{enumerate}
	\item Select the group of local regions;
	\item Balance these regions, assigning to each one a weight which is proportional to the power of its server;
	\item Refine the partitioning, reducing the overhead.
\end{enumerate}

% [TODO: see if the put option or have not disbal tolerance, both here and in the transfer (BFA) / overhead (kl)]
% [: Independent that I can for the graphics and implementation "version without disbal tolerance with X"]
A decision to this balancing scheme is that a region $R$ is considered overloaded only when the use of its resources is greater than the total use of the system, also considering a certain tolerance, $tol$, to avoid constant rebalancing. Thus, the server starts the balancing of $R$ when, and only when, $u(s(R)) > U_{total} \times tol$. Thus, even if the system as a whole is overburdened, a similar quality of game will be observed among the different regions, dividing the excessive weight between all servers fairly. What can be done when $U_{total} > 1$ is gradually reduce the amount of information sent in each state update, leaving for the application the task of extrapolating the missing information based on previous updates.
% [TODO: advantages and disadvantages by then]

Another important aspect is that each server always has an associated region. What might happen would be a region being empty -- without any cells -- and its server not participating in the game. This is useful when the total capacity of the server system is much greater than the total load of the game, or $ P_{total} \gg W_{total}$. In this case, the introduction of more servers would only increase the communication overhead of the system, without improving its quality -- except when introduced to provide fault tolerance.

The algorithms were developed oriented to regions, instead of servers, in order to be more legible, because of the constant transfers of cells. Moreover, it becomes easier to extend, in the future, the balancing model used here to allow more than one server managing the same region. The proposed algorithms are described as follows. The one in section \ref{sec:alg:localselect} is for phase 1, the sections \ref{sec:alg:ggp} to \ref{sec:alg:bfa} are alternatives for phase 2 and the algorithm in section \ref{sec:alg:kl} is the refinement of phase 3.

\subsubsection{Local regions selection}
\label{sec:alg:localselect}

The algorithm for selection of regions (Algorithm \ref{alg:local}) aims to form a set of regions such that the average usage of resources of the servers of these regions is below a certain limit. Starting from the server that has started the balancing, its neighboring regions with the least usage of resources are added. When the average usage is less than 1, or less than $ U_{total}$ (line \ref{alg:local:condition}), the selection ends and phase 2 begins, with the region set as input. These two conditions are justified because there are two possibilities: $U_{total} \leq 1$ and $U_{total} > 1$.
	
In the case when $U_{total} \leq 1$, there is sufficient power in the system so that all servers have a usage smaller than 100\%. Thus, regions are added to the group until all the servers involved are using fewer resources than they have. However, when $U_{total} > 1$, there is no way to all servers be using less than 100\% of its resources at the same time. Thus, it is sufficient that all servers are similarly overburdened, and that some kind of adjustment is made, which will probably be a reduction in the information sent to players in each state update. Although this approach seems to lead the system to an inconsistent state, due to the lack of available bandwidth, the $U_{total}$ is calculated based on the theoretical value of a region's weight. In practice, the system as a whole will take two measures: first, the frequency at which state updates are sent to players is diminished and, second, it will deny access to new players who try to join the game. Denying access when the game is overpopulated with players is the usual policy adopted by some MMOGs.

If even after all the neighbors, and the neighbors of the neighbors and so on, are selected, the criterion is not met, empty regions -- belonging to idle servers -- will be inserted in the group (line \ref{alg:local:idleserver}) because the overhead of interaction between regions introduced by them is justified by the need for more resources.

\begin{algorithm}
\caption{Local regions selection}
\label{alg:local}
\begin{algorithmic}[1]
	 \STATE $\locgroup \leftarrow \{R\}$
	 \STATE $\wlocal \leftarrow w_r(R)$
	 \STATE $\caplocal \leftarrow p(s(R))$
	 \STATE $\avguse \leftarrow \frac{\wlocal}{\caplocal}$
	 \WHILE{$\avguse > max(1, U_{total})$} \label{alg:local:condition}
	 		\IF{there is any not selected region neighbor to one of $\locgroup$}
	 			 \STATE $R \leftarrow$ not selected region neighbor to one of $\locgroup$, with smallest $u(s(R))$
	 		\ELSIF{there is any empty region} \label{alg:local:idleserver}
	 			 \STATE $R \leftarrow$ empty region with highest $p(s(R))$
	 		\ELSE
	 			 \STATE stop. no more regions to select.
	 		\ENDIF
	 		\STATE $\wlocal \leftarrow \wlocal + w_r(R)$
	 		\STATE $\caplocal \leftarrow \caplocal + p(s(R))$
	 		\STATE $\avguse \leftarrow \frac{\wlocal}{\caplocal}$
	 		\STATE $\locgroup \leftarrow \locgroup \cup \{R\}$
	 \ENDWHILE
	 \STATE run phase 2 passing $\locgroup$ as input.
\end{algorithmic}
\end{algorithm}

\subsubsection{\ggp} %repart
\label{sec:alg:ggp}
	
\textbf{\ggp}, or \ggpmeaning, seeks to allocate the heaviest cells to the regions managed by the most powerful servers. As input, the algorithm receives a list of the regions to balance. Details are shown in Algorithm \ref{alg:ggp}.


\begin{algorithm}
\caption{\ggp}
\label{alg:ggp}
\begin{algorithmic}[1]
	 \STATE $\wtodiv \leftarrow 0$ \label{alg:ggp:begingetlocalinfo}
	 \STATE $\freecap \leftarrow 0$
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wtodiv \leftarrow \wtodiv + w_r(R)$
	 		\STATE $\freecap \leftarrow \freecap + p(s(R))$
	 		\STATE temporarily free all cells from $R$ \label{alg:ggp:freeallcells}
	 \ENDFOR \label{alg:ggp:endgetlocalinfo}
	 \STATE sort $\rlist$ in decreasing $p(s(R))$ order \label{alg:ggp:sortregions}
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wshare \leftarrow \wtodiv \times \frac{p(s(R))}{\freecap}$ \label{alg:ggp:fraction}
	 		\WHILE{$w_r(R) < \wshare$} \label{alg:ggp:whilefraction}
	 		   \IF{there is any cell from $R$ neighboring a free cell}
	 		   		\STATE $R \leftarrow R \cup \{$neighbor free cell with the highest $Int_c(C)$$\}$ \label{alg:ggp:freeneighbor}
	 		   \ELSIF{there is any free cell}
	 		   		\STATE $R \leftarrow R \cup \{$heaviest free cell$\}$ \label{alg:ggp:freeheavycell}
	 		   \ELSE
	 		   		\STATE stop. no more free cells.
	 		   \ENDIF
	 		\ENDWHILE
	 \ENDFOR
\end{algorithmic}
\end{algorithm}

Like we said, it is passed as input a list of the regions whose load will be rebalanced. This makes possible the use of this algorithm both in local and global scope, just by choosing between passing some regions or all regions of the environment. The distribution is based on information from that set of regions, whose total weight and total power are calculated in lines \ref{alg:ggp:begingetlocalinfo} to \ref{alg:ggp:endgetlocalinfo}. To be redistributed later, all cells associated with these regions are released (line \ref{alg:ggp:freeallcells}).

To provide a partitioning which is balanced, proportional and with low edge-cut since the second phase of the balancing, the regions are sorted in decreasing order of server power (line \ref{alg:ggp:sortregions}). The \ggp\ then runs through this list, seeking to assign heavier cells to more powerful servers.%, while charges for areas with weak cell servers least loaded.

In line \ref{alg:ggp:fraction}, it is calculated the weight share for each region, considering the total weight that is being divided and the total power of the servers of those regions. The server power fraction of a region, $\frac{p(s(R))}{\freecap}$ should be the same fraction of weight that must be attributed to it. Even if this weight is greater than the power of that server, resulting in an overload, all the servers are similarly overloaded, satisfying the criterion of balance that has been defined. The condition for the end of the allocation of new cells in a region is that its weight is greater than or equal to its weight share.

It is important to notice that the while condition (line \ref{alg:ggp:whilefraction}) may lead to the assignment of a cell whose weight is higher than the weight share left on the region. However, it is very unlikely to assign to a region its exact weight share, so it is preferable to surpass this value, guaranteeing that every cell will be assigned to some region. Also, assigning to a region a weight which is higher than its calculated share does not imply that it will become overloaded. First, the weight share of a region is not equal to the power of its server. When there are enough resources, the region's weight share will be smaller than its capacity. Furthermore, as \ggp\ is a greedy algorithm, the heaviest cells will be assigned first, to the most powerful servers.

%The choice of cells to include in the region tries to put the most interacting pairs of cells in the same regions, reducing the overhead.% In each step, the algorithm not only tries to get a neighbor cell, but also the one with the highest that not only is free from a nearby cell already present in the region, but whose edge linking them is the heaviest possible. %Figure [TODO: reffig] shows an example of the steps of the growth of a region to achieve its share of the load balancing.

%A escolha de c�lulas para incluir na regi�o busca fazer com que cada uma das arestas mais pesadas do grafo $GW$ ligue v�rtices da mesma parti��o, reduzindo o corte de aresta e, assim, o overhead. A cada passo � dada prefer�ncia a escolher a c�lula livre que n�o apenas seja vizinha de uma c�lula j� presente na regi�o, mas tamb�m cuja aresta ligando-as seja a mais pesada poss�vel. A Figura \ref{fig:ggp} mostra um exemplo dos passos do crescimento de uma regi�o at� atingir a sua parcela de carga no balanceamento.

The criterion to choose a cell to include in the region is to make the heaviest edges on the graph $GW$ connect vertices in the same partition, reducing the edge-cut and, thus, the overhead. In each step, it is selected the cell which not only is adjacent to a cell already present in the region, but whose edge connecting them is the heaviest possible. This algorithm is based on a principle similar to the one used in GGGP \cite{karypis1999fah}, a greedy algorithm for graph partitioning. The objective of GGGP is to split a graph in two partitions of the same weight, while reducing the edge-cut with the heaviest edge heuristics. Figure \ref{fig:ggp} illustrates the steps of growth of a region until it reaches its load share.

%TODO: referenciar karypis e kumar, wow e outros jogos (eve-online, warhammer e cabal)
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{images/ggp}
\caption{Growth of a partition (region) with \ggp}
\label{fig:ggp}
\end{figure}

In the example of Figure \ref{fig:ggp}, there are two servers, $S_1$ and $S_2$, where $p(S_1) = 30$ and $p(S_2) = 18$. The total weight of the environment being repartitioned is $W_{total} = 32$. For the division to be proportional to the capacity of each server, the weights assigned to $S_1 $ and $S_2$ are 20 and 12, respectively. The selection starts with the vertex of weight 6 (free cell with the highest weight) and, after that, at each step the vertex connected by the heaviest edge is added to the partition. The selected edges and the vertices belonging to the new partition are highlighted.

In the first step of the cycle starting in line \ref{alg:ggp:whilefraction}, if the region does not have any cell yet, \ggp\ gets the heaviest free cell (line \ref{alg:ggp:freeheavycell}). The same occurs when a region is compressed between the borders of other regions and has no free neighbor, getting cells from somewhere else (Figure \ref{fig:compressed}). This may generate fragmented regions and possibly increase the overhead of the game. However, this happens more often in the last steps of the distribution, when most of the cells would be already allocated to some region. Because the algorithm is greedy, when it reaches that stage of its execution, the free cells would probably the lightest cells of the environment, causing little overhead.

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{images/compressed}
\caption{Formation of disconnected partition (fragmented region)}
\label{fig:compressed}
\end{figure}

\subsubsection{\ggpk} %v3

A possible undesirable effect of the \ggp\ algorithm is that by releasing all the cells and redistributing them, it might happen that one or more regions completely change their place, causing several players to disconnect from their servers and reconnect to a new one. To try to reduce the likelihood of such event, we propose a variation of the algorithm, called \textbf{\ggpk} (\ggpkmeaning). This new algorithm (shown in Algorithm \ref{alg:ggpk}) is similar to the original version, except that each region maintains its heaviest cell (lines \ref{alg:ggpk:saveheaviestcell} and \ref{alg:ggpk:getbackheaviestcell}), from which a region similar to the previous one can be formed, so that several players will not need to migrate to other server. However, to keep one of the cells of each region, it might be preventing a better balancing to occur. Also, the fixation of that cell might cause fragmented regions, increasing the overhead.

\begin{algorithm}
%\renewcommand{\ALG}{Algoritmo}
\caption{\ggpk}
\label{alg:ggpk}
\begin{algorithmic}[1]
	 \STATE $\wtodiv \leftarrow 0$
	 \STATE $\freecap \leftarrow 0$
	 \FOR{each $R$ in $\rlist$}
	 		\STATE $\wtodiv \leftarrow \wtodiv + w_r(R)$
	 		\STATE $\freecap \leftarrow \freecap + p(s(R))$
	 		\STATE $c \leftarrow $ heaviest cell from $R$ \label{alg:ggpk:saveheaviestcell}
	 		\STATE temporarily free all cells from $R$
	 		\STATE $R \leftarrow R \cup \{c\}$ \label{alg:ggpk:getbackheaviestcell}
	 \ENDFOR
	 \STATE sort $\rlist$ in decreasing $p(s(R))$ order \label{alg:ggp:sortregions}
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wshare \leftarrow \wtodiv \times \frac{p(s(R))}{\freecap}$
	 		\WHILE{$w_r(R) < \wshare$} \label{alg:ggpk:whilefraction}
	 		   \IF{there is any cell from $R$ neighboring a free cell}
	 		   		\STATE $R \leftarrow R \cup \{$neighbor free cell with the highest $Int_c(C)$$\}$
	 		   \ELSIF{there is any free cell}
	 		   		\STATE $R \leftarrow R \cup \{$heaviest free cell$\}$ \label{alg:ggpk:freeheavycell}
	 		   \ELSE
	 		   		\STATE stop. no more free cells.
	 		   \ENDIF
	 		\ENDWHILE
	 \ENDFOR
\end{algorithmic}
\end{algorithm}

\subsubsection{\ggpf} %v4
%[TODO: por desvantagens em outra se��o posteriores]
Another way of trying to minimize the migration of players between servers because of the rebalancing is the \textbf{\ggpf}, or \ggpfmeaning\ (Algorithm \ref{alg:ggpf}). In this algorithm, each region will gradatively release its cells in increasing order of weight, until its weight fraction is less than or equal to the power fraction of its server. Thus, the heaviest cells remain on the same server and, therefore, most players do not need to migrate. After that, the cells that were released are redistributed among the regions with lowest server resource usage (line \ref{alg:ggpf:usageorder}). The disadvantage of this algorithm is, as in \ggpk, the possibility of fragmenting the regions, with many isolated cells, increasing the overhead.

\begin{algorithm}
\caption{\ggpf}
\label{alg:ggpf}
\begin{algorithmic}[1]
	 \STATE $\wtodiv \leftarrow 0$
	 \STATE $\freecap \leftarrow 0$
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wtodiv \leftarrow \wtodiv + w_r(R)$
	 		\STATE $\freecap \leftarrow \freecap + p(s(R))$
	 		\STATE $\clist \leftarrow $ list of cells from $R$ in increasing order of weight
	 		\WHILE{$frac_r(R) > frac_p(s(R))$}
	 			 \STATE $C \leftarrow$ first element from $\clist$
	 			 \STATE remove $C$ from $R$
	 			 \STATE remove $C$ from $\clist$
	 		\ENDWHILE
	 \ENDFOR
	 \STATE sort $\rlist$ in increasing order of $u(s(R))$ \label{alg:ggpf:usageorder}
	 \FOR{each region $R$ in $\rlist$}
	 		\STATE $\wshare \leftarrow \wtodiv \times \frac{p(s(R))}{\freecap}$
	 		\WHILE{$w_r(R) < \wshare$} \label{alg:ggpf:whilefraction}
 		   	 \IF{there is any cell from $R$ neighboring a free cell}
	 		   		\STATE $R \leftarrow R \cup \{$neighbor free cell with the highest $Int_c(C)$$\}$
	 		   \ELSIF{there is any free cell}
	 		   		\STATE $R \leftarrow R \cup \{$heaviest free cell$\}$ \label{alg:ggpf:freeheavycell}
	 		   \ELSE
	 		   		\STATE stop. no more free cells.
	 		   \ENDIF
	 		\ENDWHILE
	 \ENDFOR\end{algorithmic}
\end{algorithm}

\subsubsection{\bfa} %v2
\label{sec:alg:bfa}

The \textbf{\bfa} (\bfameaning) is proposed here as an alternative to \ggp\ and its variants. The objective of the algorithm is to check what is the weight excess in each region and transfer it to free regions whose capacity is the closest to that value. This is done by transferring cells whose weight is the closest to free capacity of the receiving region, observed two restrictions: first, the total weight transferred can not be larger than the free capacity of the destination region and, second, we should not transfer a load greater than the necessary to eliminate the overload. The second restriction is justified because a weight transfer larger than necessary would probably result in a larger amount of migrating players. The exception to this rule is when a cell is heavier than the other, not for having more avatars, but because they are closer, with quadratic traffic growth between them. Algorithm \ref{alg:bfa} describes in detail the operation of \bfa.


\begin{algorithm}
\caption{\bfa}
\label{alg:bfa}
\begin{algorithmic}[1]

	 \FOR{each region $R_i$ in $\rlist$}
			\STATE $\wlose \leftarrow w_r(R_i) - W_{total} \times frac_p(s(R_i))$ \label{alg:bfa:wlose}
			\STATE $\destreg \leftarrow \rlist - \{R_i\}$
			\STATE sort $\destreg$ in decreasing order of $u(s(R))$ \label{alg:bfa:sort}
			\FOR{each region $R_j$ in $\destreg$}
				 \STATE $\regcap \leftarrow frac_p(s(R_j)) \times W_{total} - w_r(R_j)$ \label{alg:bfa:freecap}
				 \STATE $\wtoreg \leftarrow min(\wlose, \regcap)$ \label{alg:bfa:min}
				 \WHILE{$\wtoreg > 0$}
				 		\IF{$R_i$ has a cell $C$ such that $w_c(C) \leq \wtoreg$}
				 			 \STATE $C \leftarrow$ cell from $R_i$ with weight closest to, but not larger than, $\wtoreg$ \label{alg:bfa:bestfit}
				 			 \STATE $R_i \leftarrow R_i - \{C\}$
				 			 \STATE $R_j \leftarrow R_j \cup \{C\}$
				 			 \STATE $\wtoreg \leftarrow \wtoreg - w_c(C)$
				 			 \STATE $\wlose \leftarrow \wlose - w_c(C)$
				 		\ELSE
				 			 \STATE continue with next $R_j$. \label{alg:bfa:continue}
				 		\ENDIF
				 \ENDWHILE
			\ENDFOR			
	 \ENDFOR

\end{algorithmic}
\end{algorithm}


\subsubsection{Refining with the \kl\ algorithm}
\label{sec:alg:kl}
	
After balancing the load between servers in phase 2, all the servers will have a similar resource usage ratio. However, the algorithm in phase 2 cannot measure the final interaction between regions before repartitioning. This may lead to a partitioning that, although every server uses a similar percentage of its upload bandwidth to its clients, there may be a high inter-server communication overhead, causing a waste of resources of the server system.

To attenuate this problem, it is proposed here to use the algorithm of Kernighan and Lin \cite{kernighan1970ehp}. This algorithm receives as input the graph that represents the virtual environment. Given a pair of regions (partitions), \kl\ searches for pairs of cells (vertices) that, when exchanged between their regions, the overhead (edge-cut) is reduced.

%Let $R_A$ and $R_B$ be two regions and $a$ a cell such that $a \in R_A$. The external interaction of $a$ is defined as $E(a) = \sum_{b \in R_b} Int_c (a, b)$ and the internal interaction is defined as $I(a) = \sum_{a' \in R_A} Int_c(a, a')$. The cell $a$ is prone to change regions if its interaction with $R_B$ is greater than its interaction with $R_A$, i.e. $D(a) = E(a) - I(a) > 0$. Assuming that there is a cell $b \in R_B$ such that $D(a) + D(b) - 2 \times Int_c(a, b) > 0 $, the exchange will reduce the overhead between the regions. The term $D(a) + D(b) - 2 \times Int_c(a, b)$ is referred as $gain(a, b)$, because it represents the gain (reduction of overhead) of swapping the regions of $a$ and $b$.

In the case of a virtual environment distributed among various regions, generally more than two, \kl\ is run for each pair of regions. Moreover, after each swap performed by the algorithm, the balance must be kept -- otherwise, a completely unbalanced partitioning, with the lowest possible overhead, could be reached. The \kl\ algorithm is widely known in the area of distributed systems, so details will not be provided here. Consider only that it returns a value of $true$ if any change was made and $false$ otherwise. It runs for all pairs of regions. until it returns a value of false, indicating that no exchange will provide additional gain. Algorithm \ref{alg:kl} shows how the \kl\ algorithm is called.

%swapped = true;
%while swapped = true;
%	swapped = false;
%  for (each region R_i in reglist) {
%    for (each region R_j in reglist) {      
%      if kernighan-lin(R_i, R_j) = true
				  %swapped = true;
%    }
%  }
%}

\begin{algorithm}
\caption{\kl}
\label{alg:kl}
\begin{algorithmic}[1]

	\STATE $swapped \leftarrow$ \textbf{true}
	\WHILE{$swapped =$ \textbf{true}}
		\STATE $swapped \leftarrow$ \textbf{false}
		\FOR{each region $R_i$ in $\rlist$}
			\FOR{each region $R_j$ in $\rlist$}
				\IF{$Kernighan$-$Lin(R_i, R_j) =$ \textbf{true}}
					\STATE $swapped \leftarrow$ \textbf{true}
				\ENDIF
			\ENDFOR
		\ENDFOR
	\ENDWHILE

\end{algorithmic}
\end{algorithm}



\section{Work Analysis}

The technique presented by \cite{bezerra2009lbs} is good because it reduces significantly -- proved via simulations presented by the authors -- inter-server communication overhead, saving up resources of the system. However, there are a few issues with the approach. The first problem is that the granularity of the approach is fixed and limited by the cell size. If a finer granularity is desired, smaller cells should be used, increasing proportionally the complexity of the algorithm, and the potential fragmentation of the regions as well. Actually, another problem not solved with this approach is the very likely region fragmentation, as a region might contain disconnected cells. These two problems are well solved with the technique presented in the next chapter.