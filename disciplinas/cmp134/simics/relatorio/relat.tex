\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx,url}

% \usepackage{subfig}

\usepackage{graphics}
%\usepackage{math}
%\usepackage{mathaccent}


\usepackage[brazil]{babel}   
\usepackage[latin1]{inputenc} 

%\usepackage{times}
%\usepackage[latin1]{inputenc}
%\usepackage[brazil]{babel}

\hyphenation{vo-lu-me}

\begin{document}

\title{Um Breve Estudo da Adição de um Quarto\\ Nível de Cache em Processadores Multicore}

\author{Carlos Eduardo Benevides Bezerra\inst{1}}
\address{Instituto de Informática -- Universidade Federal do Rio Grande do Sul\\
  Caixa Postal 15.064 -- 91.501-970 -- Porto Alegre -- RS -- Brasil
}

\maketitle
\thispagestyle{empty}

\begin{abstract}
   The ABSTRACT is to be in fully-justified italicized text, at the top 
   of the left-hand column, below the author and affiliation 
   information. Use the word ``Abstract'' as the title, in 12-point 
   Times, boldface type, centered relative to the column, initially 
   capitalized. The abstract is to be in 10-point, single-spaced type. 
   The abstract may be up to 3 inches (7.62 cm) long. Leave two blank 
   lines after the Abstract, then begin the main text. 
\end{abstract}



%------------------------------------------------------------------------- 
\section{Introdução}

Nos últimos anos, a freqüência de relógio dos processadores tem aumentado bastante [FIXME:ref]. Paralelamente a isso, e devido a uma certa estagnação da velocidade dos cores [FIXME:ref], os fabricantes têm optado pela produção de processadores com vários núcleos de processamento (processadores \emph{multicore}, com diversos \emph{cores}). Exemplos disso são as arquitetura da Intel (\emph{Dunnington} [FIXME:ref], \emph{Nehalem} [FIXME:ref] etc.), AMD (\emph{Barcelona} [FIXME:ref], \emph{Budapest} [FIXME:ref], \emph{Deneb} [FIXME:ref] etc.) e Sun (\emph{Niagara} [FIXME:ref], \emph{Victoria Falls} [FIXME:ref] etc.).

[FIXME:fig.arch.Dunnington]

As memórias cache servem para reduzir o número de ciclos de latência que um processador deve esperar para acessar um determinado dado na memória. Reduzindo o número de ciclos, reduz-se o tempo necessário para acessar um dado. Por esta razão, o tempo de acesso a dados na memória cache é consideravelmente menor do que o tempo necessário para acessar a memória principal, por exemplo.

Contudo, ultimamente as aplicações têm cada vez um volume maior de dados a processar. Essa quantidade maior de dados, se não puderem ser acessados rapidamente pela unidade de processamento, podem implicar um pior desempenho do sistema [FIXME:ref]. Outra questão é que, nas arquiteturas multicore, vários núcleos podem estar utilizando a memória ao mesmo tempo. Por causa dessas razões, é recomendável aumentar o tamanho da memória cache (que tem acesso rápido) proporcionalmente ao aumento do volume de dados das aplicações e ao número de núcleos do processador.

A grande questão é que aumentar a memória cache, pura e simplesmente, pode não ser suficiente para reduzir o tempo de execução das tarefas realizadas pelo processador. Na verdade, um aumento sem critérios do espaço da memória cache pode implicar uma redução da velocidade do sistema. Isso acontece porque quanto maior a memória, maior é o seu tempo de acesso, devido a uma estrutura mais complexa de endereçamento [FIXME:ref]. Além disso, se vários núcleos estão tentando acessar a memória ao mesmo tempo, haverá uma contenção pelo barramento de acesso àquela memória, fazendo com que um ou mais processadores esperem até que o barramento seja liberado. Uma má escolha de estrutura e tamanho de memórias cache pode fazer com que uma arquitetura com mais memória seja mais lenta do que uma arquitetura com menos memória, porém estruturada de maneira mais eficiente.

Tendo esses aspectos em vista, neste trabalho foi feito um breve estudo da influência da estrutura de cache em processadores multicore, comparando o desempenho de uma hierarquia com 3 níveis de memória, comparada com outras duas hierarquias, ambas com 4 níveis, introduzindo um nível L4 compartilhado entre todos os núcleos. Como contribuição, neste trabalho foi testado o uso de uma hierarquia de memória entrelaçada -- o que será descrito nas próximas seções --, com o objetivo de reduzir a profundidade da busca realizada por um núcleo para buscar um dado compartilhado com outro núcleo.

O texto está organizado da seguinte forma: na seção \ref{sec:contmot}, é apresentado um pouco do contexto dentro do qual este trabalho se insere; na seção \ref{sec:prop}, é apresentada em maiores detalhes a proposta deste trabalho, incluindo a idéia de entrelaçar a hierarquia da memória cache; na seção \ref{sec:simul}, são apresentados os detalhes da modelagem e parâmetros das simulações que foram realizadas; na seção \ref{sec:result}, são mostrados os resultados e uma breve análise dos mesmos e, na seção \ref{sec:conc}, são apresentadas as conclusões a que se chegou com este trabalho.

%------------------------------------------------------------------------- 
\section{Contexto e motivação}
\label{sec:contmot}

%Falar de como funcionam as memórias cache (?)

%------------------------------------------------------------------------- 
\section{Proposta}
\label{sec:prop}

Este trabalho teve dois objetivos, que são procurar evidências de que a adição de um quarto nível de memória cache é mais benéfico do que aumentar a memória cache L3 e avaliar o ganho de desempenho conseguido ao se entrelaçar a hierarquia de memórias cache. Para analisar a diferença de desempenho com uma cache L3 grande, contra a adição de um módulo de memória L4, foram comparadas as arquiteturas seguintes:

\begin{itemize}
 \item uma arquitetura multicore, inspirada na arquitetura Dunnington, utilizada no Intel Xeon, que dispunha de 8 núcleos de processamento, com quatro módulos de memória cache L2, cada um compartilhado por um par de núcleos, e uma grande memória L3 (com 32 megabytes de espaço), compartilhada entre todos os oito núcleos (Figura \ref{L3});
\end{itemize}

\begin{figure}[!h]
  \centering  
  \includegraphics[width=0.8\linewidth]{../arq_L123}
  \caption{Arquitetura com 3 níveis de memória cache}
  \label{L3}
\end{figure}

\begin{itemize} 
\item uma arquitetura multicore, semelhante à anterior, também com oito núcleos, porém os 32 megabytes que eram da L3 foram dividos em: duas memórias L3 de 8 megabytes, cada uma compartilhada por metade dos núcleos, e uma memória L4 de 16 megabytes, compartilhada por todos (Figura \ref{L4}).
\end{itemize}

\begin{figure}[!h]
  \centering  
  \includegraphics[width=0.8\linewidth]{../arq_L1234}
  \caption{Arquitetura com 4 níveis de memória cache}
  \label{L4}
\end{figure}

Outra contribuição do trabalho foi que também se propôs o entrelaçamento da hierarquia das memórias cache. Para buscar algum resultado que indique se há algum benefício ao ser utilizado esse tipo de abordagem, foi comparadas as seguintes arquiteturas:

\begin{itemize}
 \item uma arquitetura com quatro níveis de cache (L1, L2, L3 e L4), onde cada módulo de cache só tem um módulo de nível inferior na hierarquia de memória, tal qual na Figura \ref{L4};
\end{itemize}

\begin{itemize}
 \item com outra arquitetura, na qual cada módulo de cache L2 pode ter uma ou duas memórias L3 no nível inferior da hierarquia. A Figura \ref{L4Interleaved} ilustra essa arquitetura de hierarquia entrelaçada, e a Figura \ref{treescompare} apresenta de maneira mais clara essa diferença das hierarquias -- na Figura \ref{treescompare} (a), temos a arquitetura sem entrelaçamento e, na Figura \ref{treescompare} (b), com entrelaçamento.
\end{itemize}

\begin{figure}[!h]
  \centering  
  \includegraphics[width=0.8\linewidth]{../arq_L1234Interleaved}
  \caption{Arquitetura com 4 níveis de memória cache e hierarquia entrelaçada}
  \label{L4Interleaved}
\end{figure}

\begin{figure}[!h]
  \centering  
  \includegraphics[width=0.8\linewidth]{../treescompare}
  \caption{Árvores representando as hierarquias avaliadas}
  \label{treescompare}
\end{figure}

O objetivo de fazer esse entrelaçamento é tentar reduzir o problema de poder haver buscas muito profundas na hierarquia das memórias cache quando dois núcleos de processamento compartilham uma variável. Seja uma situação em que os núcleos \emph{CPU\_0} e \emph{CPU\_7} (Figura \ref{L4}) lêem e escrevem na mesma variável \emph{x}. Sem o entrelaçamento,  quando um deles escrevesse nessa variável, o valor possivelmente armazenado na cache L1 do outro estaria incoerente e aquele núcleo teria que fazer uma busca até a primeira área de memória comum entre os dois núcleos -- no caso, a memória L4, que é mais distante dos núcleos e teria um tempo de acesso provavelmente maior, reduzindo o desempenho do sistema.

No entanto, considerando a arquitetura com hierarquia entrelaçada, apresentada na Figura \ref{L4Interleaved}, bastaria que o dado estivesse atualizado na cache de terceiro nível \emph{L3\_1}, que não seria necessário fazer uma busca tão profunda quanto mergulhar na árvore até o nível das caches L4. Utilizando essa abordagem, diminui-se a maior profundidade mínima de busca para que os núcleos compartilhem dados nas memórias cache. Contudo, esse mecanismo tem alguns detalhes a serem considerados numa implementação real da arquitetura. Por exemplo, quando ocorre um \emph{cache miss} em uma cache L2, pode ser necessário fazer busca em duas caches L3 -- no exemplo da Figura \ref{L4Interleaved}, isso acontece quando ocorre um cache miss nos módulos \emph{L2\_0} e \emph{L2\_2}. Isso se refletirá em um tempo maior de acesso, se as buscas forem seqüenciais, ou em maior custo de fabricação do hardware, se houver no processador uma unidade responsável por realizar as buscas em paralelo e retornar aquela que encontrar o dado procurado primeiro.

Na seção a seguir, serão apresentados os detalhes da modelagem das arquiteturas propostas e dos testes executados através de simulação.

%------------------------------------------------------------------------- 
\section{Modelagem e simulações}
\label{sec:simul}

Para realizar a simulação das arquiteturas propostas na seção \ref{sec:prop}, foi utilizado o simulador Simics [FIXME.ref.simics], versão 4. Através do Simics, é possível modelar e simular diversas arquiteturas de computadores, sobre as quais podem ser executados sistemas operacionais populares, como o Linux [FIXME.ref.linux]. Para modelar a arquitetura e os componentes de hardware, o Simics utiliza arquivos escritos com uma linguagem de modelagem de dispositivo (DML, \emph{device modeling language}), que permite criar componentes, ajustar seus atributos e conectá-los entre si. Após instalado e configurado o sistema operacional, foi instalado o programa de avaliação de desempenho NAS (\emph{Numerical Aerodynamic Simulation}), que permite a avaliação de desempenho de arquiteturas de computadores através de extensos cálculos numéricos [FIXME.ref.NAS].

A modelagem das arquiteturas propostas foi feita com base em uma arquitetura sparc64 (TI UltraSparc II -- \textit{BlackBird}). Todas têm as seguintes características em comum:

\begin{itemize}
 \item Número de núcleos de processamento: 8;
 \item Freqüência de clock de cada núcleo: 168 MHz;
 \item Memória cache L1 de dados: 32 kilobytes;
 \item Memória cache L1 de instruções: 32 kilobytes;
 \item Latência da cache L1: 2 ciclos;
 \item Memória cache L2: 1 megabyte (4 módulos de 1 MB, cada um compartilhado por um par de núcleos);
 \item Latência da cache L2: 5 ciclos.
\end{itemize}

A partir do terceiro nível de cache, as arquiteturas mudam completamente, sendo que três propostas foram modeladas:

\begin{itemize}
 \item Arquitetura \textbf{L123}, com três níveis de cache:
 \begin{itemize}
  \item Memória cache L3: 32 megabytes (compartilhados por todos os núcleos);
  \item Latência da cache L3: 30 ciclos;
 \end{itemize}
\end{itemize}

\begin{itemize}
 \item Arquitetura \textbf{L1234}, com quatro níveis de cache (sem entrelaçamento):
 \begin{itemize}
  \item Memória cache L3: 8 megabytes (2 módulos de 8 MB, cada um compartilhado por quatro núcleos);
  \item Latência da cache L3: 15 ciclos;
  \item Memória cache L4: 16 megabytes (compartilhados por todos os núcleos);
  \item Latência da cache L4: 30 ciclos.
 \end{itemize}
\end{itemize}

\begin{itemize}
 \item Arquitetura \textbf{InterleavedL4}, com quatro níveis de cache e com entrelaçamento:
 \begin{itemize}
  \item Memória cache L3: 8 megabytes (2 módulos de 8 MB, cada um compartilhado por quatro núcleos, porém o conjunto de núcleos é diferente da arquitetura L1234, entrelaçando os níveis de cache);
  \item Latência da cache L3: 20 ciclos;
  \item Memória cache L4: 16 megabytes (compartilhados por todos os núcleos);
  \item Latência da cache L4: 30 ciclos.
 \end{itemize}
\end{itemize}

Os motivos para decidir-se por esses parâmetros foram os seguintes: na arquitetura L123, a cache L3 tem 32 megabytes de espaço, causando um tempo de acesso (30 ciclos) maior do que na arquitetura L1234 (15 ciclos), onde cada cache L3 tem apenas 8 megabytes. Já na InterleavedL4, cada cache miss em uma cache L2 pode precisar de duas buscas nas caches L3. Para simular esse comportamento, definiu-se o tempo de acesso às L3 como de 20 ciclos, como uma estimativa de tempo médio de acesso.

O sistema operacional que foi instalado sobre cada uma das arquiteturas simuladas foi o Ubuntu (GNU/Linux, kernel 2.6.15-53). O software utilizado para avaliação das arquiteturas modeladadas, o NAS, consiste de diversos programas de avaliação de desempenho. Dois deles são o \textbf{BT} e o \textbf{CG}. Detalhes a respeito do que fazem podem ser encontrados em [FIXME.ref.NAS] e [FIXME.ref.NAS2]. 

Na próxima seção, serão apresentados os resultados encontrados com as simulações que foram realizadas.

%------------------------------------------------------------------------- 
\section{Resultados}
\label{sec:result}

Tanto o CG quando o BT buscam estressar os componentes de processamento e memória. O BT tem um tempo de execução maior, permitindo a avaliação do processador, enquanto que o CG visa a estressar as memórias, permitindo o teste de desempenho da estrutura de cache simulada. Foram utilizadas implementações em OpenMP [FIXME.ref.omp] de ambos. Para coletar os dados, foi utilizada a \emph{magic instruction} do Simics, que permite pausar a simulação e extrair o estado de cada um dos componentes de hardware. Os valores extraídos com esse método, para cada programa executado (BT e CG) foram:

\begin{itemize}
 \item Número de ciclos do processador;
 \item Número de \emph{steps} do processador;
 \item L3 cache write miss;
 \item L3 cache read miss;
 \item L4 cache write miss e
 \item L4 cache read miss.
\end{itemize}

\begin{figure}[!h]
  \centering  
  \includegraphics[width=0.8\linewidth]{../treescompare}
  \caption{Árvores representando as hierarquias avaliadas}
  \label{treescompare}
\end{figure}



%------------------------------------------------------------------------- 
\section{Conclusões}
\label{sec:conc}

All printed material, including text, illustrations, and charts, must be 
kept within a print area 6-7/8 inches (17.5 cm) wide by 8-7/8 inches 
(22.54 cm) high. Do not write or print anything outside the print area. 
Number your pages lightly, in pencil, on the upper right-hand corners of 
the BACKS of the pages (for example, 1/10, 2/10, or 1 of 10, 2 of 10, and 
so forth). Please do not write on the fronts of the pages, nor on the 
lower halves of the backs of the pages.

%------------------------------------------------------------------------- 
\section*{Agradecimentos}

%------------------------------------------------------------------------- 
\nocite{ex1,ex2}
\bibliographystyle{ieee}
\bibliography{ieee}

\end{document}

